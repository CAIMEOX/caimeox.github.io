<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>1036</fr:anchor><fr:taxon>Reference</fr:taxon><fr:addr>linear-algebra-2015</fr:addr><fr:route>linear-algebra-2015.xml</fr:route><fr:title>Linear Algebra Done Right</fr:title><fr:authors><fr:author>Sheldon Axler</fr:author></fr:authors><fr:meta name="doi">10.1007/978-3-319-11080-6</fr:meta><fr:meta name="venue">Linear and Multilinear Algebras, Matrix Theory</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>
    This best-selling textbook for a second course in linear algebra is aimed at undergrad math majors and graduate students.
</fr:p></fr:mainmatter><fr:backmatter><fr:contributions></fr:contributions><fr:context></fr:context><fr:related></fr:related><fr:backlinks><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>1033</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0005</fr:addr><fr:route>math-0005.xml</fr:route><fr:title>Linear Maps</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>31</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of linear maps.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    Now we arrive at the main topic of this chapter: linear maps. 
    In classic mathematics, to understand the properties of the structure or space,
    we often study the maps between them.
    For vector spaces we study the <fr:strong>linear maps</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>326</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0025</fr:addr><fr:route>def-0025.xml</fr:route><fr:title>Linear Map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>linear map</fr:strong> is a function between two vector spaces that preserves the operations of addition and scalar multiplication.
    In other words, a function <fr:tex>T: V  \to  W</fr:tex> where <fr:tex>V,W</fr:tex> are vector spaces if the following conditions are satisfied:
    <fr:ul><fr:li>Additivity: <fr:tex>T(u+v) = T(u) + T(v)</fr:tex> for all <fr:tex>u,v  \in  V</fr:tex></fr:li>
        <fr:li>Homogeneity: <fr:tex>T( \alpha  v) =  \alpha  T(v)</fr:tex> for all <fr:tex>\alpha   \in   \mathbb {F}</fr:tex> and <fr:tex>v  \in  V</fr:tex></fr:li></fr:ul>
    Sometimes we ignore the brackets and write <fr:tex>T v</fr:tex> instead of <fr:tex>T(v)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can talk about the set of all linear maps between two vector spaces.
    <fr:tex display="block">          \mathcal {L} (V,W) =  \{    T: V  \to  W | T  \text { is a linear map}   \}      </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>327</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0002</fr:addr><fr:route>eg-0002.xml</fr:route><fr:title>Differentiation is linear map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Define <fr:tex>D \in \mathcal {L} ( \mathcal {P}( \mathbb {R} ), \mathcal {P}( \mathbb {R} ))</fr:tex> (recall that <fr:tex>\mathcal {P}</fr:tex> means <fr:link href="def-0027.xml" type="local" addr="def-0027">set of polynomials</fr:link>) by
    <fr:tex display="block">         D(f) = f&apos;     </fr:tex>
    We can see that <fr:tex>D</fr:tex> a linear map.
    <fr:ul><fr:li>Additivity: <fr:tex>D(f+g) = (f+g)&apos; = f&apos; + g&apos; = D(f) + D(g)</fr:tex></fr:li>
        <fr:li>Homogeneity: <fr:tex>D( \alpha  f) = ( \alpha  f)&apos; =  \alpha  f&apos; =  \alpha  D(f)</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>328</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>eg-0003</fr:addr><fr:route>eg-0003.xml</fr:route><fr:title>Integration is linear map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be the vector space of all continuous functions on the interval <fr:tex>[a,b]</fr:tex>.
    The map <fr:tex>I: V  \to  V</fr:tex> defined by
    <fr:tex display="block">         I(f) =  \int _a^x f(t) dt     </fr:tex>
    is a <fr:strong>linear map</fr:strong>.
    In other words, <fr:tex>I</fr:tex> preserves the operations of addition and scalar multiplication:
    For all <fr:tex>f,g  \in  V</fr:tex> and all <fr:tex>\alpha   \in   \mathbb {R}</fr:tex>,
    <fr:tex display="block">         I(f+g) = I(f) + I(g)  \quad   \text {and}  \quad  I( \alpha  f) =  \alpha  I(f)     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    We can find a linear map that takes on <fr:em>whatever values we wish</fr:em> on the 
    vectors in a basis by the following theorem.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>329</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000F</fr:addr><fr:route>thm-000F.xml</fr:route><fr:title>Linear maps and basis of domain</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1, v_2,  \ldots , v_n</fr:tex> be a basis of vector space <fr:tex>V</fr:tex>.
    Then for any vector space <fr:tex>W</fr:tex> and any vectors <fr:tex>w_1, w_2,  \ldots , w_n</fr:tex> in <fr:tex>W</fr:tex>,
    there exists a unique linear map <fr:tex>T: V  \to  W</fr:tex> such that
    <fr:tex display="block">         T(v_i) = w_i  \quad   \text {for all}  \quad  i = 1,2, \ldots ,n     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now let&apos;s turn to the algebraic operations over the set of linear maps <fr:tex>\mathcal {L} (V,W)</fr:tex>.
    We begin by defining the addition and scalar multiplication of linear maps.
    This leads to a surprising result: the set of linear maps is actually a vector space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>330</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0029</fr:addr><fr:route>def-0029.xml</fr:route><fr:title>Addition and scalar multiplication over <fr:tex>\mathcal {L} (V,W)</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T_1, T_2  \in   \mathcal {L} (V,W)</fr:tex>.
    We define the <fr:strong>addition</fr:strong> of <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex> as the linear map <fr:tex>T_1 + T_2: V  \to  W</fr:tex> such that
    <fr:tex display="block">         (T_1 + T_2)(v) = T_1(v) + T_2(v)  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    The scalar multiplication of a linear map <fr:tex>T  \in   \mathcal {L} (V,W)</fr:tex> by a scalar <fr:tex>c  \in   \mathbb {F}</fr:tex> is the linear map <fr:tex>cT: V  \to  W</fr:tex> such that
    <fr:tex display="block">         (cT)(v) = cT(v)  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    With these operations, <fr:tex>\mathcal {L} (V,W)</fr:tex> is a <fr:link href="def-000H.xml" type="local" addr="def-000H"><fr:strong>vector space</fr:strong></fr:link> over the field <fr:tex>\mathbb {F}</fr:tex>.
    Note that the additive identity of <fr:tex>\mathcal {L} (V,W)</fr:tex> is the <fr:strong>zero map</fr:strong> <fr:tex>0: V  \to  W</fr:tex> such that
    <fr:tex display="block">         0(v) = 0  \quad   \text {for all}  \quad  v  \in  V     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Usually it makes no sense to multiply two linear maps. But we can define
    an operation called the <fr:strong>product</fr:strong> of linear maps, which is just the composition of the two functions.
    This can form a <fr:strong>monoid</fr:strong> or even a <fr:strong>group</fr:strong> under certain conditions.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>331</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002A</fr:addr><fr:route>def-002A.xml</fr:route><fr:title>Product of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T_1: V  \to  W</fr:tex> and <fr:tex>T_2: W  \to  U</fr:tex> be linear maps.
    We define the <fr:strong>product</fr:strong> of <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex> as the linear map <fr:tex>T_2  \circ  T_1: V  \to  U</fr:tex> such that
    <fr:tex display="block">         (T_2  \circ  T_1)(v) = T_2(T_1(v))  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    Note that this is just the composition of the two functions <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex>. 
    And we usually denote <fr:tex>T_2  \circ  T_1</fr:tex> by <fr:tex>T_2T_1</fr:tex>.
    The product of linear maps is associative, that is,
    <fr:tex display="block">         (T_3  \circ  T_2)  \circ  T_1 = T_3  \circ  (T_2  \circ  T_1)     </fr:tex>
    for any linear maps <fr:tex>T_1: V  \to  W</fr:tex>, <fr:tex>T_2: W  \to  U</fr:tex>, and <fr:tex>T_3: U  \to  X</fr:tex>.
    The identity map <fr:tex>I_V: V  \to  V</fr:tex> is the identity element of the set of linear maps <fr:tex>\mathcal {L} (V,V)</fr:tex> under the product operation.
    That is, for any linear map <fr:tex>T: V  \to  V</fr:tex>,
    <fr:tex display="block">         I_V  \circ  T = T  \circ  I_V = T     </fr:tex>
    where <fr:tex>I_V</fr:tex> is the identity map on <fr:tex>V</fr:tex>.
    The set of all linear maps from a vector space to itself, <fr:tex>\mathcal {L} (V,V)</fr:tex>, forms a <fr:link href="def-0007.xml" type="local" addr="def-0007"><fr:strong>monoid</fr:strong></fr:link> under the product operation.
    The set of all invertible linear maps from a vector space to itself, <fr:tex>\mathcal {L} (V,V)^*</fr:tex>, forms a group under the product operation.
    The identity map is the identity element of the <fr:link href="def-0001.xml" type="local" addr="def-0001"><fr:strong>group</fr:strong></fr:link> <fr:tex>\mathcal {L} (V,V)^*</fr:tex>.
</fr:p><fr:p>
    With addition we also have the distributive law for the product of linear maps.
    That is, for any linear maps <fr:tex>S,S_1,S_2: V  \to  W</fr:tex> and <fr:tex>T,T_1,T_2: U \to  V</fr:tex>:
    <fr:tex display="block">         (S_1 + S_2)T = S_1T + S_2T  \quad   \text {and}  \quad  T(S_1 + S_2) = TS_1 + TS_2     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    In algebra, we have a structure named <fr:strong>kernel</fr:strong>, which is the set of all elements that are mapped to the zero element.
    For linear maps, the kernel is the <fr:strong>null space</fr:strong></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>332</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002C</fr:addr><fr:route>def-002C.xml</fr:route><fr:title>Null Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    For <fr:tex>T: V  \to  W</fr:tex>, the <fr:strong>null space</fr:strong> of <fr:tex>T</fr:tex> is the set of all vectors in <fr:tex>V</fr:tex> that are mapped to <fr:tex>0</fr:tex> in <fr:tex>W</fr:tex>.
    <fr:tex display="block">          \text {null }  T =  \{   v  \in  V | T(v) = 0   \}      </fr:tex>
    The null space of <fr:tex>T</fr:tex> is a subspace of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The injective linear map is defined like normal <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link> functions.
    To check whether a linear map is injective, we can just check whether the null space is trivial.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>333</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000G</fr:addr><fr:route>thm-000G.xml</fr:route><fr:title>Injectivity equivalent to Kernel Triviality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T: V  \to  W</fr:tex> be a linear map. Then <fr:tex>T</fr:tex> is injective if and only if <fr:tex>\text {null }  T =  \{   0   \}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The image of a linear map is the set of all elements that are mapped to by some element in the domain.
    This is called the <fr:strong>range</fr:strong> of the linear map, just like <fr:link href="def-002E.xml" type="local" addr="def-002E">range</fr:link> of normal function.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>334</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000H</fr:addr><fr:route>thm-000H.xml</fr:route><fr:title>Range is a subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    If <fr:tex>T: V  \to  W</fr:tex> is a linear map, then the range of <fr:tex>T</fr:tex> is a subspace of <fr:tex>W</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next theorem plays a crucial role in the study of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>335</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000I</fr:addr><fr:route>thm-000I.xml</fr:route><fr:title>Fundamental Theorems of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be finite-dimensional vector space and <fr:tex>T : V  \to  W</fr:tex> be a linear map. 
    Then <fr:tex>\text {range }  T</fr:tex> is finite-dimensional and 
    <fr:tex display="block">          \dim  V =  \dim   \text {range }  T +  \dim   \text {null }  T     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can show that no linear map from a finite-dimensional vector space
    to a <fr:em>smaller</fr:em> (In dimension) vector space can be <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link>.
    This can be easily proved by the fundamental theorem of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>336</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000M</fr:addr><fr:route>thm-000M.xml</fr:route><fr:title>Map to smaller dimension is not injective</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces, 
    and <fr:tex>\dim  V &gt;  \dim  W</fr:tex>.
    Then no linear map <fr:tex>T:V \to  W</fr:tex> is injective.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Similarly, we can show that no linear map from a finite-dimensional vector space
    to a <fr:em>larger</fr:em> (In dimension) vector space can be <fr:link href="def-002F.xml" type="local" addr="def-002F">surjective</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>337</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000N</fr:addr><fr:route>thm-000N.xml</fr:route><fr:title>Map to bigger dimension is not surjective</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces, 
    and <fr:tex>\dim  V &lt;  \dim  W</fr:tex>.
    Then no linear map <fr:tex>T:V \to  W</fr:tex> is surjective.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    These two lemmas are very important in the study of linear equations.
    The idea here is to express linear equations system in terms of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>338</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0004</fr:addr><fr:route>eg-0004.xml</fr:route><fr:title>Homogeneous Linear Equations System</fr:title></fr:frontmatter><fr:mainmatter><fr:p>Reprase in terms of a linear map the question of whether a <fr:link href="def-002Q.xml" type="local" addr="def-002Q">homogeneous system linear equations</fr:link> has a nonzero solution.</fr:p><fr:p>
        Let <fr:tex>A</fr:tex> be the coefficient matrix of a homogeneous linear system.
        <fr:tex display="block">             A =  \begin {bmatrix}                 a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\                  a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}              \end {bmatrix}         </fr:tex>
        The equation <fr:tex>A \vec {x} =  \vec {0}</fr:tex> has a trivial solution <fr:tex>\vec {x} =  \vec {0}</fr:tex>.
        The question here is whether there is a nontrivial solution.
    </fr:p><fr:p>
        Define <fr:tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</fr:tex> by
        <fr:tex display="block">             T( \vec {x}) = A \vec {x}         </fr:tex>
        Then the question of whether the homogeneous linear system has a nontrivial solution is equivalent to 
        asking <fr:tex>\text {null }  T</fr:tex> is nontrivial.
        That is, <fr:tex>T</fr:tex> is <fr:link href="thm-000G.xml" type="local" addr="thm-000G">not injective</fr:link>.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>339</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000O</fr:addr><fr:route>thm-000O.xml</fr:route><fr:title>Homogeneous system of linear equations</fr:title></fr:frontmatter><fr:mainmatter><fr:p> 
    A homogeneous system of linear equations
    with more variables than equations has 
    a nontrivial solution.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have seen that <fr:link href="thm-000M.xml" type="local" addr="thm-000M">map to smaller dimension is not injective</fr:link>.
    <fr:tex>T</fr:tex> is not injective if <fr:tex>n &gt; m</fr:tex>. This results the theorem above.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>340</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0005</fr:addr><fr:route>eg-0005.xml</fr:route><fr:title>Inhomogeneous Linear Equations System</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
        Rephrase in terms of a linear map the question of whether a inhomogeneous system linear equations has no solutions
        for some choice of constant terms.
    </fr:p><fr:p>
    Let <fr:tex>A</fr:tex> be the coefficient matrix of a inhomogeneous linear system.
    <fr:tex display="block">         A =  \begin {bmatrix}             a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\              a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\               \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\              a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}          \end {bmatrix}     </fr:tex>
    The equation <fr:tex>A \vec {x} =  \vec {b}</fr:tex> has a solution <fr:tex>\vec {x} = A^{-1} \vec {b}</fr:tex>.
    </fr:p><fr:p>
        Define <fr:tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</fr:tex> by
        <fr:tex display="block">             T( \vec {x}) = A \vec {x}         </fr:tex>
        Then the statement that inhomogeneous linear system has no solutions is equivalent to 
        <fr:tex>\vec {b}  \not \in   \text {range }  T</fr:tex>.
        Thus the question is rephrased as not having a solution for some choice of <fr:tex>\vec {b}</fr:tex>.
        What condition ensures <fr:tex>T</fr:tex> is not surjective.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>341</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000P</fr:addr><fr:route>thm-000P.xml</fr:route><fr:title>Inhomogeneous system of linear equations</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An inhomogeneous system of linear equations
    with more equations than variables has 
    no solution for some choice of the constant term.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Let <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> be a basis of <fr:tex>V</fr:tex>.
    We know that for any value of a linear map <fr:tex>T:V \to  W</fr:tex>,
    can be determined by values <fr:tex>\{   T(v_1), T(v_2),  \cdots , T(v_n)   \}</fr:tex>.
    This leads to the definition of the matrix representation of a linear map.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>342</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002R</fr:addr><fr:route>def-002R.xml</fr:route><fr:title>Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>m,n \in   \mathbb {Z} ^+</fr:tex>.
    A <fr:tex>m \times  n</fr:tex> matrix is a rectangular array of elements of a field <fr:tex>\mathbb {F}</fr:tex>
    with <fr:tex>m</fr:tex> <fr:strong>rows</fr:strong> and <fr:tex>n</fr:tex> <fr:strong>columns</fr:strong>.
    <fr:tex display="block">         A =  \begin {bmatrix}             a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\              a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\               \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\              a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}          \end {bmatrix}     </fr:tex>
    The notation <fr:tex>A_{jk}</fr:tex> refers to the element in the <fr:tex>j</fr:tex>-th row and <fr:tex>k</fr:tex>-th column.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can define the matrix representation of a linear map.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>346</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002S</fr:addr><fr:route>def-002S.xml</fr:route><fr:title>Matrix of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex>\{   v_1, \ldots ,v_n   \} \subset  V</fr:tex> be a basis of <fr:tex>V</fr:tex>,
    and <fr:tex>\{   w_1, \ldots ,w_m   \} \subset  W</fr:tex> be a basis of <fr:tex>W</fr:tex>.
    The <fr:strong>matrix of <fr:tex>T</fr:tex></fr:strong> with respect to these bases is
    the <fr:tex>m \times  n</fr:tex> matrix <fr:tex>\mathcal {M} (T)</fr:tex> such that
    <fr:tex display="block">         T(v_j) =  \sum _{i=1}^m  \mathcal {M} (T)_{ij}w_i     </fr:tex>
    Or we denote <fr:tex>\mathcal {M} (T)</fr:tex> as <fr:tex>\mathcal {M} (T, (v_1, \ldots ,v_n), (w_1, \ldots ,w_m))</fr:tex>.
</fr:p><fr:p>
    If <fr:tex>T</fr:tex> maps <fr:tex>n</fr:tex>-dimensional vector space to <fr:tex>m</fr:tex>-dimensional vector space,
    then <fr:tex>\mathcal {M} (T)</fr:tex> is a <fr:tex>m \times  n</fr:tex> matrix.
</fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>343</fr:anchor><fr:title>
    <fr:strong>Addition</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    For two same-size matrix <fr:tex>A,B</fr:tex>,
    the sum of <fr:tex>A</fr:tex> and <fr:tex>B</fr:tex> is the matrix <fr:tex>C</fr:tex> such that
    <fr:tex display="block">         C_{ij} = A_{ij} + B_{ij}     </fr:tex>
    In the language of linear maps <fr:tex>S,T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex display="block">          \mathcal {M} (T+S) =  \mathcal {M} (T) +  \mathcal {M} (S)     </fr:tex>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>344</fr:anchor><fr:title>
    <fr:strong>Scalar Multiplication</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    For a scalar <fr:tex>c</fr:tex> and a matrix <fr:tex>A</fr:tex>,
    the product of <fr:tex>c</fr:tex> and <fr:tex>A</fr:tex> is the matrix <fr:tex>B</fr:tex> such that
    <fr:tex display="block">         B_{ij} = cA_{ij}     </fr:tex>
    In the language of linear maps <fr:tex>T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex display="block">          \mathcal {M} (cT) = c \mathcal {M} (T)     </fr:tex>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>345</fr:anchor><fr:title>
    <fr:strong>Set of Matrices</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    The set of all <fr:tex>m \times  n</fr:tex> matrices with elements in <fr:tex>\mathbb {F}</fr:tex> is denoted as <fr:tex>\mathcal {M} _{m \times  n}( \mathbb {F} )</fr:tex>
    or <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex>.
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
    We can see that <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex> is itself a vector space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>347</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000Q</fr:addr><fr:route>thm-000Q.xml</fr:route><fr:title><fr:tex>\dim \mathbb {F} ^{m \times  n} = mn</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:tex>\mathbb {F} ^{m \times  n}</fr:tex> is a vector space with dimension <fr:tex>mn</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Consider linear maps <fr:tex>T:U \to  V</fr:tex> and <fr:tex>S:V \to  W</fr:tex>.
    The composition of linear maps is <fr:tex>ST</fr:tex>.
    Does the composition of linear maps have a matrix representation?
    <fr:tex display="block">          \mathcal {M} (ST) =  \mathcal {M} (S) \mathcal {M} (T)     </fr:tex>
    This makes no sense now but indicates the definition of <fr:strong>matrix multiplication</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>349</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002T</fr:addr><fr:route>def-002T.xml</fr:route><fr:title>Matrix Multiplication</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be a <fr:tex>m \times  n</fr:tex> matrix and <fr:tex>B</fr:tex> be a <fr:tex>n \times  p</fr:tex> matrix.
    Then <fr:tex>AC</fr:tex> is defined as the <fr:tex>m \times  p</fr:tex> matrix <fr:tex>C</fr:tex> such that
    <fr:tex display="block">         C_{ij} =  \sum _{k=1}^n A_{ik}B_{kj}     </fr:tex></fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>348</fr:anchor><fr:title>
    <fr:strong>Derivation</fr:strong>
</fr:title><fr:parent>def-002T</fr:parent></fr:frontmatter><fr:mainmatter>
    Let <fr:tex>T:U \to  V</fr:tex> and <fr:tex>S:V \to  W</fr:tex> be linear maps.
    Denote <fr:tex>A =  \mathcal {M} (S)</fr:tex> and <fr:tex>C =  \mathcal {M} (T)</fr:tex>.
    Then the composition of linear maps <fr:tex>ST</fr:tex> is computed
    <fr:tex display="block">          \begin {align*}             (ST)(u)_k &amp;= S( \sum _{r=1}^n C_{rk}v_r)  \\              &amp;=  \sum _{r=1}^n C_{rk}S(v_r)  \\              &amp;=  \sum _{r=1}^n C_{rk} \sum _{s=1}^m A _{sr}w_s  \\              &amp;=  \sum _{s=1}^m \left ( \sum _{r=1}^n C_{rk}A_{sr} \right )w_s  \\           \end {align*}     </fr:tex>
    Thus <fr:tex>\mathcal {M} (ST)</fr:tex> is the <fr:tex>m \times  p</fr:tex> whose entries are
    <fr:tex display="block">          \mathcal {M} (ST)_{sk} =  \sum _{r=1}^n A_{sr}C_{rk}     </fr:tex>
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
    Now we see that the desired matrix multiplication holds.
    Matrix multiplication is not commutative in general.
    However, it satisfies the associative law and the distributive law.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>350</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002Y</fr:addr><fr:route>def-002Y.xml</fr:route><fr:title><fr:tex>A_{j \cdot }</fr:tex> and <fr:tex>A_{ \cdot  j}</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be a <fr:tex>m \times  n</fr:tex> matrix.
    <fr:ul><fr:li>
            If <fr:tex>1 \leq  j \leq  m</fr:tex> then <fr:tex>A_{j \cdot }</fr:tex> is the <fr:tex>j</fr:tex>-th row of <fr:tex>A</fr:tex>,
            defined as a <fr:tex>1 \times  n</fr:tex> matrix. (A row vector)
        </fr:li>
        <fr:li>
            If <fr:tex>1 \leq  j \leq  n</fr:tex> then <fr:tex>A_{ \cdot  j}</fr:tex> is the <fr:tex>j</fr:tex>-th column of <fr:tex>A</fr:tex>,
            defined as a <fr:tex>m \times  1</fr:tex> matrix. (A column vector)
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    With the notation we can think of matrix multiplication in another perspective.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>351</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000R</fr:addr><fr:route>thm-000R.xml</fr:route><fr:title>Entry pf matrix product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose <fr:tex>A</fr:tex> is an <fr:tex>m \times  n</fr:tex> matrix and <fr:tex>B</fr:tex> is an <fr:tex>n \times  p</fr:tex> matrix.
    Then the entry of the product <fr:tex>AB</fr:tex> is:
    <fr:tex display="block">         (AB)_{ij} = A_{i \cdot }B_{ \cdot  j}     </fr:tex>
    for <fr:tex>1 \leq  i \leq  m</fr:tex> and <fr:tex>1 \leq  j \leq  p</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have an interesting observation.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>352</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000S</fr:addr><fr:route>thm-000S.xml</fr:route><fr:title>Linear Combination of columns</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be an <fr:tex>m \times  n</fr:tex> matrix,
    and <fr:tex>c</fr:tex> is a <fr:tex>1 \times  1</fr:tex> matrix.
    <fr:tex display="block">         c =  \begin {pmatrix} c_1  \\  c_2  \\   \vdots   \\  c_n  \end {pmatrix}     </fr:tex>
    Then <fr:tex>Ac = c_1A_{ \cdot  1} + c_2A_{ \cdot  2} +  \cdots  + c_nA_{ \cdot  n}</fr:tex>.
    In other words, <fr:tex>Ac</fr:tex> is a linear Combination of the columns of <fr:tex>A</fr:tex>,
    with the scalars that multiply the columns coming from <fr:tex>c</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we begin the study the invertibility of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>353</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002Z</fr:addr><fr:route>def-002Z.xml</fr:route><fr:title>Inverse</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A linear map <fr:tex>T \in \mathcal {L} (V,W)</fr:tex> is said to be <fr:tex>invertible</fr:tex> if 
    there exists a linear map <fr:tex>S \in \mathcal {L} (W,V)</fr:tex> such that:
    <fr:tex display="block">          \begin {align*}             T \cdot  S &amp;=  \text {id} _V  \\              S \cdot  T &amp;=  \text {id} _W          \end {align*}     </fr:tex>
    where <fr:tex>\text {id}</fr:tex> is the identity map.
    If a linear map <fr:tex>T</fr:tex> is invertible, 
    then the map <fr:tex>S</fr:tex> is <fr:strong>unique</fr:strong> and is called the <fr:strong>inverse</fr:strong> of <fr:tex>T</fr:tex>, denoted <fr:tex>T^{-1}</fr:tex>.
</fr:p><fr:p>
    An <fr:strong>isomorphism</fr:strong> is a linear map that is invertible.
    Two vector spaces are said to be <fr:strong>isomorphic</fr:strong> if there exists an isomorphism between them.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    A linear map is invertible if and only if
    it is <fr:strong>bijective</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>354</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000T</fr:addr><fr:route>thm-000T.xml</fr:route><fr:title>Isomorphism of equal dimensions</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Two finite-dimensional vector spaces over <fr:tex>\mathbb {F}</fr:tex>
    are isomorphic iff they have the same <fr:link href="def-001V.xml" type="local" addr="def-001V">dimension</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>355</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000U</fr:addr><fr:route>thm-000U.xml</fr:route><fr:title><fr:tex>\mathcal {L} (V,W)</fr:tex> is isomorphic to <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1, v_2,  \ldots , v_n</fr:tex> be a basis for <fr:tex>V</fr:tex>,
    and <fr:tex>w_1, w_2,  \ldots , w_m</fr:tex> be a basis for <fr:tex>W</fr:tex>.
    Then <fr:tex>\mathcal {M}</fr:tex> is an isomorphism between <fr:tex>\mathcal {L} (V,W)</fr:tex> and <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This has a trivial corollary.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>356</fr:anchor><fr:taxon>Corollary</fr:taxon><fr:addr>thm-000V</fr:addr><fr:route>thm-000V.xml</fr:route><fr:title>Dimension product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces.
    Then <fr:tex>\mathcal {L} (V,W)</fr:tex> is finite-dimensional and
    <fr:tex display="block">          \dim ( \mathcal {L} (V,W)) =  \dim (V) \dim (W).     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>1034</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0002</fr:addr><fr:route>math-0002.xml</fr:route><fr:title>Finite Dimensional Vector Space</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of finite-dimensional vector space.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    Adding up scalar mulitples of vectors in a list gives a linear combination.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>306</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000L</fr:addr><fr:route>def-000L.xml</fr:route><fr:title>Linear Combination</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a <fr:link href="def-000H.xml" type="local" addr="def-000H">vector space</fr:link> over a field <fr:tex>F</fr:tex>.
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in <fr:tex>V</fr:tex>.
    A <fr:strong>linear combination</fr:strong> of <fr:tex>v_1,  \dots , v_n</fr:tex> is an expression of the form
    <fr:tex display="block">         a_1 v_1 +  \dots  + a_n v_n     </fr:tex>
    where <fr:tex>a_1,  \dots , a_n  \in  F</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    To talk about a structure, we usually define a collection of this structure.
    Hence we have span for linear combinations.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>307</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000M</fr:addr><fr:route>def-000M.xml</fr:route><fr:title>Linear Span</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a vector space over a field <fr:tex>F</fr:tex>.
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in <fr:tex>V</fr:tex>.
    The <fr:strong>span</fr:strong> of <fr:tex>v_1,  \dots , v_n</fr:tex> is defined as
    <fr:tex display="block">          \text {span} (v_1,  \dots , v_n) =  \{ a_1 v_1 +  \dots  + a_n v_n  \mid  a_i  \in  F \}      </fr:tex>
    The span of empty set is defined to be <fr:tex>\{ 0 \}</fr:tex>.    
</fr:p><fr:p>
    If <fr:tex>\text {span} (v_1,  \dots , v_n) = V</fr:tex>, we say that <fr:tex>v_1,  \dots , v_n</fr:tex> <fr:strong>spans</fr:strong> <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Suppose we have span <fr:tex>S= \text {span} (v_1,  \dots , v_n)</fr:tex>. (Span is trivially a subspace.)
    Obviously for all <fr:tex>v_j (1  \leq  j  \leq  n)</fr:tex>, <fr:tex>v_j  \in  S</fr:tex>.
    Because subspaces are closed under scalar multiplication and addition, every
    subspace of <fr:tex>V</fr:tex> containing <fr:tex>v_1,  \dots , v_n</fr:tex> must contain <fr:tex>S</fr:tex>.
    Thus we conclude that <fr:tex>S</fr:tex> is the smallest subspace containing <fr:tex>v_1,  \dots , v_n</fr:tex>.
</fr:p><fr:p>
    The discussion about <fr:strong>spans</fr:strong> leads to a key definition in linear algebra.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>308</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000N</fr:addr><fr:route>def-000N.xml</fr:route><fr:title>Finite-Dimensional Vector Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:link href="def-000H.xml" type="local" addr="def-000H">vector space</fr:link> <fr:tex>V</fr:tex> is called <fr:strong>finite-dimensional</fr:strong> if some <fr:link href="def-000G.xml" type="local" addr="def-000G">list</fr:link> of vectors <fr:tex>v_1,  \dots , v_n</fr:tex> <fr:link href="def-000M.xml" type="local" addr="def-000M">spans</fr:link> <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The opposite of finite-dimensional is infinite-dimensional.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>309</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000O</fr:addr><fr:route>def-000O.xml</fr:route><fr:title>Infinite-dimensional vector space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A vector space <fr:tex>V</fr:tex> is called <fr:strong>infinite-dimensional</fr:strong> if it is not <fr:link href="def-000N.xml" type="local" addr="def-000N">finite-dimensional</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Consider the situation that there is only one way to
    express a vector <fr:tex>v</fr:tex> as a linear combination of vectors in a list <fr:tex>v_1,  \dots , v_n</fr:tex>.
    What property of the list <fr:tex>v_1,  \dots , v_n</fr:tex> does this situation imply? The answer is
    linear independence.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>310</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000P</fr:addr><fr:route>def-000P.xml</fr:route><fr:title>Linearly independent</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A set of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is called <fr:strong>linearly independent</fr:strong> if
    <fr:tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</fr:tex>
    implies that <fr:tex>a_1 =  \dots  = a_n = 0</fr:tex>.
    The trivial case of <fr:tex>\{ 0 \}</fr:tex> is also considered linearly independent.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    If some vectors are not linearly independent, then there are more than one way to
    express a vector as a linear combination of vectors in the list. This leads to 
    the following definition.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>311</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Q</fr:addr><fr:route>def-000Q.xml</fr:route><fr:title>Linearly dependent</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A set of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is called <fr:strong>linearly dependent</fr:strong> if
    <fr:tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</fr:tex>
    for some <fr:tex>a_1,  \dots , a_n  \in   \mathbb {F}</fr:tex> with at least one <fr:tex>a_i  \neq  0</fr:tex> (not all <fr:tex>0</fr:tex>).
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The following lemma is a direct consequence of the definition of linear independence.
    It states that for a given linearly dependent list, we can always remove a vector
    without changing the span.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>312</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-0001</fr:addr><fr:route>thm-0001.xml</fr:route><fr:title>Linear Dependence Lemma</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in a vector space <fr:tex>V</fr:tex> over a field <fr:tex>\mathbb {F}</fr:tex>.
    If <fr:tex>v_1,  \dots , v_n</fr:tex> are linearly dependent, then there exists <fr:tex>1  \leq  i  \leq  n</fr:tex> such that
    <fr:ul><fr:li><fr:tex>v_i  \in   \text {span} (v_1,  \dots , v_{i-1})</fr:tex></fr:li>
        <fr:li>Remove <fr:tex>v_i</fr:tex> from the list <fr:tex>v_1,  \dots , v_n</fr:tex> and the span does not change</fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>313</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-0002</fr:addr><fr:route>thm-0002.xml</fr:route><fr:title>Length of linearly independent list <fr:tex>\leq</fr:tex> length of spanning list</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    In a finite dimensional vector space, the length of a linearly independent list is less than or equal to the length of a spanning list.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have discussed linear independent lists and spanning lists.
    Now we are ready to define a basis.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>314</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000R</fr:addr><fr:route>def-000R.xml</fr:route><fr:title>Basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A basis of <fr:tex>V</fr:tex> is a list of vectors in <fr:tex>V</fr:tex>
    that is linearly independent and spans <fr:tex>V</fr:tex>. 
</fr:p><fr:p><fr:strong>Criterion for basis</fr:strong>
    A list of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is a basis of <fr:tex>V</fr:tex> if and only if
    every <fr:tex>v  \in  V</fr:tex> can be written <fr:strong>uniquely</fr:strong> as a linear combination of <fr:tex>v_1,  \dots , v_n</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    For instance, we have standard basis <fr:tex>\{ e_1,  \dots , e_n \}</fr:tex> for <fr:tex>\mathbb {F}^n</fr:tex>,
    where <fr:tex>e_i</fr:tex> is the vector with <fr:tex>1</fr:tex> at <fr:tex>i</fr:tex>-th position and <fr:tex>0</fr:tex> elsewhere.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>315</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0005</fr:addr><fr:route>thm-0005.xml</fr:route><fr:title>Spanning List contains a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every spanning list in a vector space can be reduced to a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    From the <fr:link href="thm-0005.xml" type="local" addr="thm-0005">theorem</fr:link> we can infer a corollary.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>316</fr:anchor><fr:taxon>Corollary</fr:taxon><fr:addr>thm-0006</fr:addr><fr:route>thm-0006.xml</fr:route><fr:title>Basis of finite-dimensional vector space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every finite-dimensional vector space has a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next result states for a spanning list can be reduced to a basis.
    We can adjoin one or more vectors to a linearly independent list to form a basis.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>317</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0007</fr:addr><fr:route>thm-0007.xml</fr:route><fr:title>Linearly dependent list extends to a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every linearly independent list of vectors in  a finite-dimensional vector space can be extended to a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Remind the definition of <fr:link href="der-000K" type="external">direct sum</fr:link>, we can now show that
    every subspace of a finite-dimensional vecrtor space can be paired
    with another subspace to form a direct sum of the whole space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>318</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0008</fr:addr><fr:route>thm-0008.xml</fr:route><fr:title>Direct Sum of Subspaces of <fr:tex>V</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose <fr:tex>V</fr:tex> is a finite dimensional vector space,
    and <fr:tex>U</fr:tex> is a subspace of <fr:tex>V</fr:tex>.
    Then there exists a subspace <fr:tex>W</fr:tex> of <fr:tex>V</fr:tex> such that
    <fr:tex>V = U  \oplus  W</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This post discusses about <fr:em>finite-dimensional vector space</fr:em>.
    But we have not yet defined what is dimension.
    We tempted to define the dimension as the length of basis intuitively.
    With this definition we should prove its well-definedness.
    That is, every basis has the same length.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>319</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0009</fr:addr><fr:route>thm-0009.xml</fr:route><fr:title>Basis length is invariant</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every basis of <fr:tex>V</fr:tex> has the same length.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This can be proved by <fr:link href="thm-0002.xml" type="local" addr="thm-0002">Lemma 8</fr:link>.
    Now we can formally define the dimension of such spaces.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>320</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-001V</fr:addr><fr:route>def-001V.xml</fr:route><fr:title>Dimension</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>dimension</fr:strong> of a finite-dimensional vector space <fr:tex>V</fr:tex> is the length of any basis of the vector space.
    Denoted by <fr:tex>\dim  V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Every subspace of a finite-dimensional vector space is also finite-dimensional.
    Hence we can talk about the dimension of a subspace.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>321</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000A</fr:addr><fr:route>thm-000A.xml</fr:route><fr:title>Dimension of a subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex>U</fr:tex> be a subspace of <fr:tex>V</fr:tex>.
    Then <fr:tex>\dim  U  \leq   \dim  V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    According to the definition of <fr:link href="def-000P.xml" type="local" addr="def-000P">linearly independent</fr:link>,
    to show a list of vectors is a basis, we only need to show it is linearly independent,
    and it spans the whole space.
    The next theorems simplifies the task:
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>322</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000B</fr:addr><fr:route>thm-000B.xml</fr:route><fr:title>Linearly independent list of the right length is a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link href="def-000P.xml" type="local" addr="def-000P">linearly independent</fr:link> list of vectors in <fr:tex>V</fr:tex> with length equal to <fr:tex>\dim  V</fr:tex> is a basis of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>323</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000C</fr:addr><fr:route>thm-000C.xml</fr:route><fr:title>Spanning list of the right length is a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link href="def-000M.xml" type="local" addr="def-000M">spanning</fr:link> list of vectors in <fr:tex>V</fr:tex> with length equal to <fr:tex>\dim  V</fr:tex> is a basis of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we move to the discussion of the dimension of the sum of two subspaces.
    This is analogous to the <fr:link href="thm-000E.xml" type="local" addr="thm-000E">inclusion-exclusion principle</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>324</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000D</fr:addr><fr:route>thm-000D.xml</fr:route><fr:title>Dimension of a sum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex>U</fr:tex> and <fr:tex>W</fr:tex> be subspaces of <fr:tex>V</fr:tex>.
    Then
    <fr:tex display="block">          \dim (U + W) =  \dim  U +  \dim  W -  \dim (U  \cap  W).     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>1035</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0001</fr:addr><fr:route>math-0001.xml</fr:route><fr:title>Introduction to Vector Space</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of vector space.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    The motivation for the definition of a vector space comes from the properties
    of vectors in Euclidean space <fr:tex>\mathbb {R}^n</fr:tex> and <fr:tex>\mathbb {C}^n</fr:tex>.
    The definition abstracts and generalizes these properties.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>301</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000H</fr:addr><fr:route>def-000H.xml</fr:route><fr:title>Vector Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A vector space over a <fr:link href="def-0006.xml" type="local" addr="def-0006">field</fr:link> <fr:tex>F</fr:tex> is a non-empty set <fr:tex>V</fr:tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <fr:tex>F</fr:tex> are commonly called <fr:strong>vectors</fr:strong>, and the elements of <fr:tex>F</fr:tex> are called <fr:strong>scalars</fr:strong>.
    <fr:ul><fr:li>Commutativity: <fr:tex>              \forall  x, y  \in  V, x + y = y + x         </fr:tex></fr:li>
        <fr:li>Associativity: <fr:tex>              \forall  x, y, z  \in  V, (x + y) + z = x + (y + z)         </fr:tex></fr:li>
        <fr:li>Additive Identity: <fr:tex>              \exists  0  \in  V  \text { such that }  \forall  x  \in  V, x + 0 = x         </fr:tex></fr:li>
        <fr:li>Multiplicative Identity: <fr:tex>              \forall  x  \in  V, 1x = x         </fr:tex></fr:li>
        <fr:li>Additive Inverse: <fr:tex>              \forall  x  \in  V,  \exists  y  \in  V  \text { such that } x + y = 0         </fr:tex></fr:li>
        <fr:li>Distributivity: <fr:tex>              \forall  x, y  \in  V,  \forall  c, d  \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx         </fr:tex></fr:li></fr:ul></fr:p><fr:p>
    Elements of a vector space are called <fr:strong>vectors</fr:strong> or <fr:strong>points</fr:strong>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    When dealing with vector spaces, we usually interested only in subspaces.
    And the union of subspaces is rarely a subspace, thus
    we are more interested with sums of subspaces.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>302</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000I</fr:addr><fr:route>def-000I.xml</fr:route><fr:title>Linear Subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A subset <fr:tex>U</fr:tex> of a vector space <fr:tex>V</fr:tex> over a field <fr:tex>F</fr:tex> is called a <fr:strong>subspace</fr:strong> of <fr:tex>V</fr:tex> if <fr:tex>U</fr:tex> is itself a <fr:strong>vector space</fr:strong> over <fr:tex>F</fr:tex> with the operations of addition and scalar multiplication on <fr:tex>V</fr:tex>.
    The subset also satisfies the following axioms (vice versa):
    <fr:ul><fr:li>Additive identity: <fr:tex>0 \in  U</fr:tex></fr:li>
        <fr:li>Closure: <fr:tex>\forall  u,v \in  U, u+v \in  U</fr:tex></fr:li>
        <fr:li>Closed Scalar multiplication: <fr:tex>\forall  u \in  U,  \forall  c \in  F, cu \in  U</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    After that we can define the sum of subsets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>303</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000J</fr:addr><fr:route>def-000J.xml</fr:route><fr:title>Sum of subsets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>U_1,  \dots , U_n</fr:tex> be subsets of a vector space <fr:tex>V</fr:tex>.
    The <fr:strong>sum</fr:strong> of <fr:tex>U_1,  \dots , U_n</fr:tex> is defined as
    <fr:tex display="block">U_1 +  \dots  + U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The sum of subspaces is the smallest subspace that contains all the subspaces.
</fr:p><fr:p>
    Every element in <fr:tex>U_1 +  \dots  + U_n</fr:tex> can be written as a sum of elements <fr:tex>u_i</fr:tex> in <fr:tex>U_i</fr:tex>:
    <fr:tex display="block">         u_1+ \cdots +u_n     </fr:tex>
    We will interested in cases where each vector in <fr:tex>U_1 +  \dots  + U_n</fr:tex> can be represented in the form above
    in only one way. This leads to the definition of direct sum.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>304</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000K</fr:addr><fr:route>def-000K.xml</fr:route><fr:title>Direct Sum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>U_1,  \dots , U_n</fr:tex> be subspaces of a vector space <fr:tex>V</fr:tex>.
    The <fr:strong>direct sum</fr:strong> of <fr:tex>U_1,  \dots , U_n</fr:tex> is defined as
    <fr:tex display="block">         U_1  \oplus   \dots   \oplus  U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \}      </fr:tex>
    if every element in <fr:tex>U_1  \oplus   \dots   \oplus  U_n</fr:tex> can be written as <fr:tex>u_1 +  \dots  + u_n </fr:tex> in only one way.
    This definition requires every vector in the sum have a unique representation.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:backlinks><fr:references></fr:references></fr:backmatter></fr:tree>