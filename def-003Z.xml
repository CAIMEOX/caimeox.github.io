<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?><fr:tree toc="true" numbered="true" show-heading="true" show-metadata="true" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
  <fr:frontmatter>
    <fr:anchor>1848</fr:anchor>
    <fr:addr type="user">def-003Z</fr:addr>
    <fr:route>def-003Z.xml</fr:route>
    <fr:title text="Transposition">Transposition</fr:title>
    <fr:taxon>Definition</fr:taxon>
    <fr:authors></fr:authors>
  </fr:frontmatter>
  <fr:mainmatter>
    <fr:p>A <fr:link type="local" href="def-003Y.xml" addr="def-003Y" title="Permutation">permutation</fr:link> in which only two elements are exchanged is called a <fr:strong>transposition</fr:strong>.
    The notation is <fr:tex display="inline">\tau _{i,j}</fr:tex> where <fr:tex display="inline">i</fr:tex> and <fr:tex display="inline">j</fr:tex> are the two elements exchanged while the others remain fixed.</fr:p>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree toc="false" numbered="false" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
      <fr:frontmatter>
        <fr:title text="Context">Context</fr:title>
        <fr:authors></fr:authors>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="false" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
          <fr:frontmatter>
            <fr:anchor>1849</fr:anchor>
            <fr:addr type="user">math-0007</fr:addr>
            <fr:route>math-0007.xml</fr:route>
            <fr:title text="Vector Calculus and Geometry of Space">Vector Calculus and Geometry of Space</fr:title>
            <fr:taxon>Differential Geometry</fr:taxon>
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>4</fr:month>
              <fr:day>5</fr:day>
            </fr:date>
            <fr:authors></fr:authors>
          </fr:frontmatter>
          <fr:mainmatter>
            <fr:p>Notes about multi-variable calculus, geometry of space and linear algebra.
    Refer to <fr:link type="external" href="A%20Visual%20Introduction%20to%20Differential%20Forms%20and%20Calculus%20on%20Manifolds">df-cm-2018</fr:link>.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>651</fr:anchor>
                <fr:addr type="machine">#312</fr:addr>
                <fr:route>unstable-312.xml</fr:route>
                <fr:title text="Review of Vector Spaces">Review of Vector Spaces</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>We now start with introducing the vector space over the field of real numbers <fr:tex display="inline">\mathbb {R}</fr:tex>.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>652</fr:anchor>
                    <fr:addr type="user">def-000H</fr:addr>
                    <fr:route>def-000H.xml</fr:route>
                    <fr:title text="Vector Space">Vector Space</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A vector space over a <fr:link type="local" href="def-0006.xml" addr="def-0006" title="Field">field</fr:link> <fr:tex display="inline">F</fr:tex> is a non-empty set <fr:tex display="inline">V</fr:tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <fr:tex display="inline">V</fr:tex> are commonly called <fr:strong>vectors</fr:strong>, and the elements of <fr:tex display="inline">F</fr:tex> are called <fr:strong>scalars</fr:strong>.
    <fr:ul><fr:li>Commutativity: <fr:tex display="inline">             \forall  x, y \in  V, x + y = y + x         </fr:tex></fr:li>
        <fr:li>Associativity: <fr:tex display="inline">             \forall  x, y, z \in  V, (x + y) + z = x + (y + z)         </fr:tex></fr:li>
        <fr:li>Additive Identity: <fr:tex display="inline">             \exists  0 \in  V \text { such that } \forall  x \in  V, x + 0 = x         </fr:tex></fr:li>
        <fr:li>Multiplicative Identity: <fr:tex display="inline">             \forall  x \in  V, 1x = x         </fr:tex></fr:li>
        <fr:li>Additive Inverse: <fr:tex display="inline">             \forall  x \in  V, \exists  y \in  V \text { such that } x + y = 0         </fr:tex></fr:li>
        <fr:li>Distributivity: <fr:tex display="inline">             \forall  x, y \in  V, \forall  c, d \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx         </fr:tex></fr:li></fr:ul></fr:p>
                    <fr:p>Elements of a vector space are called <fr:strong>vectors</fr:strong> or <fr:strong>points</fr:strong>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Use <fr:tex display="inline">\mathbb {R}^2</fr:tex> as an example we can see (Note that we always treat elements of vector spaces as 
        column vectors and never as row vectors):
        <fr:tex display="block">             c \cdot  \begin {bmatrix}                 a \\ b             \end {bmatrix} = \begin {bmatrix}                 c \cdot  a \\ c \cdot  b             \end {bmatrix}         </fr:tex></fr:p>
                <fr:p>Now we will consider a certain type of transformation between vector spaces called a <fr:link type="local" href="def-0025.xml" addr="def-0025" title="Linear Map"><fr:strong>linear transformation</fr:strong></fr:link>.
        Suppose <fr:tex display="inline">T</fr:tex> is a mapping between <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>, that is <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex>, then <fr:tex display="inline">T</fr:tex> is a linear transformation if:
        <fr:tex display="block">             T(c \cdot  \vec {v}) = c \cdot  T(\vec {v})             \\              T(\vec {v} + \vec {w}) = T(\vec {v}) + T(\vec {w})         </fr:tex>
        If <fr:tex display="inline">T</fr:tex> is a linear transformation from <fr:tex display="inline">\mathbb {R}^m</fr:tex> to <fr:tex display="inline">\mathbb {R}</fr:tex> we simply call it a <fr:strong>linear function</fr:strong> or a <fr:strong>linear functional</fr:strong>.</fr:p>
                <fr:p>We now turn our attention to the relationship between linear transformation and matrices. 
        We just stick to vector spaces <fr:tex display="inline">\mathbb {R}^n</fr:tex> and the standard basis made up of the <fr:strong>Euclidian unit vectors</fr:strong>.
        In order to write linear transformation <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> as a matrix we need ordered bases for both <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
        We can use the intuitively obvious order <fr:tex display="inline">e_1 &lt; e_2 &lt; \cdots  &lt; e_n</fr:tex>.
        Now we can give formal definition of the matrix representation of a linear transformation.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>653</fr:anchor>
                    <fr:addr type="user">def-003W</fr:addr>
                    <fr:route>def-003W.xml</fr:route>
                    <fr:title text="Matrix Representation of Linear Transformation over {R}^n">Matrix Representation of Linear Transformation over <fr:tex display="inline">\mathbb {R}^n</fr:tex></fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>Suppose that <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> is a linear transformation between vector spaces <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
    Let <fr:tex display="inline">e_1, e_2, \ldots , e_n</fr:tex> be the standard basis of <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">f_1, f_2, \ldots , f_m</fr:tex> be the standard basis of <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
    Then the matrix representation of <fr:tex display="inline">T</fr:tex> is the <fr:tex display="inline">m \times  n</fr:tex> matrix <fr:tex display="inline">A</fr:tex> such that for <fr:tex display="inline">1\leq  j\leq  n</fr:tex>:
    <fr:tex display="block">         T(e_j) = \sum _{i=1}^m A_{ij} f_i     </fr:tex>
    where the matrix representation of <fr:tex display="inline">T</fr:tex> is given by the <fr:tex display="inline">m\times  n</fr:tex> matrix with entries <fr:tex display="inline">A_{ij}</fr:tex>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>The last major topic in this section is the definition of the <fr:link type="local" href="def-003X.xml" addr="def-003X" title="Dual Space">dual space</fr:link>.
        In our discussion, we only concern the dual space of <fr:tex display="inline">\mathbb {R}^n</fr:tex> which is denoted as <fr:tex display="inline">(\mathbb {R}^n)^*</fr:tex>.
        Now let&apos;s consider the <fr:strong>dual basis</fr:strong> of <fr:tex display="inline">(\mathbb {R}^n)^*</fr:tex> which is denoted as <fr:tex display="inline">\{T_1, \cdots , T_n\}</fr:tex>, 
        which is defined by:
        <fr:tex display="block">             T_i(e_j) = e^i(e_j) = \langle  e^i, e_j \rangle  = \delta _{j}^i         </fr:tex>
        where <fr:tex display="inline">\delta _{ij}</fr:tex> is the <fr:link type="local" href="def-001P.xml" addr="def-001P" title="Kronecker Delta">Kronecker delta</fr:link>. We say that <fr:tex display="inline">T_i</fr:tex> is dual to the vector <fr:tex display="inline">e_i</fr:tex>.
        Note that we also denote <fr:tex display="inline">T_i</fr:tex> as <fr:tex display="inline">e^i</fr:tex> using superscript notation. And the notation <fr:tex display="inline">\langle  e^i, e_j \rangle </fr:tex> d
        indicates the products of row vector <fr:tex display="inline">e^i</fr:tex> and column vector <fr:tex display="inline">e_j</fr:tex> (Usually used in quantum computing).
        <fr:tex display="block">             \alpha (v) = \langle  \alpha , v \rangle  = [a,b] \times  \begin {bmatrix}                 x \\ y             \end {bmatrix} = ax + by         </fr:tex>
        This explains wht we always denote elements of the vector space as column vectors, because elements of the dual space 
        are written as row vectors and its very important to distinguish between them.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>654</fr:anchor>
                <fr:addr type="machine">#313</fr:addr>
                <fr:route>unstable-313.xml</fr:route>
                <fr:title text="Dot Products">Dot Products</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>In linear algebra, <fr:strong>dot product</fr:strong> or <fr:strong>scalar product</fr:strong> is an operation that takes two vectors and returns a scalar.
        Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them.
        Dot product is also used to define lengths and angles.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>655</fr:anchor>
                    <fr:addr type="user">def-0041</fr:addr>
                    <fr:route>def-0041.xml</fr:route>
                    <fr:title text="Dot Product (Coordinate Form)">Dot Product (Coordinate Form)</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>The <fr:strong>dot product</fr:strong> of two vectors <fr:tex display="inline">\vec {a} = (a_1, a_2, \cdots , a_n)</fr:tex> and <fr:tex display="inline">\vec {b} = (b_1, b_2, \cdots , b_n)</fr:tex> is defined as
    <fr:tex display="block">         \vec {a}\cdot \vec {b} = a_1b_1 + a_2b_2 + \cdots  + a_nb_n = \sum _{i=1}^n a_ib_i.     </fr:tex>
    The dot product is also called the <fr:strong>inner product</fr:strong> or <fr:strong>scalar product</fr:strong>.
    The dot product satisfies the following properties:
    <fr:ul><fr:li><fr:strong>Commutative</fr:strong>: <fr:tex display="inline">\vec {a}\cdot \vec {b} = \vec {b}\cdot \vec {a}</fr:tex></fr:li>
        <fr:li><fr:strong>Distributive</fr:strong>: <fr:tex display="inline">\vec {a}\cdot (\vec {b} + \vec {c}) = \vec {a}\cdot \vec {b} + \vec {a}\cdot \vec {c}</fr:tex></fr:li>
        <fr:li><fr:strong>Bilinear</fr:strong>: <fr:tex display="inline">\vec {a}\cdot (k\vec {b}) = k(\vec {a}\cdot \vec {b}) = (\vec {a}\cdot  k\vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Scalar Multiplication</fr:strong>: <fr:tex display="inline">(c_1\vec {a}) \cdot  (c_2\vec {b}) = c_1c_2(\vec {a}\cdot \vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Orthogonality</fr:strong>: If <fr:tex display="inline">\vec {a}\cdot \vec {b} = 0</fr:tex>, then <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> are <fr:strong>orthogonal</fr:strong></fr:li>
        <fr:li><fr:strong>Product Rule</fr:strong>: If <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> are vector valued differentiable functions then the derivative 
            of <fr:tex display="inline">\vec {a}\cdot \vec {b}</fr:tex> is given by the rule <fr:tex display="inline">(\vec {a}\cdot \vec {b})&apos; = \vec {a}&apos;\cdot \vec {b} + \vec {a}\cdot \vec {b}&apos;</fr:tex></fr:li></fr:ul></fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>656</fr:anchor>
                    <fr:addr type="user">def-0042</fr:addr>
                    <fr:route>def-0042.xml</fr:route>
                    <fr:title text="Dot Product (Geometric Form)">Dot Product (Geometric Form)</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>In <fr:strong>Euclidean space</fr:strong>, a <fr:strong>Euclidean vector</fr:strong> is a geometric object that possesses both 
    a norm and a direction. The <fr:strong>dot product</fr:strong> of two vectors <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> is defined as
    <fr:tex display="block">         \vec {a}\cdot \vec {b} = \lVert \vec {a}\rVert \lVert \vec {b}\rVert \cos \theta      </fr:tex>
    where <fr:tex display="inline">\theta </fr:tex> is the angle between the two vectors.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>The geometric definition of dot product helps us express the projection of one vector onto another as well as the component of 
        one vector in the direction of another. By simple geometry we can derive the formula for the <fr:strong>projection</fr:strong>
        <fr:tex display="block">             \text {proj}_{\vec {a}}\vec {b} = \frac {\vec {a}\cdot \vec {b}}{\lVert \vec {a}\rVert }\frac {\vec {a}}{\lVert \vec {a}\rVert }         </fr:tex>
        and the <fr:strong>component</fr:strong> of <fr:tex display="inline">\vec {b}</fr:tex> in the direction <fr:tex display="inline">\vec {a}</fr:tex> is given by
        <fr:tex display="block">             \text {comp}_{\vec {a}}\vec {b} = \lVert \text {proj}_{\vec {a}}\vec {b}\rVert  = \frac {\vec {a}\cdot \vec {b}}{\lVert \vec {a}\rVert }         </fr:tex></fr:p>
                <fr:p>Two points determine a line, and so does a point and a vector. Define the base point vector <fr:tex display="inline">\vec {b}=(x,y,z)</fr:tex> and
        the direction vector <fr:tex display="inline">\vec {v}=(a,b,c)</fr:tex> then the line is given by <fr:tex display="inline">\vec {r}(t)</fr:tex>
        <fr:tex display="block">             \vec {r}(t) = t\vec {v} + \vec {b} = (at+x, bt+y, ct+z)         </fr:tex>
        Solving for <fr:tex display="inline">t</fr:tex> in the equation we get
        <fr:tex display="block">             t = \frac {x-at}{a} = \frac {y-bt}{b} = \frac {z-ct}{c}         </fr:tex>
        which is the <fr:strong>equation of line</fr:strong>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>657</fr:anchor>
                <fr:addr type="machine">#314</fr:addr>
                <fr:route>unstable-314.xml</fr:route>
                <fr:title text="Volume and Determinants">Volume and Determinants</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>The <fr:strong>determinant</fr:strong> has various properties and applications in linear algebra and geometry.
        For us the most useful thing about it will be how it relates to volume:
        the determinant of a matrix gives the <fr:strong>signed volume</fr:strong> of the parallelepiped that 
        is generated by the vectors given by the matrix columns.</fr:p>
                <fr:p>Determinants can be introduced in a variety of different ways but many of them are not at all clear.
        It usually relates to volume hence we will actually use our intuitive understanding of volumes and 
        three properties that we expected volume to have to derive the determinant (It is <fr:strong>uniquely</fr:strong> determined!).</fr:p>
                <fr:p>So how do we expect volume to behave?
        First we expect a unit cube to have a volume of one.
        Second we expect the <fr:strong>degenerate</fr:strong> parallelepiped to have a volume of zero. Basically in <fr:tex display="inline">n</fr:tex> dimensions any 
        <fr:tex display="inline">n-1</fr:tex> dimensions object has zero <fr:tex display="inline">n</fr:tex>-D volume.
        Third we expect that volumes to be <fr:strong>linear</fr:strong>.
        Now with these three properties we move to the actual mathematics.</fr:p>
                <fr:p>Suppose we have a parallelepiped <fr:tex display="inline">\mathscr {P}\in \mathbb {R}^n</fr:tex> whose edges are given by <fr:tex display="inline">v_1, v_2, \cdots , v_n\in \mathbb {R}^n</fr:tex>.
        We sat that the parallelepiped <fr:tex display="inline">\mathscr {P}</fr:tex> is the <fr:strong>span</fr:strong> of the vectors <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> and 
        write <fr:tex display="inline">\mathscr {P}=\text {span}\{v_1, v_2, \cdots , v_n\}</fr:tex> (Note that this span is different from linear span).
        We want to find function <fr:tex display="inline">D:\mathbb {R}^{n\times  n}\to \mathbb {R}</fr:tex> which takes <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> or a matrix with <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> as columns
        to a real number which is the volume of <fr:tex display="inline">\mathscr {P}</fr:tex>. Now we present the three properties in mathematical form.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>658</fr:anchor>
                    <fr:addr type="machine">#315</fr:addr>
                    <fr:route>unstable-315.xml</fr:route>
                    <fr:title text="Properties of Volume">Properties of Volume</fr:title>
                    <fr:date>
                      <fr:year>2024</fr:year>
                      <fr:month>4</fr:month>
                      <fr:day>5</fr:day>
                    </fr:date>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:ul><fr:li><fr:tex display="inline"> D(I) = I </fr:tex> where <fr:tex display="inline">I = [e_1, e_2, \cdots , e_n]</fr:tex> is the identity matrix.</fr:li>
            <fr:li><fr:tex display="inline"> D(v_1, v_2, \cdots , v_n) = 0 </fr:tex> if <fr:tex display="inline">v_i = v_j</fr:tex> for any <fr:tex display="inline">i\neq  j</fr:tex>.</fr:li>
            <fr:li><fr:tex display="inline"> D(v_1, \cdots , v_{j-1}, v+cw, v_{j+1}, \cdots , v_n) \\                  = D(v_1, \cdots , v_{j-1}, v, v_{j+1}, \cdots , v_n) + cD(v_1, \cdots , v_{j-1}, w, v_{j+1}, \cdots , v_n) </fr:tex>
                for any <fr:tex display="inline">1 \leq  j \leq  n</fr:tex>, that is, <fr:tex display="inline">D</fr:tex> is linear.</fr:li></fr:ul>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Now we use these properties of volume to derive several other useful properties.
        The first property is that the volumes are signed.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>659</fr:anchor>
                    <fr:addr type="machine">#316</fr:addr>
                    <fr:route>unstable-316.xml</fr:route>
                    <fr:title text="Derived Properties of Volume Function">Derived Properties of Volume Function</fr:title>
                    <fr:date>
                      <fr:year>2024</fr:year>
                      <fr:month>4</fr:month>
                      <fr:day>5</fr:day>
                    </fr:date>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:ul><fr:li><fr:tex display="inline">D</fr:tex> is alternating, if we switch any two vectors the sign changes.
                <fr:tex display="block">                     D(v_1, \cdots , v_i, \cdots , v_j, \cdots , v_n) = -D(v_1, \cdots , v_j, \cdots , v_i, \cdots , v_n)                 </fr:tex></fr:li> 
            <fr:li>If <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> are <fr:link type="local" href="def-000Q.xml" addr="def-000Q" title="Linearly dependent">linear dependent</fr:link> then
                <fr:tex display="block">                     D(v_1, v_2, \cdots , v_n) = 0                 </fr:tex></fr:li>
            <fr:li>Adding a multiple of one vector to another does not change the determinant.</fr:li></fr:ul>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>We almost ready to derive the formula for determinant. The final ingredient we need to do is <fr:strong>permutations</fr:strong>.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>660</fr:anchor>
                    <fr:addr type="user">def-003Y</fr:addr>
                    <fr:route>def-003Y.xml</fr:route>
                    <fr:title text="Permutation">Permutation</fr:title>
                    <fr:taxon>Defintion</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A <fr:strong>permutation</fr:strong> of a set <fr:tex display="inline">S</fr:tex> is a bijection from <fr:tex display="inline">S</fr:tex> to itself.
    The set of permutation of <fr:tex display="inline">\{1,\cdots , n\}</fr:tex> is usually denoted by <fr:tex display="inline">S_n</fr:tex>.
    We often denote a particular permutation <fr:tex display="inline">\sigma </fr:tex> by <fr:strong>Cauchy&apos;s two-line notation</fr:strong>:
    <fr:tex display="block">         \begin {bmatrix}             1 &amp; 2 &amp; \cdots  &amp; n \\             \sigma (1) &amp; \sigma (2) &amp; \cdots  &amp; \sigma (n)         \end {bmatrix}     </fr:tex>
    or <fr:strong>Cauchy&apos;s one-line notation</fr:strong>: <fr:tex display="inline">(\sigma (1),\sigma (2),\cdots ,\sigma (n))</fr:tex>.
    Another common notation is the <fr:strong>cycle notation</fr:strong>:
    <fr:tex display="block">         (i_1\ i_2\ \cdots \ i_k)     </fr:tex> which means <fr:tex display="inline">i_1 \to  i_2 \to  \cdots  \to  i_k \to  i_1</fr:tex>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>661</fr:anchor>
                    <fr:addr type="user">def-003Z</fr:addr>
                    <fr:route>def-003Z.xml</fr:route>
                    <fr:title text="Transposition">Transposition</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A <fr:link type="local" href="def-003Y.xml" addr="def-003Y" title="Permutation">permutation</fr:link> in which only two elements are exchanged is called a <fr:strong>transposition</fr:strong>.
    The notation is <fr:tex display="inline">\tau _{i,j}</fr:tex> where <fr:tex display="inline">i</fr:tex> and <fr:tex display="inline">j</fr:tex> are the two elements exchanged while the others remain fixed.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Notice that the composition of two permutations is also a permutation. 
        And for any permutation <fr:tex display="inline">\sigma </fr:tex> we can perform a series of transpositions to get the identity permutation.
        It turns out that the count of the number of transpositions needed to get the identity permutation is always the same,
        which is called the <fr:strong>parity</fr:strong> of the permutation.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>662</fr:anchor>
                    <fr:addr type="user">def-0040</fr:addr>
                    <fr:route>def-0040.xml</fr:route>
                    <fr:title text="Sign of Permutation">Sign of Permutation</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>The <fr:strong>sign</fr:strong> of a <fr:link type="local" href="def-003Y.xml" addr="def-003Y" title="Permutation">permutation</fr:link> <fr:tex display="inline">\sigma \in  S_n</fr:tex> is a function <fr:tex display="inline">\text {sgn}:S_n\to \{-1,1\}</fr:tex> defined as
    <fr:tex display="inline">\text {sgn}(\sigma ) = 1</fr:tex> if <fr:tex display="inline">\sigma </fr:tex> requires an even number of permutations and 
    <fr:tex display="inline">\text {sgn}(\sigma ) = -1</fr:tex> if <fr:tex display="inline">\sigma </fr:tex> requires an odd number of permutations to get the identity permutation.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Now we define the permutation of unit vectors <fr:tex display="inline">E_\sigma  = [e_{\sigma (1)}, e_{\sigma (2)}, \cdots , e_{\sigma (n)}]</fr:tex>.
        We got the property that
        <fr:tex display="block">             D(E_\sigma ) = \text {sgn}(\sigma )D(I) = \text {sgn}(\sigma )         </fr:tex>
        Now we have all the pieces necessary to find a formula that will give the volume of the parallelepiped spanned
        by <fr:tex display="inline">n</fr:tex> vectors.
        <fr:tex display="block">             \begin {align*}                 D\left (\begin {bmatrix}                     a_{11} &amp; a_{12} &amp; \cdots  &amp; a_{1n} \\                     a_{21} &amp; a_{22} &amp; \cdots  &amp; a_{2n} \\                     \vdots  &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                     a_{n1} &amp; a_{n2} &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) &amp;= \sum _{i_1=1}^n a_{i_11}D\left (\begin {bmatrix}                     | &amp; a_{12} &amp; \cdots  &amp; a_{1n} \\                     e_{i_1} &amp; a_{22} &amp; \cdots  &amp; a_{2n} \\                     | &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                     | &amp; a_{n2} &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) \\                  &amp;= \sum _{i_1=1}^n a_{i_11} \sum _{i_2=1}^n a_{i_22}D\left (\begin {bmatrix}                     | &amp; | &amp; \cdots  &amp; a_{1n} \\                     e_{i_1} &amp; e_{i_2} &amp; \cdots  &amp; a_{2n} \\                     | &amp; | &amp; \vdots  &amp; \vdots  \\                     | &amp; | &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) \\                 &amp;= \vdots  \\                  &amp;= \sum _{i_1, i_2, \cdots , i_n = 1}^{n} a_{i_11}a_{i_22}\cdots  a_{i_nn}D\left (                     \begin {bmatrix}                         | &amp; | &amp;  &amp; | \\                         e_{i_1} &amp; e_{i_2} &amp; \cdots  &amp; e_{i_n} \\                         | &amp; | &amp;  &amp; | \\                     \end {bmatrix}                 \right ) \\                  &amp;= \sum _{\sigma \in  S_n} a_{\sigma (1)1}\cdots  a_{\sigma (n)n}                 D\left (                     \begin {bmatrix}                         | &amp; | &amp;  &amp; | \\                         e_{\sigma (1)} &amp; e_{\sigma (2)} &amp; \cdots  &amp; e_{\sigma (n)} \\                         | &amp; | &amp;  &amp; | \\                     \end {bmatrix}                 \right ) \\                  &amp;= \sum _{\sigma \in  S_n} a_{\sigma (1)1}a_{\sigma (2)2}\cdots  a_{\sigma (n)n} \text {sgn}(\sigma ) \\                  &amp;= \sum _{\sigma \in  S_n} \text {sgn}(\sigma ) \prod _{i=1}^n a_{\sigma (i)i}             \end {align*}         </fr:tex>
        In the forth step we transform the terms because the value of <fr:tex display="inline">D</fr:tex> is zero for any <fr:tex display="inline">{i_j} = {i_k}</fr:tex>,
        non-zero terms should be permutation of <fr:tex display="inline">S_n</fr:tex>.</fr:p>
                <fr:p>It&apos;s easy to validate that the following properties of the determinant holds:
        <fr:ul><fr:li><fr:tex display="inline">D(AB) = D(A)D(B)</fr:tex></fr:li>
            <fr:li><fr:tex display="inline">D(A) = D(A^T)</fr:tex></fr:li></fr:ul>
        The second statement for transpose of <fr:tex display="inline">A</fr:tex> indicates that all the properties above also holds for row as well.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>663</fr:anchor>
                <fr:addr type="machine">#317</fr:addr>
                <fr:route>unstable-317.xml</fr:route>
                <fr:title text="Derivatives of Multivariable Functions">Derivatives of Multivariable Functions</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>In this section we will introduce the idea of the derivative of a multivariable function. 
        Recall that a function <fr:tex display="inline">f:\mathbb {R}\to \mathbb {R}</fr:tex> the derivative of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">x_0\in \mathbb {R}</fr:tex> is given by
        <fr:tex display="block">             f&apos;(x_0) = \lim _{h\to  0} \frac {f(x_0+h) - f(x_0)}{h}         </fr:tex>
        if the limit exists. Now let&apos;s do some transformations:
        <fr:tex display="block">             \begin {align*}                 &amp; f&apos;(x_0) = \lim _{h\to  0} \frac {f(x_0+h) - f(x_0)}{h} \\                 \implies  &amp; \lim _{h\to  0} \frac {f(x_0+h) - f(x_0) -f&apos;(x_0)h }{h} = 0 \\                 \implies  &amp; \lim _{x\to  x_0} \frac {f(x) - f(x_0) - f&apos;(x_0)(x-x_0)}{x-x_0} = 0 \\                  \implies  &amp; \lim _{x\to  x_0} \frac {|f(x) - f(x_0) - f&apos;(x_0)(x-x_0)|}{|x-x_0|} = 0             \end {align*}         </fr:tex></fr:p>
                <fr:p>Since <fr:tex display="inline">f&apos;(x_0)</fr:tex> represents the slope of the line tangent to the graph of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">(x_0, f(x_0))</fr:tex>,
        differentiability of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">x_0</fr:tex> means that there exists a number <fr:tex display="inline">m</fr:tex> st
        <fr:tex display="block">             \lim _{x\to  x_0} \frac {|f(x) - f(x_0) - m(x-x_0)|}{|x-x_0|} = 0         </fr:tex>
        Now consider the function <fr:tex display="inline">T:\mathbb {R}\to \mathbb {R}</fr:tex> where <fr:tex display="inline">T(s) = ms</fr:tex>
        <fr:tex display="block">             T(s+t) = m(s+t) = ms + mt = T(s) + T(t)             \\              T(cs) = mcs = c(ms) = cT(s)         </fr:tex>
        then <fr:tex display="inline">T</fr:tex> is a linear transformation. In fact <fr:tex display="inline">T</fr:tex> is the linear function that most closely approximates the 
        function <fr:tex display="inline">f</fr:tex> at the point <fr:tex display="inline">(x_0, f(x_0))</fr:tex>. So for <fr:tex display="inline">x</fr:tex> values that are very close to <fr:tex display="inline">x_0</fr:tex> we have
        <fr:tex display="block">             f(x) \approx  m(x-x_0) + f(x_0)         </fr:tex></fr:p>
                <fr:p>Now let&apos;s generalize the concept of derivatives to functions of the form <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}^m</fr:tex>.
        We assume the function <fr:tex display="inline">f</fr:tex> has the form
        <fr:tex display="block">             \begin {align*}                 &amp;f(x_1, x_2, \cdots , x_n) =                  \\                  &amp;(f_1(x_1, x_2, \cdots , x_n), f_2(x_1, x_2, \cdots , x_n), \cdots , f_m(x_1, x_2, \cdots , x_n))             \end {align*}         </fr:tex>
        We want to search for this linear transformation which we will denoted by <fr:tex display="inline">Df</fr:tex>,
        that most closely approximates this function <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> at some specific point <fr:tex display="inline">x_0=(x_{1_0}, x_{2_0}, \cdots , x_{n_0}) \in  \mathbb {R}^n</fr:tex>.
        If <fr:tex display="inline">f</fr:tex> is differentiable at <fr:tex display="inline">x_0</fr:tex> then there exists a linear transformation <fr:tex display="inline">Df(x_0):\mathbb {R}^n\to \mathbb {R}^m</fr:tex> such that
        <fr:tex display="block">             \lim _{x\to  x_0} \frac {                 \lVert                      f(x) - f(x_0) - Df(x_0)(x-x_0)                 \rVert              }{\lVert x-x_0\rVert } = 0         </fr:tex>
        The <fr:tex display="inline">\lVert \cdot \rVert </fr:tex> represents the <fr:strong>Euclidean norm</fr:strong> of the vector (Multi-dimensional version of the absolute value)
        <fr:tex display="block">             \lVert \vec {x}\rVert  = \sqrt {x_1^2 + x_2^2 + \cdots  + x_n^2} = \sqrt {\sum _{i=1}^n x_i^2}         </fr:tex>
        which is just the length of the vector. This allows us to perform dividing.</fr:p>
                <fr:p>As before we have
        <fr:tex display="block">             f(x) \approx  Df(x_0)(x-x_0) + f(x_0)         </fr:tex>
        Now we want to write <fr:tex display="inline">Df(x)</fr:tex> as a matrix. Denote the basis of <fr:tex display="inline">\mathbb {R}^n</fr:tex> as <fr:tex display="inline">e_j</fr:tex> and the basis of <fr:tex display="inline">\mathbb {R}^m</fr:tex> as <fr:tex display="inline">f_i</fr:tex>.
        Then we want to find <fr:tex display="inline">a_{ij}</fr:tex> st
        <fr:tex display="block">             Df(x)(e_j) = \sum _{i=1}^{m} a_{ij} f_j = \begin {bmatrix}                 a_{1j} \\ a_{2j} \\ \vdots  \\ a_{mj}             \end {bmatrix}         </fr:tex>
        In other words, the <fr:tex display="inline">i</fr:tex>-th component of the <fr:tex display="inline">j</fr:tex>-th column of <fr:tex display="inline">Df(x)</fr:tex> is just the <fr:tex display="inline">i</fr:tex>-th component of the <fr:tex display="inline">Df(x)(e_j)</fr:tex></fr:p>
                <fr:p>Recall from vector calculus that given a function <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}</fr:tex> we defined the <fr:strong>partial derivative</fr:strong> of <fr:tex display="inline">f</fr:tex> with respect to the <fr:tex display="inline">x_j</fr:tex> as 
        <fr:tex display="block">             \frac {\partial  f}{\partial  x_j} = \lim _{h\to 0}             \frac {f(x_1,\cdots ,x_j+h,\cdots ,x_n) - f(x_1,\cdots ,x_n)}{h}         </fr:tex>
        Hence we can define the partial derivatives for each <fr:tex display="inline">f_i (1\leq  i\leq  m)</fr:tex> with respect to each <fr:tex display="inline">x_j (1\leq  j\leq  n)</fr:tex>.
        <fr:tex display="block">             \frac {\partial  f_i}{\partial  x_j} = \lim _{h\to 0}             \frac {f_i(x_1,\cdots ,x_j+h,\cdots ,x_n) - f_i(x_1,\cdots ,x_n)}{h}         </fr:tex>
        Thus we have
        <fr:tex display="block">             \frac {\partial  f_i}{\partial  x_j} = a_{ij}         </fr:tex>
        To find <fr:tex display="inline">a_{ij}</fr:tex> of <fr:tex display="inline">Df(x_0)</fr:tex> we need to find the <fr:tex display="inline">i</fr:tex>-th element of <fr:tex display="inline">Df(x_0)(e_j)</fr:tex>. Let
        <fr:tex display="block">             x = \begin {bmatrix}                 x_{1_0} \\ x_{2_0} \\ \vdots  \\ x_{n_0}             \end {bmatrix} + \begin {bmatrix}                 0 \\ \vdots  \\ 1 \\ \vdots  \\ 0             \end {bmatrix} = x_0 + he_j         </fr:tex>
        We have 
        <fr:tex display="block">             \lim _{x\to  x_0}\frac {\lVert f(x)-f(x_0)-Df(x_0)(he_j)\rVert }{\lVert he_j\rVert }             \\ \implies               \lim _{h\to 0}\frac {\lVert                  f(x_0+he_j) - f(x_0) -hDf(x_0)(e_j)             \rVert }{\lVert h\rVert } = 0         </fr:tex>
        The component is given by 
        <fr:tex display="block">             \lim _{h\to 0}\frac {\lVert f_i(x_0+he_j)-f_i(x_0)-ha_{ij}\rVert }{\lVert h\rVert } = 0             \\ \implies               a_{ij} = \lim _{h\to 0}\frac {f_i(x_0+he_j) - f_i(x_0)}{h}         </fr:tex>
        which is exactly <fr:tex display="inline">\frac {\partial  f_i}{\partial  x_j}</fr:tex>. Thus the matrix representation of <fr:tex display="inline">Df(x)</fr:tex> is given by 
        a matrix called the <fr:strong>Jacobin matrix</fr:strong> of <fr:tex display="inline">f</fr:tex>.
        <fr:tex display="block">             Df(x) = \begin {bmatrix}                 \frac {\partial  f_1}{\partial  x_1} &amp; \frac {\partial  f_1}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_1}{\partial  x_n} \\                 \frac {\partial  f_2}{\partial  x_1} &amp; \frac {\partial  f_2}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_2}{\partial  x_n} \\                 \vdots  &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                 \frac {\partial  f_m}{\partial  x_1} &amp; \frac {\partial  f_m}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_m}{\partial  x_n}             \end {bmatrix} = \left [                 \frac {\partial  f_i}{\partial  x_j}             \right ]         </fr:tex>
        where <fr:tex display="inline">i</fr:tex> ranges row and <fr:tex display="inline">j</fr:tex> ranges column.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
          </fr:mainmatter>
          <fr:backmatter></fr:backmatter>
        </fr:tree>
      </fr:mainmatter>
      <fr:backmatter></fr:backmatter>
    </fr:tree>
    <fr:tree toc="false" numbered="false" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
      <fr:frontmatter>
        <fr:title text="Related">Related</fr:title>
        <fr:authors></fr:authors>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="false" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
          <fr:frontmatter>
            <fr:anchor>1850</fr:anchor>
            <fr:addr type="user">def-003Y</fr:addr>
            <fr:route>def-003Y.xml</fr:route>
            <fr:title text="Permutation">Permutation</fr:title>
            <fr:taxon>Defintion</fr:taxon>
            <fr:authors></fr:authors>
          </fr:frontmatter>
          <fr:mainmatter>
            <fr:p>A <fr:strong>permutation</fr:strong> of a set <fr:tex display="inline">S</fr:tex> is a bijection from <fr:tex display="inline">S</fr:tex> to itself.
    The set of permutation of <fr:tex display="inline">\{1,\cdots , n\}</fr:tex> is usually denoted by <fr:tex display="inline">S_n</fr:tex>.
    We often denote a particular permutation <fr:tex display="inline">\sigma </fr:tex> by <fr:strong>Cauchy&apos;s two-line notation</fr:strong>:
    <fr:tex display="block">         \begin {bmatrix}             1 &amp; 2 &amp; \cdots  &amp; n \\             \sigma (1) &amp; \sigma (2) &amp; \cdots  &amp; \sigma (n)         \end {bmatrix}     </fr:tex>
    or <fr:strong>Cauchy&apos;s one-line notation</fr:strong>: <fr:tex display="inline">(\sigma (1),\sigma (2),\cdots ,\sigma (n))</fr:tex>.
    Another common notation is the <fr:strong>cycle notation</fr:strong>:
    <fr:tex display="block">         (i_1\ i_2\ \cdots \ i_k)     </fr:tex> which means <fr:tex display="inline">i_1 \to  i_2 \to  \cdots  \to  i_k \to  i_1</fr:tex>.</fr:p>
          </fr:mainmatter>
          <fr:backmatter></fr:backmatter>
        </fr:tree>
      </fr:mainmatter>
      <fr:backmatter></fr:backmatter>
    </fr:tree>
  </fr:backmatter>
</fr:tree>