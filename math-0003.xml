<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>662</fr:anchor><fr:taxon>Set Theory</fr:taxon><fr:addr>math-0003</fr:addr><fr:route>math-0003.xml</fr:route><fr:title>Set Theory</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    Refer to <fr:link href="cat-sci-2013.xml" type="local" addr="cat-sci-2013">Category Theory for Scientists</fr:link>.
</fr:p><fr:p><fr:strong>Set</fr:strong> is a common concept in mathematics.
    This post is a brief introduction to set theory aimed at 
    complete all basic knowledge of set theory.
    The following topics will be covered
    <fr:ul><fr:li><fr:strong>Zermelo-Fraenkel Axioms</fr:strong> and <fr:strong>Axiom of Choice</fr:strong></fr:li>
        <fr:li>Cardinality</fr:li>
        <fr:li>Set theory constructions</fr:li></fr:ul></fr:p><fr:p>
    In this post, we use the Zermelo-Fraenkel set theory with the Axiom of Choice (<fr:strong>ZFC</fr:strong>).
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>270</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000S</fr:addr><fr:route>def-000S.xml</fr:route><fr:title>ZFC Set</fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:strong>ZFC</fr:strong> is the abbreviation of Zermelo-Fraenkel set theory with the Axiom of Choice.
    The axioms of ZFC are listed below.
    <fr:ul><fr:li><fr:strong>Axiom of Extensionality</fr:strong>:
            Two sets are equal if and only if they have the same elements.
        </fr:li>
        <fr:li><fr:strong>Axiom of Pairing</fr:strong>:
            For any two sets <fr:tex>a</fr:tex> and <fr:tex>b</fr:tex>,
            there exists a set <fr:tex>\{   a,b   \}</fr:tex> whose elements are exactly <fr:tex>a</fr:tex> and <fr:tex>b</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom schema of Separation</fr:strong>:
            Let <fr:tex>P</fr:tex> is a property of sets.
            <fr:tex>P(u)</fr:tex> means <fr:tex>u</fr:tex> satisfies the property <fr:tex>P</fr:tex>.
            then for any set <fr:tex>X</fr:tex> exists <fr:tex>Y =  \{   u  \in  X | P(u)   \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Union</fr:strong>:
            For any set <fr:tex>X</fr:tex> (a family of sets), exists union set <fr:tex>\bigcup  X : \equiv   \{                    u: \exists  v \in  X  \text { such that } u \in  v                \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Power Set</fr:strong>:
            For any set <fr:tex>X</fr:tex>, exists the power <fr:tex>P(X) : \equiv   \{   Y:Y \subseteq  X   \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Infinity</fr:strong>:
            There exists a set <fr:tex>\omega</fr:tex> such that <fr:tex>\emptyset \in \omega</fr:tex> and for any <fr:tex>x \in \omega</fr:tex>, <fr:tex>x \cup \{   x   \} \in \omega</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Regularity</fr:strong>:
            For any non-empty set there is a minimal element with respect to the membership relation.
        </fr:li>
        <fr:li><fr:strong>Axiom schema of Replacement</fr:strong>:
            Let <fr:tex>F</fr:tex> be a function where <fr:tex>\text {dom }  f = X</fr:tex>, then for any set <fr:tex>X</fr:tex> exists a set <fr:tex>Y =  \{   F(x):x \in  X   \}</fr:tex>.
            <fr:p>
                This function is not the normal function but some logical stuff.
            </fr:p></fr:li>
        <fr:li><fr:strong>Axiom of Choice</fr:strong>:
            For any family of non-empty sets <fr:tex>X</fr:tex>, there exists a function <fr:tex>f:X \to \bigcup  X</fr:tex> such that for any <fr:tex>x \in  X</fr:tex>, <fr:tex>f(x) \in  x</fr:tex>.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>275</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002V</fr:addr><fr:route>def-002V.xml</fr:route><fr:title>Set Operations</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>(X_i)_{i \in  I}</fr:tex> be a family of sets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>271</fr:anchor><fr:title>Union</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigcup _{i \in  I}X_i =  \set {x: \exists  i \in  I  \text { such that } x \in  X_i}     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>272</fr:anchor><fr:title>Intersection</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigcap _{i \in  I}X_i =  \set {x: \forall  i \in  I, x \in  X_i}     </fr:tex>
    Note that <fr:tex>I  \neq   \emptyset</fr:tex> here.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>273</fr:anchor><fr:title>Disjoint Union</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigsqcup _{i \in  I}X_i =  \set {(x,i):x \in  X_i, i \in  I}     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>274</fr:anchor><fr:title>Product</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \prod _{i \in  I}X_i =  \set {(x_i)_{i \in  I}: \forall  i \in  I, x_i \in  X_i}     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:p>
    And principles of set theory
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>276</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000T</fr:addr><fr:route>def-000T.xml</fr:route><fr:title>Principle of Extensionality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Two sets are equal if and only if they have the same elements.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>277</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000U</fr:addr><fr:route>def-000U.xml</fr:route><fr:title>Principle of Comprehension</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Given a set <fr:tex>A</fr:tex> and a property <fr:tex>P(x)</fr:tex>, there exists a set <fr:tex>B</fr:tex> such that
    <fr:tex>x \in  B  \iff  x \in  A  \land  P(x)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We then define the Cartesian product of two sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>278</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000V</fr:addr><fr:route>def-000V.xml</fr:route><fr:title>Cartesian product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Given two sets <fr:tex>A</fr:tex> and <fr:tex>B</fr:tex>, the Cartesian product <fr:tex>A \times  B</fr:tex> is the set
    of all ordered pairs <fr:tex>(a,b)</fr:tex> where <fr:tex>a \in  A</fr:tex> and <fr:tex>b \in  B</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    With the Cartesian product, we can define the relation
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>279</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000W</fr:addr><fr:route>def-000W.xml</fr:route><fr:title>Relation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>relation</fr:strong> <fr:tex>R</fr:tex> is a subset of the Cartesian product of two sets <fr:tex>A</fr:tex> and
    <fr:tex>B</fr:tex>, i.e. <fr:tex>R \subseteq  A \times  B</fr:tex>.
    If <fr:tex>(a,b) \in  R</fr:tex>, we write <fr:tex>aRb</fr:tex>.

    A relation that between <fr:tex>X</fr:tex> and itself is called <fr:strong>homogeneous relation</fr:strong>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>280</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000X</fr:addr><fr:route>def-000X.xml</fr:route><fr:title>Equivalence Relation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An equivalence relation <fr:tex>R</fr:tex> on a set <fr:tex>A</fr:tex> is a <fr:link href="def-000W.xml" type="local" addr="def-000W">relation</fr:link> that is reflexive,
    symmetric, and transitive.
    <fr:ul><fr:li>Reflexive:
            <fr:tex>\forall  x \in  A, xRx</fr:tex></fr:li>
        <fr:li>Symmetric:
            <fr:tex>\forall  x,y \in  A, xRy \implies  yRx</fr:tex></fr:li>
        <fr:li>Transitive:
            <fr:tex>\forall  x,y,z \in  A, xRy \land  yRz \implies  xRz</fr:tex></fr:li></fr:ul>
    We often denote the equivalence relation by <fr:tex>\sim</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>281</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002U</fr:addr><fr:route>def-002U.xml</fr:route><fr:title>Equivalence Class</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>\sim</fr:tex> be an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link> on a set <fr:tex>A</fr:tex>.
    For any element <fr:tex>a \in  A</fr:tex>, the <fr:strong>equivalence class</fr:strong> of <fr:tex>a</fr:tex> is the set
    <fr:tex>[a] =  \set {b \in  A:b \sim  a}</fr:tex>.
    The set of all equivalence classes is denoted by <fr:tex>A/ \sim</fr:tex>,
    which is called the <fr:strong>quotient set</fr:strong> of <fr:tex>A</fr:tex> by <fr:tex>\sim</fr:tex>.
    <fr:p>
        The equivalence class of <fr:tex>a</fr:tex> is also denoted by <fr:tex>\overline {a}</fr:tex>.
    </fr:p></fr:p></fr:mainmatter></fr:tree><fr:p>
    One of the most important relations is the order relation.
    The basic order relation is the preorder.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>282</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Z</fr:addr><fr:route>def-000Z.xml</fr:route><fr:title>Preorder</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>preorder</fr:strong> is a relation <fr:tex>\leq</fr:tex> that is reflexive and transitive.
    <fr:ul><fr:li>Reflexive: <fr:tex>a \leq  a</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  c</fr:tex> implies <fr:tex>a \leq  c</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>283</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Y</fr:addr><fr:route>def-000Y.xml</fr:route><fr:title>Partial Order</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>(non-strict) partial order</fr:strong> is a relation <fr:tex>\leq</fr:tex> that is reflexive, antisymmetric and transitive.
    <fr:ul><fr:li>Reflexive: <fr:tex>a \leq  a</fr:tex></fr:li>
        <fr:li>Antisymmetric: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  a</fr:tex> implies <fr:tex>a=b</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  c</fr:tex> implies <fr:tex>a \leq  c</fr:tex></fr:li></fr:ul>
    A non-strict partial order is also known as an antisymmetric <fr:link href="def-000Z.xml" type="local" addr="def-000Z">preorder</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    And the strict partial order (notice the difference between asymmetric and antisymmetric)
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>284</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0010</fr:addr><fr:route>def-0010.xml</fr:route><fr:title>Strict partial orders</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A strict partial order is a relation <fr:tex>&lt;</fr:tex> that is irreflexive, asymmetric and transitive.
    <fr:ul><fr:li>Irreflexive: <fr:tex>\neg (a&lt;a)</fr:tex></fr:li>
        <fr:li>Asymmetric: <fr:tex>a&lt;b</fr:tex> implies <fr:tex>\neg (b&lt;a)</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a&lt;b</fr:tex> and <fr:tex>b&lt;c</fr:tex> implies <fr:tex>a&lt;c</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    With the definition of order, we can define the upper bound and lower bound
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>285</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0011</fr:addr><fr:route>def-0011.xml</fr:route><fr:title>Upper Bound and Lower Bound</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let a subset <fr:tex>S</fr:tex> of a <fr:link href="def-000Y.xml" type="local" addr="def-000Y">partially ordered</fr:link> set <fr:tex>(P,  \leq )</fr:tex>,
    <fr:tex>S</fr:tex> is bounded above if there exists <fr:tex>x  \in  P</fr:tex> such that <fr:tex>\forall  y  \in  S, y  \leq  x</fr:tex>. And <fr:tex>x</fr:tex> is called an <fr:strong>upper bound</fr:strong> of <fr:tex>S</fr:tex>.
    Dually, <fr:tex>S</fr:tex> is bounded below if there exists <fr:tex>x  \in  P</fr:tex> such that <fr:tex>\forall  y  \in  S, x  \leq  y</fr:tex>. And <fr:tex>x</fr:tex> is called a <fr:strong>lower bound</fr:strong> of <fr:tex>S</fr:tex>.
</fr:p>
    <fr:p><fr:strong>Supremum (least upper bound)</fr:strong></fr:p>
    <fr:p>
    An element <fr:tex>x \in  P</fr:tex> is a supremum of <fr:tex>S</fr:tex>,
    if for all upper bounds <fr:tex>z  \in  P</fr:tex> of <fr:tex>S</fr:tex>, <fr:tex>x  \leq  z</fr:tex>.
    Denoted as <fr:tex>x =  \sup  S</fr:tex>.
    </fr:p>
    <fr:p><fr:strong>Infimum (greatest lower bound)</fr:strong></fr:p>
    <fr:p>
    An element <fr:tex>x \in  P</fr:tex> is a infimum of <fr:tex>S</fr:tex>,
    if for all lower bounds <fr:tex>z  \in  P</fr:tex> of <fr:tex>S</fr:tex>, <fr:tex>z  \leq  x</fr:tex>.
    Denoted as <fr:tex>x =  \inf  S</fr:tex>.
    </fr:p>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>286</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002G</fr:addr><fr:route>def-002G.xml</fr:route><fr:title>Function</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets then a <fr:strong>function</fr:strong> <fr:tex>f:X  \to  Y</fr:tex>
    is a mapping that sends each element of <fr:tex>X</fr:tex> to a unique element of <fr:tex>Y</fr:tex>,
    denoted by <fr:tex>f(x) = y</fr:tex>.
    Function is a special case of <fr:link href="def-000W.xml" type="local" addr="def-000W">relation</fr:link>, and it is a relation that is left-total and right-unique.
    <fr:tex display="block">         f  \in  X  \times  Y  \text { and }  \forall  x  \in  X,  \exists ! y  \in  Y, (x,y)  \in  f     </fr:tex>
    <fr:tex>X</fr:tex> is said to be the <fr:strong>domain</fr:strong> of <fr:tex>f</fr:tex> and <fr:tex>Y</fr:tex> is said to be the <fr:strong>codomain</fr:strong> of <fr:tex>f</fr:tex>,
    where we denote <fr:tex>X =  \text {dom }  f</fr:tex> and <fr:tex>Y =  \text {cod }  f</fr:tex>.
</fr:p><fr:p>
    Two functions <fr:tex>f:X \to  Y</fr:tex> and <fr:tex>g:Y \to  Z</fr:tex> can be <fr:strong>composed</fr:strong> to form a new function <fr:tex>g  \circ  f : X  \to  Z</fr:tex>,
    where the composition is defined by
    <fr:tex display="block">         (g  \circ  f)(x) = g(f(x))      </fr:tex></fr:p><fr:p>
    The set of all functions from <fr:tex>X</fr:tex> to <fr:tex>Y</fr:tex> is denoted by <fr:tex>\hom _ \text {set} (X, Y)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The isomorphism function is defined as follows
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>287</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002H</fr:addr><fr:route>def-002H.xml</fr:route><fr:title>Set Isomorphism</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets and <fr:tex>f: X  \to  Y</fr:tex> be a function.
    The function <fr:tex>f</fr:tex> is called an <fr:strong>isomorphism</fr:strong> if it is both <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link> and <fr:link href="def-002F.xml" type="local" addr="def-002F">surjective</fr:link>.
    In other words, there exists a function <fr:tex>g: Y  \to  X</fr:tex> such that
    <fr:tex display="block">         g  \circ  f =  \text {id} _X  \text { and } f  \circ  g =  \text {id} _Y     </fr:tex>
    where <fr:tex>\text {id} _X</fr:tex> and <fr:tex>\text {id} _Y</fr:tex> are the <fr:strong>identity functions</fr:strong> on <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> respectively.
    And we say <fr:tex>f</fr:tex> is <fr:strong>invertible</fr:strong> and <fr:tex>g</fr:tex> is the <fr:strong>inverse</fr:strong> of <fr:tex>f</fr:tex>.
    If there is a isomorphism between <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex>, we say <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> are <fr:strong>isomorphic</fr:strong>,
    denoted by <fr:tex>X  \cong  Y</fr:tex>.
    Isomorphism is an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    With isomorphism, we can define the cardinality of a set.
    Two isomorphic sets have the same cardinality.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>288</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002I</fr:addr><fr:route>def-002I.xml</fr:route><fr:title>Cardinality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> be a set and <fr:tex>n  \in   \mathbb {N}</fr:tex>. 
    <fr:tex>A</fr:tex> si said to have <fr:strong>cardinality</fr:strong> <fr:tex>n</fr:tex>, denoted by <fr:tex> |A|= n</fr:tex>,
    if there exists an isomorphism between <fr:tex>A</fr:tex> and <fr:tex>S_n =  \{   1,2, \cdots ,n   \}</fr:tex>.
    If <fr:tex>A</fr:tex> has finite cardinality, we say <fr:tex>A</fr:tex> is <fr:strong>finite</fr:strong>, otherwise
    we say <fr:tex>A</fr:tex> is <fr:strong>infinite</fr:strong>, denoted by <fr:tex>|A|  \geq   \infty</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next topic is the product of sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>289</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002J</fr:addr><fr:route>def-002J.xml</fr:route><fr:title>Product of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets, then the <fr:strong>Cartesian product</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> is the set
    <fr:tex display="block">         X  \times  Y =  \set {(x,y)  \mid  x  \in  X  \text { and } y  \in  Y}     </fr:tex>
    There are two natural projections from the Cartesian product to the original sets, namely
    <fr:tex display="block">          \pi _1 : X  \times  Y  \to  X  \text { and }  \pi _2 : X  \times  Y  \to  Y     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    This leads to an improtant concept named <fr:strong>universal property</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>290</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000J</fr:addr><fr:route>thm-000J.xml</fr:route><fr:title>Universal Property for Product of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets.
    For any set <fr:tex>A</fr:tex> and function
    <fr:tex>f: A  \to  X</fr:tex> and <fr:tex>g: A  \to  Y</fr:tex>,
    there exists a <fr:em>unique</fr:em> function <fr:tex>h: A  \to  X  \times  Y</fr:tex> such that
    the following diagram commutes:
    
    <fr:embedded-tex hash="4157eb89f51117c585cb94d00d036a56"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; {X \times  Y}  \\ 
            X &amp;&amp; Y  \\ 
            &amp; A
             \arrow [&quot;{ \pi _1}&quot;&apos;, from=1-2, to=2-1]
             \arrow [&quot;{ \pi _2}&quot;, from=1-2, to=2-3]
             \arrow [&quot;f&quot;, from=3-2, to=2-1]
             \arrow [&quot;g&quot;&apos;, from=3-2, to=2-3]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    We might denote the unique function by <fr:tex>\langle  f,g  \rangle : A  \to  X  \times  Y</fr:tex>.
    It is sufficient to define <fr:tex>\langle  f,g  \rangle (a) = (f(a),g(a))</fr:tex> for all <fr:tex>a \in  A</fr:tex> as the unique function.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Dual to the product of sets, we have the coproduct of sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>291</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002K</fr:addr><fr:route>def-002K.xml</fr:route><fr:title>Coproduct of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets, then the <fr:strong>coproduct</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> is 
    defined as the <fr:strong>disjoint union</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex>, denoted by <fr:tex>X  \sqcup  Y</fr:tex>.
    There are two natural injections from the original sets to the coproduct, namely
    <fr:tex display="block">         i_1 : X  \to  X  \sqcup  Y  \text { and } i_2 : Y  \to  X  \sqcup  Y     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>292</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000K</fr:addr><fr:route>thm-000K.xml</fr:route><fr:title>Universal Property for Coproduct of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets. For any set <fr:tex>A</fr:tex> and function
    <fr:tex>f : X  \to  A</fr:tex> and <fr:tex>g : Y  \to  A</fr:tex>, there exists a <fr:em>unique</fr:em> function
    <fr:tex>h : X  \sqcup  Y  \to  A</fr:tex> such that the following diagram commutes:
    
    <fr:embedded-tex hash="31473672edfba5d6215d76dd08a01a24"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; {X \sqcup  Y}
             \arrow [&quot;{i_1}&quot;&apos;, from=2-1, to=3-2]
             \arrow [&quot;{i_2}&quot;, from=2-3, to=3-2]
             \arrow [&quot;f&quot;, from=2-1, to=1-2]
             \arrow [&quot;g&quot;&apos;, from=2-3, to=1-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}   
     
    </fr:embedded-tex-body></fr:embedded-tex>

    We might denote the unique as <fr:tex>f \sqcup  g: X  \sqcup  Y  \to  A</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    In this section we discuss the <fr:em>limits</fr:em> of variously-shaped diagrams of sets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>293</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002L</fr:addr><fr:route>def-002L.xml</fr:route><fr:title>Pullback of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose we have sets <fr:tex>X</fr:tex>, <fr:tex>Y</fr:tex>, and <fr:tex>Z</fr:tex> and functions
    <fr:tex>f : X  \to  Z</fr:tex> and <fr:tex>g : Y  \to  Z</fr:tex>.
    
    <fr:embedded-tex hash="aea0109fc5888410344cbfd1c2bfad2d"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    Its <fr:strong>fiber product</fr:strong> is the set
    <fr:tex display="block">         X  \times _Z Y =  \{   (x,w,y)  \mid  f(x) = w = g(y)   \}      </fr:tex>
    There are obvious projections 
    <fr:tex>          \pi _1 : X  \times _Z Y  \to  X  \text { and }  \pi _2 : X  \times _Z Y  \to  Y     </fr:tex>
    such that the following diagram commutes (<fr:tex>W = X  \times _Z Y</fr:tex>):
    
    <fr:embedded-tex hash="9194755931a1b27a68b010256252d579"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            W &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
             \arrow [&quot;{ \pi _2}&quot;, from=1-1, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;&apos;, from=1-1, to=2-1]
             \arrow [&quot; \lrcorner &quot;{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    The <fr:strong>pullback</fr:strong> is defined to be any set <fr:tex>W  \cong  X \times _Z Y</fr:tex>
    The corner symbol indicates <fr:tex>W</fr:tex> is a <fr:em>pullback</fr:em></fr:p></fr:mainmatter></fr:tree><fr:p>
    The pullback also satisfies the universal property.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>294</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000L</fr:addr><fr:route>thm-000L.xml</fr:route><fr:title>Universal Property for Pullback</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose the given diagram:
    
    <fr:embedded-tex hash="5e6f2da5af96f3d2b5aa340ada59f646"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;t&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;u&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    For any set <fr:tex>A</fr:tex> and commutative solid arrow diagram as below
    (functions <fr:tex>f:A \to  X</fr:tex> and <fr:tex>g:A \to  Y</fr:tex> such that <fr:tex>t \circ  f = u \circ  g</fr:tex>):
    
    <fr:embedded-tex hash="2d3ff6bcdbabe8193a5f90642c805f62"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \usetikzlibrary {arrows}
         \begin {tikzcd}
            &amp; {X \times _ZY}  \\ 
             \\ 
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; Z
             \arrow [&quot;f&quot;&apos;, from=3-2, to=4-1]
             \arrow [&quot;g&quot;, from=3-2, to=4-3]
             \arrow [&quot;t&quot;&apos;, from=4-1, to=5-2]
             \arrow [&quot;u&quot;, from=4-3, to=5-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;&apos;, bend right, from=1-2, to=4-1]
	         \arrow [&quot;{ \pi _2}&quot;, bend left, from=1-2, to=4-3]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    there exists a <fr:em>unique</fr:em> arrow <fr:tex>\langle  f,g  \rangle _Z: A \to  X \times _Z Y</fr:tex> such that
    <fr:tex display="block">          \pi _1 \circ \langle  f,g  \rangle _Z = f  \text { and }  \pi _2 \circ \langle  f,g  \rangle _Z = g     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter><fr:backmatter><fr:contributions></fr:contributions><fr:context><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>661</fr:anchor><fr:addr>notes</fr:addr><fr:route>notes.xml</fr:route><fr:title>Notes</fr:title></fr:frontmatter><fr:mainmatter><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>269</fr:anchor><fr:taxon>Type Theory</fr:taxon><fr:addr>tt-0001</fr:addr><fr:route>tt-0001.xml</fr:route><fr:title>Untyped Lambda Calculus</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    Refer to <fr:link href="ttafp-2014.xml" type="local" addr="ttafp-2014">Type Theory and Formal Proof</fr:link>.
</fr:p><fr:p>
    The idea to generalize the behavior of functions in mathematics and logic led to the development of the lambda calculus.
    The lambda calculus is a formal system for expressing computation based on function abstraction and application using <fr:em>variable binding</fr:em> and <fr:em>substitution</fr:em>. 
    In dealing with functions there are two <fr:strong>construction principles</fr:strong> and one <fr:strong>evalutaion rule</fr:strong>.
    <fr:ul><fr:li><fr:strong>Construction Principles</fr:strong>: note that expressions do not force to be meaningful.</fr:li>
        <fr:ul><fr:li>Function Abstraction: <fr:tex>\lambda  x.M</fr:tex></fr:li>
            <fr:li>Function Application: <fr:tex>M N</fr:tex>, this only produces a new expression,
            in which the function has not yet been executed.</fr:li></fr:ul>
    <fr:li><fr:strong>Evaluation Rule</fr:strong></fr:li>
        <fr:ul><fr:li>Beta Reduction: <fr:tex>( \lambda  x.M)N \to  M[x:=N]</fr:tex></fr:li></fr:ul></fr:ul>
    The beta reduction makes use of the <fr:strong>substitution</fr:strong> <fr:tex>M[x:=N]</fr:tex> which represents the result of replacing all free occurrences of <fr:tex>x</fr:tex> in <fr:tex>M</fr:tex> with <fr:tex>N</fr:tex>.
    Note that the application is <fr:strong>left associative</fr:strong>, that is, <fr:tex>MNP</fr:tex> means <fr:tex>(MN)P</fr:tex>.
    And application has the highest precedence, that is, <fr:tex>\lambda  x.MN</fr:tex> means <fr:tex>\lambda  x.(MN)</fr:tex>.
</fr:p><fr:p>
    The multi-argument function <fr:tex>\lambda  x_1 \ldots  x_n.M</fr:tex> is defined as <fr:tex>\lambda  x_1.( \lambda  x_2.( \ldots ( \lambda  x_n.M) \ldots ))</fr:tex> (right associative),
    that is, simulated by a sequence of single-argument functions. The later function is called <fr:strong>curried function</fr:strong> and the
    process of transforming a multi-argument function into a sequence of single-argument functions is called <fr:strong>currying</fr:strong>.
</fr:p>
    <fr:strong>Lambda Terms</fr:strong>
    <fr:p>Expressions in the lambda calculus is called <fr:strong>terms</fr:strong>. The set of terms is denoted <fr:tex>\Lambda</fr:tex>.</fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>250</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000F</fr:addr><fr:route>def-000F.xml</fr:route><fr:title>Set of Lambda Terms</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
Let <fr:tex>\Lambda</fr:tex> be the set of lambda terms. Then <fr:tex>\Lambda</fr:tex> is defined inductively as follows:
(<fr:tex>V</fr:tex> is the set of variables)
<fr:ul><fr:li>Variable: <fr:tex>\forall  x \in  V, x \in   \Lambda</fr:tex></fr:li>
<fr:li>Abstraction: <fr:tex>\forall  x \in  V, M \in   \Lambda ,  \lambda  x.M \in   \Lambda</fr:tex></fr:li>
<fr:li>Application: <fr:tex>\forall  M,N \in   \Lambda , (MN) \in   \Lambda</fr:tex></fr:li></fr:ul></fr:p><fr:p>
Another way to define <fr:tex>\Lambda</fr:tex> is to use the following grammar (The 3 possibilities are separated by <fr:code>|</fr:code>):
<fr:tex display="block">\Lambda  = V |  \lambda  V. \Lambda  |  \Lambda \Lambda</fr:tex></fr:p></fr:mainmatter></fr:tree>
<fr:p>
    With the following recursive definition we can determine 
    what the <fr:strong>subterms</fr:strong> of a give <fr:tex>\lambda \text {-term}</fr:tex> are. Here we use 
    a concept named <fr:link href="def-0035.xml" type="local" addr="def-0035">multiset</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>251</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0036</fr:addr><fr:route>def-0036.xml</fr:route><fr:title>Multiset of Subterms</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    We define a map <fr:tex>\text {Sub}</fr:tex>:
    <fr:ul><fr:li><fr:strong>Basis</fr:strong>: <fr:tex>\forall  x \in  V, \text {Sub} (x) = \{   x   \}</fr:tex></fr:li>
        <fr:li><fr:strong>Application</fr:strong>: <fr:tex>\forall  M,N \in \Lambda , \text {Sub} (MN) =  \text {Sub} (M) \cup \text {Sub} (N) \cup \{   MN   \}</fr:tex></fr:li>
        <fr:li><fr:strong>Abstraction</fr:strong>: <fr:tex>\forall  x \in  V,M \in \Lambda , \text {Sub} ( \lambda  x.M) =  \text {Sub} (M) \cup \{   \lambda  x.M   \}</fr:tex></fr:li></fr:ul>
    <fr:tex>L</fr:tex> is a subterm of <fr:tex>M</fr:tex> if <fr:tex>L \in \text {Sub} (M)</fr:tex>.
    If <fr:tex>L \not \equiv  M</fr:tex> then we say <fr:tex>L</fr:tex> is a <fr:strong>proper subterm</fr:strong> of <fr:tex>M</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The definition above uses a notation <fr:tex>\equiv</fr:tex> which means <fr:em>syntactic equality</fr:em> here.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>252</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0006</fr:addr><fr:route>eg-0006.xml</fr:route><fr:title>Subterms</fr:title></fr:frontmatter><fr:mainmatter><fr:ul><fr:li><fr:tex>\text {Sub} ( ( x \space z ) )</fr:tex> = <fr:tex>\{   x,z, ( x \space z )   \}</fr:tex></fr:li>
    <fr:li><fr:tex>              \text {Sub} ( \lambda  x. ( x \space x ) )              =  \{   \lambda  x. ( x \space x ) , ( x \space x ) ,x,x   \}          </fr:tex></fr:li></fr:ul></fr:mainmatter></fr:tree><fr:p>
    The substerm mapping satisfies the following lemma.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>253</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000W</fr:addr><fr:route>thm-000W.xml</fr:route><fr:title>Lemma of subterms</fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:ul><fr:li><fr:strong>Reflexivity</fr:strong>: <fr:tex>\forall  M \in \Lambda ,M \in \text {Sub} (M)</fr:tex></fr:li>
        <fr:li><fr:strong>Transitivity</fr:strong>: <fr:tex>\forall  L,M,N \in \Lambda ,L \in \text {Sub} (M) \land  M \in \text {Sub} (N) \implies  L \in \text {Sub} (N)</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    Variable occurrences in a <fr:tex>\lambda \text {-term}</fr:tex> can be divided into 3 categories:
    <fr:ul><fr:li>Bound Occurrences: <fr:tex>x</fr:tex> is bound in <fr:tex>M</fr:tex> if <fr:tex>x</fr:tex> is the argument of an <fr:strong>abstraction</fr:strong> in <fr:tex>M</fr:tex>.</fr:li>
        <fr:li>Free Occurrences: <fr:tex>x</fr:tex> is free in <fr:tex>M</fr:tex> if <fr:tex>x</fr:tex> is not bound by any <fr:strong>abstraction</fr:strong> in <fr:tex>M</fr:tex>.</fr:li>
        <fr:li>Binding Occurrences: something after a lambda notation <fr:tex>\lambda</fr:tex></fr:li></fr:ul>
    We mainly focus on the <fr:strong>free variables</fr:strong> of a term.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>254</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0037</fr:addr><fr:route>def-0037.xml</fr:route><fr:title>Set of Free Variables</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>FV(L)</fr:tex> be the set of free variables in a term <fr:tex>L</fr:tex>.
    <fr:ul><fr:li><fr:strong>Variable</fr:strong>: <fr:tex>\forall  x \in  V, \text {FV} (x) =  \{   x   \}</fr:tex></fr:li>
        <fr:li><fr:strong>Application</fr:strong>: <fr:tex>\forall  M,N \in \Lambda , \text {FV} (MN) =  \text {FV} (M) \cup \text {FV} (N)</fr:tex></fr:li>
        <fr:li><fr:strong>Abstraction</fr:strong>: <fr:tex>\forall  x \in  V,M \in \Lambda , \text {FV} ( \lambda  x.M) =  \text {FV} (M) \setminus \{   x   \}</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>255</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0038</fr:addr><fr:route>def-0038.xml</fr:route><fr:title>Closed Lambda Terms</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:tex>\lambda \text {-term}</fr:tex> <fr:tex>M</fr:tex> is <fr:strong>closed</fr:strong> if <fr:tex>\text {FV} (M) =  \emptyset</fr:tex>.
    A closed <fr:tex>\lambda \text {-term}</fr:tex> is also called a <fr:strong>combinator</fr:strong>.
    The set of all combinators is denoted by <fr:tex>\Lambda ^0</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>256</fr:anchor><fr:title>Alpha conversion</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date><fr:parent>tt-0001</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>Functions in <fr:tex>\lambda \text {-calculus}</fr:tex> have the property that the name of 
    the binding variables is irrelevant.
    In order to describe this equality we need to define a relation
    called <fr:tex>\alpha \text {-conversion}</fr:tex> or <fr:tex>\alpha \text {-equivalence}</fr:tex>,
    which is based on the process of renaming binding variables.</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>257</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0039</fr:addr><fr:route>def-0039.xml</fr:route><fr:title>Renaming</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>M ^{ x \to y }</fr:tex> be the result of replacing all free occurrences of <fr:tex>x</fr:tex> in <fr:tex>M</fr:tex> with <fr:tex>y</fr:tex>.
    The relation <fr:strong>renaming</fr:strong> is expression with the symbol <fr:tex>=_ \alpha</fr:tex>:
    <fr:tex>\lambda  x.M =_ \alpha \lambda  y. M ^{ x \to y }</fr:tex> if <fr:tex>y \not \in \text {FV} (M)</fr:tex> and <fr:tex>y</fr:tex> is not a binding variable in <fr:tex>M</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The definition of <fr:strong>renaming</fr:strong> should be extended to more general terms.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>258</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003A</fr:addr><fr:route>def-003A.xml</fr:route><fr:title>Alpha Equivalence</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:tex>\alpha</fr:tex> equivalence is a relation between <fr:tex>\lambda \text {-term}</fr:tex>, defined as follows:
    <fr:ul><fr:li><fr:strong>Renaming</fr:strong>: <fr:tex>\lambda  x. M  =_ \alpha   \lambda  y.  M ^{ x \to y }</fr:tex> if <fr:tex>y \not \in \text {FV} (M)</fr:tex> and <fr:tex>y</fr:tex> is not a binding variable in <fr:tex>M</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Compatibility</fr:strong>: If <fr:tex>M =_ \alpha  N</fr:tex> then <fr:tex>\lambda  x.M =_ \alpha \lambda  x.N</fr:tex> and <fr:tex>ML  =_ \alpha  NL, LM  =_ \alpha  LN</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Reflexivity</fr:strong>: <fr:tex>M =_ \alpha  M</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Symmetry</fr:strong>: If <fr:tex>M =_ \alpha  N</fr:tex> then <fr:tex>N =_ \alpha  M</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Transitivity</fr:strong>: If <fr:tex>M =_ \alpha  N</fr:tex> and <fr:tex>N =_ \alpha  L</fr:tex> then <fr:tex>M =_ \alpha  L</fr:tex>.
        </fr:li></fr:ul>
    The first principle is the basis of alpha equivalence, which is the same as <fr:link href="def-0039.xml" type="local" addr="def-0039">renaming</fr:link>.
    The last 3 properties ensures that <fr:tex>=_ \alpha</fr:tex> is an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link>.
    
</fr:p><fr:p>
    If <fr:tex>M =_ \alpha  N</fr:tex> then we say <fr:tex>M</fr:tex> and <fr:tex>N</fr:tex> are <fr:tex>\alpha \text {-equivalent}</fr:tex> or <fr:tex>\alpha \text {-convertible}</fr:tex>.
    <fr:tex>M</fr:tex> is an <fr:tex>\alpha \text {-variant}</fr:tex> of <fr:tex>N</fr:tex> and vice versa.

</fr:p></fr:mainmatter></fr:tree><fr:p>
    In previous sections we informally mentioned the concept of <fr:strong>substitution</fr:strong>.
    Now we give a precise formulation
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>259</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003B</fr:addr><fr:route>def-003B.xml</fr:route><fr:title>Substitution</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>substitution</fr:strong> is defined by the following rules:
    <fr:ul><fr:li><fr:tex>M [ x := N ] : \equiv  N</fr:tex></fr:li>
        <fr:li><fr:tex>y [ x := N ] : \equiv  y</fr:tex> if <fr:tex>y \not \equiv  x</fr:tex></fr:li>
        <fr:li><fr:tex>(PQ) [ x := N ] : \equiv ( P [ x := N ] )( Q [ x := N ] )</fr:tex></fr:li>
        <fr:li><fr:tex>( \lambda  y.P) [ x := N ] : \equiv \lambda  z. P ^{ y \to z } [ x := N ]</fr:tex> 
            if <fr:tex>\lambda  z. P ^{ y \to z }   =_ \alpha   \lambda  y.P</fr:tex> and <fr:tex>z \not \in \text {FV} (N)</fr:tex></fr:li></fr:ul>
    The terms with form <fr:tex>P [ x := N ]</fr:tex> are not <fr:tex>\lambda \text {-term}</fr:tex>,
    but we can regard them as a <fr:em>meta notation</fr:em> that appears
    in the substitution process and the result contains no such terms.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Renaming can be considered as a special case of substitution.
    We can show that <fr:tex>M ^{ x \to u } =_ \alpha M [ x := u ]</fr:tex> if the conditions of renaming are satisfied.
</fr:p><fr:p>
    We may do <fr:strong>sequential substitution</fr:strong> in a term,
    that is, doing a number of substitutions consecutively.
    And we have the following lemma, which states that the order of substitution is important.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>260</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000X</fr:addr><fr:route>thm-000X.xml</fr:route><fr:title>Substitution is not commutative</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>x \not \equiv  y</fr:tex> and assume <fr:tex>x \not \in \text {FV} (L)</fr:tex>.
    Then <fr:tex>L[y:=N][x:=M]  \equiv  L[x:=M][y:=N[x:=M]]</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>261</fr:anchor><fr:title><fr:tex>\lambda \text {-term}</fr:tex> modulo <fr:tex>\alpha \text {-equivalence}</fr:tex></fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date><fr:parent>tt-0001</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>As we have seen, the relation <fr:tex>=_ \alpha</fr:tex> is an equivalence relation.
    Hence we can define the set of equivalence classes of terms with respect to <fr:tex>=_ \alpha</fr:tex>.
    Now we can identify a term with its equivalence class.
    We still use <fr:tex>\equiv</fr:tex> for syntactic equality modulo <fr:tex>\alpha \text {-equivalence}</fr:tex>.
    </fr:p></fr:mainmatter></fr:tree><fr:p><fr:tex>\alpha \text {-equivalence}</fr:tex> is a congruence relation, which means that it is conserved by elementary process of term construction.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>262</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000Y</fr:addr><fr:route>thm-000Y.xml</fr:route><fr:title>Congruence Property of Substitution</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>L =_ \alpha  M</fr:tex> and <fr:tex>N =_ \alpha  P</fr:tex>.
    <fr:ul><fr:li><fr:tex>                 LN  =_ \alpha  MP             </fr:tex></fr:li>
        <fr:li><fr:tex>                  \lambda  x.L  =_ \alpha   \lambda  x.M             </fr:tex></fr:li>
        <fr:li><fr:tex>                  L [ x := N ]   =_ \alpha   M [ x := P ]              </fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>263</fr:anchor><fr:title>Barendregt Convention</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date><fr:parent>tt-0001</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>The Barendregt Convention states that we should avoid using the same variable name in different abstractions.
    This is to avoid the confusion of free variables. It states that 
    we choose the names for the binding variables in a <fr:tex>\lambda \text {-term}</fr:tex> in such a manner
    that they are all different, and each of them differs from 
    all free variables occurring in the term.</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>264</fr:anchor><fr:title>Beta Reduction</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date><fr:parent>tt-0001</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Since we have formally defined the <fr:strong>substitution</fr:strong>,
        we can rephrase the reduction as a relation on <fr:tex>\lambda \text {-term}</fr:tex>, namely <fr:tex>\beta \text {-reduction}</fr:tex>.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>265</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003C</fr:addr><fr:route>def-003C.xml</fr:route><fr:title>One Step Beta Reduction</fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:strong>One step beta reduction</fr:strong> (<fr:tex>\to _ \beta</fr:tex>) is defined as follows:
    <fr:ul><fr:li><fr:strong>Basis</fr:strong>:
            <fr:tex>                 ( \lambda  x.M)N \to _ \beta M [ x := N ]              </fr:tex></fr:li>
        <fr:li><fr:strong>Compatibility</fr:strong>:
            If <fr:tex>M \to _ \beta  N</fr:tex> then <fr:tex>\lambda  x.M \to _ \beta \lambda  x.N</fr:tex>,
            <fr:tex>ML \to _ \beta  NL</fr:tex> and <fr:tex>LM \to _ \beta  LN</fr:tex>.
        </fr:li></fr:ul></fr:p><fr:p>
    The term of the form <fr:tex>( \lambda  x.M)N</fr:tex> is called a <fr:strong>redex (reducible expression)</fr:strong>.
    The term of the form <fr:tex>M [ x := N ]</fr:tex> is called the <fr:strong>contractum</fr:strong> (of the redex).
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>266</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0007</fr:addr><fr:route>eg-0007.xml</fr:route><fr:title>Divergent Combinator</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An interesting example named <fr:strong>omega combinator</fr:strong> of beta reduction is the following:
    <fr:tex display="block">          ( ( \lambda  x. ( x \space x ) ) \space ( \lambda  x. ( x \space x ) ) )           \to _ \beta           ( ( \lambda  x. ( x \space x ) ) \space ( \lambda  x. ( x \space x ) ) )      </fr:tex>
    The result of the beta reduction is the same term as the original term,
    and never terminates.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We can often perform a sequence of beta reductions. This leads to the definition.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>267</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003D</fr:addr><fr:route>def-003D.xml</fr:route><fr:title>Beta Reduction</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>(zero-or-more-step) beta reduction</fr:strong> (<fr:tex>\twoheadrightarrow _{ \beta }</fr:tex>) is a
    generalized version of the <fr:link href="def-003C.xml" type="local" addr="def-003C">one step beta reduction</fr:link>.
    <fr:tex>M \twoheadrightarrow _{ \beta }  N</fr:tex> if there exists <fr:tex>n \geq  0</fr:tex> and there are terms <fr:tex>M_0,M_1, \ldots ,M_n</fr:tex>
    such that <fr:tex>M_0=M</fr:tex>, <fr:tex>M_n=N</fr:tex> and <fr:tex>M_i \to _ \beta  M_{i+1}</fr:tex> for <fr:tex>0 \leq  i&lt;n</fr:tex>.
    In other words there exists a chain of one-step beta reductions from <fr:tex>M</fr:tex> to <fr:tex>N</fr:tex>.
    <fr:tex display="block">         M \equiv  M_0 \to _ \beta  M_1 \to _ \beta \cdots \to _ \beta  M_n \equiv  N     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>268</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000Z</fr:addr><fr:route>thm-000Z.xml</fr:route><fr:title>Properties of Beta Reduction</fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:ul><fr:li><fr:strong>Compatibility</fr:strong>:
            <fr:tex>\twoheadrightarrow _{ \beta }</fr:tex> extends <fr:tex>\to _ \beta</fr:tex>, i.e. if <fr:tex>M \to _ \beta  N</fr:tex> then <fr:tex>M \twoheadrightarrow _{ \beta }  N</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Reflixivity</fr:strong>:
            <fr:tex>                 M \twoheadrightarrow _{ \beta }  M             </fr:tex></fr:li>
        <fr:li><fr:strong>Transitivity</fr:strong>:
            <fr:tex>                 M \twoheadrightarrow _{ \beta }  N  \land  N \twoheadrightarrow _{ \beta }  P  \implies  M \twoheadrightarrow _{ \beta }  P             </fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>295</fr:anchor><fr:taxon>Set Theory</fr:taxon><fr:addr>math-0003</fr:addr><fr:route>math-0003.xml</fr:route><fr:title>Set Theory</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    Refer to <fr:link href="cat-sci-2013.xml" type="local" addr="cat-sci-2013">Category Theory for Scientists</fr:link>.
</fr:p><fr:p><fr:strong>Set</fr:strong> is a common concept in mathematics.
    This post is a brief introduction to set theory aimed at 
    complete all basic knowledge of set theory.
    The following topics will be covered
    <fr:ul><fr:li><fr:strong>Zermelo-Fraenkel Axioms</fr:strong> and <fr:strong>Axiom of Choice</fr:strong></fr:li>
        <fr:li>Cardinality</fr:li>
        <fr:li>Set theory constructions</fr:li></fr:ul></fr:p><fr:p>
    In this post, we use the Zermelo-Fraenkel set theory with the Axiom of Choice (<fr:strong>ZFC</fr:strong>).
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>270</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000S</fr:addr><fr:route>def-000S.xml</fr:route><fr:title>ZFC Set</fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:strong>ZFC</fr:strong> is the abbreviation of Zermelo-Fraenkel set theory with the Axiom of Choice.
    The axioms of ZFC are listed below.
    <fr:ul><fr:li><fr:strong>Axiom of Extensionality</fr:strong>:
            Two sets are equal if and only if they have the same elements.
        </fr:li>
        <fr:li><fr:strong>Axiom of Pairing</fr:strong>:
            For any two sets <fr:tex>a</fr:tex> and <fr:tex>b</fr:tex>,
            there exists a set <fr:tex>\{   a,b   \}</fr:tex> whose elements are exactly <fr:tex>a</fr:tex> and <fr:tex>b</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom schema of Separation</fr:strong>:
            Let <fr:tex>P</fr:tex> is a property of sets.
            <fr:tex>P(u)</fr:tex> means <fr:tex>u</fr:tex> satisfies the property <fr:tex>P</fr:tex>.
            then for any set <fr:tex>X</fr:tex> exists <fr:tex>Y =  \{   u  \in  X | P(u)   \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Union</fr:strong>:
            For any set <fr:tex>X</fr:tex> (a family of sets), exists union set <fr:tex>\bigcup  X : \equiv   \{                    u: \exists  v \in  X  \text { such that } u \in  v                \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Power Set</fr:strong>:
            For any set <fr:tex>X</fr:tex>, exists the power <fr:tex>P(X) : \equiv   \{   Y:Y \subseteq  X   \}</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Infinity</fr:strong>:
            There exists a set <fr:tex>\omega</fr:tex> such that <fr:tex>\emptyset \in \omega</fr:tex> and for any <fr:tex>x \in \omega</fr:tex>, <fr:tex>x \cup \{   x   \} \in \omega</fr:tex>.
        </fr:li>
        <fr:li><fr:strong>Axiom of Regularity</fr:strong>:
            For any non-empty set there is a minimal element with respect to the membership relation.
        </fr:li>
        <fr:li><fr:strong>Axiom schema of Replacement</fr:strong>:
            Let <fr:tex>F</fr:tex> be a function where <fr:tex>\text {dom }  f = X</fr:tex>, then for any set <fr:tex>X</fr:tex> exists a set <fr:tex>Y =  \{   F(x):x \in  X   \}</fr:tex>.
            <fr:p>
                This function is not the normal function but some logical stuff.
            </fr:p></fr:li>
        <fr:li><fr:strong>Axiom of Choice</fr:strong>:
            For any family of non-empty sets <fr:tex>X</fr:tex>, there exists a function <fr:tex>f:X \to \bigcup  X</fr:tex> such that for any <fr:tex>x \in  X</fr:tex>, <fr:tex>f(x) \in  x</fr:tex>.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>275</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002V</fr:addr><fr:route>def-002V.xml</fr:route><fr:title>Set Operations</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>(X_i)_{i \in  I}</fr:tex> be a family of sets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>271</fr:anchor><fr:title>Union</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigcup _{i \in  I}X_i =  \set {x: \exists  i \in  I  \text { such that } x \in  X_i}     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>272</fr:anchor><fr:title>Intersection</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigcap _{i \in  I}X_i =  \set {x: \forall  i \in  I, x \in  X_i}     </fr:tex>
    Note that <fr:tex>I  \neq   \emptyset</fr:tex> here.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>273</fr:anchor><fr:title>Disjoint Union</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \bigsqcup _{i \in  I}X_i =  \set {(x,i):x \in  X_i, i \in  I}     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>274</fr:anchor><fr:title>Product</fr:title><fr:parent>def-002V</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">          \prod _{i \in  I}X_i =  \set {(x_i)_{i \in  I}: \forall  i \in  I, x_i \in  X_i}     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:p>
    And principles of set theory
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>276</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000T</fr:addr><fr:route>def-000T.xml</fr:route><fr:title>Principle of Extensionality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Two sets are equal if and only if they have the same elements.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>277</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000U</fr:addr><fr:route>def-000U.xml</fr:route><fr:title>Principle of Comprehension</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Given a set <fr:tex>A</fr:tex> and a property <fr:tex>P(x)</fr:tex>, there exists a set <fr:tex>B</fr:tex> such that
    <fr:tex>x \in  B  \iff  x \in  A  \land  P(x)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We then define the Cartesian product of two sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>278</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000V</fr:addr><fr:route>def-000V.xml</fr:route><fr:title>Cartesian product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Given two sets <fr:tex>A</fr:tex> and <fr:tex>B</fr:tex>, the Cartesian product <fr:tex>A \times  B</fr:tex> is the set
    of all ordered pairs <fr:tex>(a,b)</fr:tex> where <fr:tex>a \in  A</fr:tex> and <fr:tex>b \in  B</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    With the Cartesian product, we can define the relation
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>279</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000W</fr:addr><fr:route>def-000W.xml</fr:route><fr:title>Relation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>relation</fr:strong> <fr:tex>R</fr:tex> is a subset of the Cartesian product of two sets <fr:tex>A</fr:tex> and
    <fr:tex>B</fr:tex>, i.e. <fr:tex>R \subseteq  A \times  B</fr:tex>.
    If <fr:tex>(a,b) \in  R</fr:tex>, we write <fr:tex>aRb</fr:tex>.

    A relation that between <fr:tex>X</fr:tex> and itself is called <fr:strong>homogeneous relation</fr:strong>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>280</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000X</fr:addr><fr:route>def-000X.xml</fr:route><fr:title>Equivalence Relation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An equivalence relation <fr:tex>R</fr:tex> on a set <fr:tex>A</fr:tex> is a <fr:link href="def-000W.xml" type="local" addr="def-000W">relation</fr:link> that is reflexive,
    symmetric, and transitive.
    <fr:ul><fr:li>Reflexive:
            <fr:tex>\forall  x \in  A, xRx</fr:tex></fr:li>
        <fr:li>Symmetric:
            <fr:tex>\forall  x,y \in  A, xRy \implies  yRx</fr:tex></fr:li>
        <fr:li>Transitive:
            <fr:tex>\forall  x,y,z \in  A, xRy \land  yRz \implies  xRz</fr:tex></fr:li></fr:ul>
    We often denote the equivalence relation by <fr:tex>\sim</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>281</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002U</fr:addr><fr:route>def-002U.xml</fr:route><fr:title>Equivalence Class</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>\sim</fr:tex> be an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link> on a set <fr:tex>A</fr:tex>.
    For any element <fr:tex>a \in  A</fr:tex>, the <fr:strong>equivalence class</fr:strong> of <fr:tex>a</fr:tex> is the set
    <fr:tex>[a] =  \set {b \in  A:b \sim  a}</fr:tex>.
    The set of all equivalence classes is denoted by <fr:tex>A/ \sim</fr:tex>,
    which is called the <fr:strong>quotient set</fr:strong> of <fr:tex>A</fr:tex> by <fr:tex>\sim</fr:tex>.
    <fr:p>
        The equivalence class of <fr:tex>a</fr:tex> is also denoted by <fr:tex>\overline {a}</fr:tex>.
    </fr:p></fr:p></fr:mainmatter></fr:tree><fr:p>
    One of the most important relations is the order relation.
    The basic order relation is the preorder.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>282</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Z</fr:addr><fr:route>def-000Z.xml</fr:route><fr:title>Preorder</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>preorder</fr:strong> is a relation <fr:tex>\leq</fr:tex> that is reflexive and transitive.
    <fr:ul><fr:li>Reflexive: <fr:tex>a \leq  a</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  c</fr:tex> implies <fr:tex>a \leq  c</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>283</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Y</fr:addr><fr:route>def-000Y.xml</fr:route><fr:title>Partial Order</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>(non-strict) partial order</fr:strong> is a relation <fr:tex>\leq</fr:tex> that is reflexive, antisymmetric and transitive.
    <fr:ul><fr:li>Reflexive: <fr:tex>a \leq  a</fr:tex></fr:li>
        <fr:li>Antisymmetric: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  a</fr:tex> implies <fr:tex>a=b</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a \leq  b</fr:tex> and <fr:tex>b \leq  c</fr:tex> implies <fr:tex>a \leq  c</fr:tex></fr:li></fr:ul>
    A non-strict partial order is also known as an antisymmetric <fr:link href="def-000Z.xml" type="local" addr="def-000Z">preorder</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    And the strict partial order (notice the difference between asymmetric and antisymmetric)
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>284</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0010</fr:addr><fr:route>def-0010.xml</fr:route><fr:title>Strict partial orders</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A strict partial order is a relation <fr:tex>&lt;</fr:tex> that is irreflexive, asymmetric and transitive.
    <fr:ul><fr:li>Irreflexive: <fr:tex>\neg (a&lt;a)</fr:tex></fr:li>
        <fr:li>Asymmetric: <fr:tex>a&lt;b</fr:tex> implies <fr:tex>\neg (b&lt;a)</fr:tex></fr:li>
        <fr:li>Transitive: <fr:tex>a&lt;b</fr:tex> and <fr:tex>b&lt;c</fr:tex> implies <fr:tex>a&lt;c</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    With the definition of order, we can define the upper bound and lower bound
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>285</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0011</fr:addr><fr:route>def-0011.xml</fr:route><fr:title>Upper Bound and Lower Bound</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let a subset <fr:tex>S</fr:tex> of a <fr:link href="def-000Y.xml" type="local" addr="def-000Y">partially ordered</fr:link> set <fr:tex>(P,  \leq )</fr:tex>,
    <fr:tex>S</fr:tex> is bounded above if there exists <fr:tex>x  \in  P</fr:tex> such that <fr:tex>\forall  y  \in  S, y  \leq  x</fr:tex>. And <fr:tex>x</fr:tex> is called an <fr:strong>upper bound</fr:strong> of <fr:tex>S</fr:tex>.
    Dually, <fr:tex>S</fr:tex> is bounded below if there exists <fr:tex>x  \in  P</fr:tex> such that <fr:tex>\forall  y  \in  S, x  \leq  y</fr:tex>. And <fr:tex>x</fr:tex> is called a <fr:strong>lower bound</fr:strong> of <fr:tex>S</fr:tex>.
</fr:p>
    <fr:p><fr:strong>Supremum (least upper bound)</fr:strong></fr:p>
    <fr:p>
    An element <fr:tex>x \in  P</fr:tex> is a supremum of <fr:tex>S</fr:tex>,
    if for all upper bounds <fr:tex>z  \in  P</fr:tex> of <fr:tex>S</fr:tex>, <fr:tex>x  \leq  z</fr:tex>.
    Denoted as <fr:tex>x =  \sup  S</fr:tex>.
    </fr:p>
    <fr:p><fr:strong>Infimum (greatest lower bound)</fr:strong></fr:p>
    <fr:p>
    An element <fr:tex>x \in  P</fr:tex> is a infimum of <fr:tex>S</fr:tex>,
    if for all lower bounds <fr:tex>z  \in  P</fr:tex> of <fr:tex>S</fr:tex>, <fr:tex>z  \leq  x</fr:tex>.
    Denoted as <fr:tex>x =  \inf  S</fr:tex>.
    </fr:p>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>286</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002G</fr:addr><fr:route>def-002G.xml</fr:route><fr:title>Function</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets then a <fr:strong>function</fr:strong> <fr:tex>f:X  \to  Y</fr:tex>
    is a mapping that sends each element of <fr:tex>X</fr:tex> to a unique element of <fr:tex>Y</fr:tex>,
    denoted by <fr:tex>f(x) = y</fr:tex>.
    Function is a special case of <fr:link href="def-000W.xml" type="local" addr="def-000W">relation</fr:link>, and it is a relation that is left-total and right-unique.
    <fr:tex display="block">         f  \in  X  \times  Y  \text { and }  \forall  x  \in  X,  \exists ! y  \in  Y, (x,y)  \in  f     </fr:tex>
    <fr:tex>X</fr:tex> is said to be the <fr:strong>domain</fr:strong> of <fr:tex>f</fr:tex> and <fr:tex>Y</fr:tex> is said to be the <fr:strong>codomain</fr:strong> of <fr:tex>f</fr:tex>,
    where we denote <fr:tex>X =  \text {dom }  f</fr:tex> and <fr:tex>Y =  \text {cod }  f</fr:tex>.
</fr:p><fr:p>
    Two functions <fr:tex>f:X \to  Y</fr:tex> and <fr:tex>g:Y \to  Z</fr:tex> can be <fr:strong>composed</fr:strong> to form a new function <fr:tex>g  \circ  f : X  \to  Z</fr:tex>,
    where the composition is defined by
    <fr:tex display="block">         (g  \circ  f)(x) = g(f(x))      </fr:tex></fr:p><fr:p>
    The set of all functions from <fr:tex>X</fr:tex> to <fr:tex>Y</fr:tex> is denoted by <fr:tex>\hom _ \text {set} (X, Y)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The isomorphism function is defined as follows
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>287</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002H</fr:addr><fr:route>def-002H.xml</fr:route><fr:title>Set Isomorphism</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets and <fr:tex>f: X  \to  Y</fr:tex> be a function.
    The function <fr:tex>f</fr:tex> is called an <fr:strong>isomorphism</fr:strong> if it is both <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link> and <fr:link href="def-002F.xml" type="local" addr="def-002F">surjective</fr:link>.
    In other words, there exists a function <fr:tex>g: Y  \to  X</fr:tex> such that
    <fr:tex display="block">         g  \circ  f =  \text {id} _X  \text { and } f  \circ  g =  \text {id} _Y     </fr:tex>
    where <fr:tex>\text {id} _X</fr:tex> and <fr:tex>\text {id} _Y</fr:tex> are the <fr:strong>identity functions</fr:strong> on <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> respectively.
    And we say <fr:tex>f</fr:tex> is <fr:strong>invertible</fr:strong> and <fr:tex>g</fr:tex> is the <fr:strong>inverse</fr:strong> of <fr:tex>f</fr:tex>.
    If there is a isomorphism between <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex>, we say <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> are <fr:strong>isomorphic</fr:strong>,
    denoted by <fr:tex>X  \cong  Y</fr:tex>.
    Isomorphism is an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    With isomorphism, we can define the cardinality of a set.
    Two isomorphic sets have the same cardinality.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>288</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002I</fr:addr><fr:route>def-002I.xml</fr:route><fr:title>Cardinality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> be a set and <fr:tex>n  \in   \mathbb {N}</fr:tex>. 
    <fr:tex>A</fr:tex> si said to have <fr:strong>cardinality</fr:strong> <fr:tex>n</fr:tex>, denoted by <fr:tex> |A|= n</fr:tex>,
    if there exists an isomorphism between <fr:tex>A</fr:tex> and <fr:tex>S_n =  \{   1,2, \cdots ,n   \}</fr:tex>.
    If <fr:tex>A</fr:tex> has finite cardinality, we say <fr:tex>A</fr:tex> is <fr:strong>finite</fr:strong>, otherwise
    we say <fr:tex>A</fr:tex> is <fr:strong>infinite</fr:strong>, denoted by <fr:tex>|A|  \geq   \infty</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next topic is the product of sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>289</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002J</fr:addr><fr:route>def-002J.xml</fr:route><fr:title>Product of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets, then the <fr:strong>Cartesian product</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> is the set
    <fr:tex display="block">         X  \times  Y =  \set {(x,y)  \mid  x  \in  X  \text { and } y  \in  Y}     </fr:tex>
    There are two natural projections from the Cartesian product to the original sets, namely
    <fr:tex display="block">          \pi _1 : X  \times  Y  \to  X  \text { and }  \pi _2 : X  \times  Y  \to  Y     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    This leads to an improtant concept named <fr:strong>universal property</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>290</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000J</fr:addr><fr:route>thm-000J.xml</fr:route><fr:title>Universal Property for Product of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets.
    For any set <fr:tex>A</fr:tex> and function
    <fr:tex>f: A  \to  X</fr:tex> and <fr:tex>g: A  \to  Y</fr:tex>,
    there exists a <fr:em>unique</fr:em> function <fr:tex>h: A  \to  X  \times  Y</fr:tex> such that
    the following diagram commutes:
    
    <fr:embedded-tex hash="4157eb89f51117c585cb94d00d036a56"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; {X \times  Y}  \\ 
            X &amp;&amp; Y  \\ 
            &amp; A
             \arrow [&quot;{ \pi _1}&quot;&apos;, from=1-2, to=2-1]
             \arrow [&quot;{ \pi _2}&quot;, from=1-2, to=2-3]
             \arrow [&quot;f&quot;, from=3-2, to=2-1]
             \arrow [&quot;g&quot;&apos;, from=3-2, to=2-3]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    We might denote the unique function by <fr:tex>\langle  f,g  \rangle : A  \to  X  \times  Y</fr:tex>.
    It is sufficient to define <fr:tex>\langle  f,g  \rangle (a) = (f(a),g(a))</fr:tex> for all <fr:tex>a \in  A</fr:tex> as the unique function.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Dual to the product of sets, we have the coproduct of sets
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>291</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002K</fr:addr><fr:route>def-002K.xml</fr:route><fr:title>Coproduct of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets, then the <fr:strong>coproduct</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> is 
    defined as the <fr:strong>disjoint union</fr:strong> of <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex>, denoted by <fr:tex>X  \sqcup  Y</fr:tex>.
    There are two natural injections from the original sets to the coproduct, namely
    <fr:tex display="block">         i_1 : X  \to  X  \sqcup  Y  \text { and } i_2 : Y  \to  X  \sqcup  Y     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>292</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000K</fr:addr><fr:route>thm-000K.xml</fr:route><fr:title>Universal Property for Coproduct of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>X</fr:tex> and <fr:tex>Y</fr:tex> be sets. For any set <fr:tex>A</fr:tex> and function
    <fr:tex>f : X  \to  A</fr:tex> and <fr:tex>g : Y  \to  A</fr:tex>, there exists a <fr:em>unique</fr:em> function
    <fr:tex>h : X  \sqcup  Y  \to  A</fr:tex> such that the following diagram commutes:
    
    <fr:embedded-tex hash="31473672edfba5d6215d76dd08a01a24"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; {X \sqcup  Y}
             \arrow [&quot;{i_1}&quot;&apos;, from=2-1, to=3-2]
             \arrow [&quot;{i_2}&quot;, from=2-3, to=3-2]
             \arrow [&quot;f&quot;, from=2-1, to=1-2]
             \arrow [&quot;g&quot;&apos;, from=2-3, to=1-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}   
     
    </fr:embedded-tex-body></fr:embedded-tex>

    We might denote the unique as <fr:tex>f \sqcup  g: X  \sqcup  Y  \to  A</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    In this section we discuss the <fr:em>limits</fr:em> of variously-shaped diagrams of sets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>293</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002L</fr:addr><fr:route>def-002L.xml</fr:route><fr:title>Pullback of Sets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose we have sets <fr:tex>X</fr:tex>, <fr:tex>Y</fr:tex>, and <fr:tex>Z</fr:tex> and functions
    <fr:tex>f : X  \to  Z</fr:tex> and <fr:tex>g : Y  \to  Z</fr:tex>.
    
    <fr:embedded-tex hash="aea0109fc5888410344cbfd1c2bfad2d"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    Its <fr:strong>fiber product</fr:strong> is the set
    <fr:tex display="block">         X  \times _Z Y =  \{   (x,w,y)  \mid  f(x) = w = g(y)   \}      </fr:tex>
    There are obvious projections 
    <fr:tex>          \pi _1 : X  \times _Z Y  \to  X  \text { and }  \pi _2 : X  \times _Z Y  \to  Y     </fr:tex>
    such that the following diagram commutes (<fr:tex>W = X  \times _Z Y</fr:tex>):
    
    <fr:embedded-tex hash="9194755931a1b27a68b010256252d579"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            W &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
             \arrow [&quot;{ \pi _2}&quot;, from=1-1, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;&apos;, from=1-1, to=2-1]
             \arrow [&quot; \lrcorner &quot;{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    The <fr:strong>pullback</fr:strong> is defined to be any set <fr:tex>W  \cong  X \times _Z Y</fr:tex>
    The corner symbol indicates <fr:tex>W</fr:tex> is a <fr:em>pullback</fr:em></fr:p></fr:mainmatter></fr:tree><fr:p>
    The pullback also satisfies the universal property.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>294</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000L</fr:addr><fr:route>thm-000L.xml</fr:route><fr:title>Universal Property for Pullback</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose the given diagram:
    
    <fr:embedded-tex hash="5e6f2da5af96f3d2b5aa340ada59f646"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;t&quot;&apos;, from=2-1, to=2-2]
             \arrow [&quot;u&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    For any set <fr:tex>A</fr:tex> and commutative solid arrow diagram as below
    (functions <fr:tex>f:A \to  X</fr:tex> and <fr:tex>g:A \to  Y</fr:tex> such that <fr:tex>t \circ  f = u \circ  g</fr:tex>):
    
    <fr:embedded-tex hash="2d3ff6bcdbabe8193a5f90642c805f62"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \usetikzlibrary {arrows}
         \begin {tikzcd}
            &amp; {X \times _ZY}  \\ 
             \\ 
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; Z
             \arrow [&quot;f&quot;&apos;, from=3-2, to=4-1]
             \arrow [&quot;g&quot;, from=3-2, to=4-3]
             \arrow [&quot;t&quot;&apos;, from=4-1, to=5-2]
             \arrow [&quot;u&quot;, from=4-3, to=5-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;&apos;, bend right, from=1-2, to=4-1]
	         \arrow [&quot;{ \pi _2}&quot;, bend left, from=1-2, to=4-3]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>

    there exists a <fr:em>unique</fr:em> arrow <fr:tex>\langle  f,g  \rangle _Z: A \to  X \times _Z Y</fr:tex> such that
    <fr:tex display="block">          \pi _1 \circ \langle  f,g  \rangle _Z = f  \text { and }  \pi _2 \circ \langle  f,g  \rangle _Z = g     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>300</fr:anchor><fr:taxon>Math Analysis</fr:taxon><fr:addr>math-0004</fr:addr><fr:route>math-0004.xml</fr:route><fr:title>The Construction of <fr:tex>\mathbb {R}</fr:tex></fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    We start constructing <fr:tex>\mathbb {R}</fr:tex> from <fr:tex>\mathbb {Q}</fr:tex> by a way that it satisfies the existence theorem,
    the core of construction.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>296</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0003</fr:addr><fr:route>thm-0003.xml</fr:route><fr:title>Existence theorem</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    There exists an ordered field <fr:tex>\mathbb {R}</fr:tex> that satisfies the <fr:link href="def-0012.xml" type="local" addr="def-0012">least upper bound property</fr:link>.
    Moreover <fr:tex>\mathbb {R}</fr:tex> contains <fr:tex>\mathbb {Q}</fr:tex> as a subfield.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The least-upper-bound property mentioned above is defined:
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>297</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0012</fr:addr><fr:route>def-0012.xml</fr:route><fr:title>Least upper bound property</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A set <fr:tex>S</fr:tex> has the least upper bound property if every non-empty subset <fr:tex>T</fr:tex> of <fr:tex>S</fr:tex> that is bounded above has a least upper bound <fr:tex>\sup  T</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Why do we need the least-upper-bound property?
    Consider the set <fr:tex>S =  \{ x  \in   \mathbb {Q} | x^2 &lt; 2 \}</fr:tex>.
    <fr:tex>S</fr:tex> is bounded above by <fr:tex>2</fr:tex>, but it does not have a least upper bound in <fr:tex>\mathbb {Q}</fr:tex>.
    Therefore we can&apos;t express <fr:tex>\sqrt {2}</fr:tex> in field <fr:tex>\mathbb {Q}</fr:tex> since some &quot;gaps&quot; exist.
    This fact motivates us to construct a more complete field <fr:tex>\mathbb {R}</fr:tex>.
    We have constructed <fr:tex>\mathbb {Q}</fr:tex> from <fr:tex>\mathbb {Z}</fr:tex>, and now we construct <fr:tex>\mathbb {R}</fr:tex> from <fr:tex>\mathbb {Q}</fr:tex>.
</fr:p><fr:p>
    Then we should find a way to express &quot;<fr:tex>\sqrt {2}</fr:tex>&quot; using <fr:tex>\mathbb {Q}</fr:tex>.
    A crucial idea is <fr:strong>approximating</fr:strong> <fr:tex>\sqrt {2}</fr:tex> by a sequence of rational numbers.
    <fr:tex display="block">          \sqrt {2} :=  \{  p^2&lt;2  \lor  p&lt;0, p \in \mathbb {Q}  \}      </fr:tex>
    We can cut the number axis into two pieces by <fr:tex>\sqrt {2}</fr:tex>, such cut is called a <fr:strong>Dedekind cut</fr:strong>. 
    A cut should be well-defined rather than just an intuitive concept.
</fr:p><fr:p>
    As we use set theory to construct <fr:tex>\mathbb {R}</fr:tex>, it motivates us to define Dedekind cut as a set.
    It should satisfies some properties:
    <fr:ul><fr:li>Can&apos;t be empty or the whole <fr:tex>\mathbb {Q}</fr:tex></fr:li>
        <fr:li>Closed downward</fr:li>
        <fr:li>Contains not the largest number</fr:li></fr:ul>
    A formal definition is given below:
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>298</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0013</fr:addr><fr:route>def-0013.xml</fr:route><fr:title>Dedekind cuts</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A Dedekind cut is a partition of the rationals <fr:tex>\mathbb {Q}</fr:tex> into two non-empty sets <fr:tex>L</fr:tex> and <fr:tex>R</fr:tex> such that:
    <fr:ul><fr:li><fr:tex>L \neq \emptyset</fr:tex></fr:li>
        <fr:li><fr:tex>R \neq \emptyset</fr:tex></fr:li>
        <fr:li>if <fr:tex>x,y \in \mathbb {Q}, x&lt;y</fr:tex> and <fr:tex>y \in  L</fr:tex> then <fr:tex>x \in  L</fr:tex></fr:li>
        <fr:li>if <fr:tex>p \in  L</fr:tex> then exists <fr:tex>q \in  L</fr:tex> such that <fr:tex>p&lt;q</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can defined the real number as a set of Dedekind cuts.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>299</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0014</fr:addr><fr:route>def-0014.xml</fr:route><fr:title>Real Number System</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The element of <fr:tex>\mathbb {R}</fr:tex> is a <fr:link href="def-0013.xml" type="local" addr="def-0013">Dedekind Cut</fr:link> in <fr:tex>\mathbb {Q}</fr:tex>.
    <fr:tex display="block">          \mathbb {R} :=  \{  L | (L,R)  \text { is a Dedekind Cut}  \}      </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now define the order relation on <fr:tex>\mathbb {R}</fr:tex>.
    We have defined <fr:tex>\mathbb {R}</fr:tex> as the set of Dedekind cuts, so we can define the strict partial order relation <fr:tex>&lt;</fr:tex> on <fr:tex>\mathbb {R}</fr:tex> by the set operation <fr:tex>\subset</fr:tex>.
    The irreflexive, asymmetric and transitive properties are trivial. 
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>305</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0001</fr:addr><fr:route>math-0001.xml</fr:route><fr:title>Introduction to Vector Space</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of vector space.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    The motivation for the definition of a vector space comes from the properties
    of vectors in Euclidean space <fr:tex>\mathbb {R}^n</fr:tex> and <fr:tex>\mathbb {C}^n</fr:tex>.
    The definition abstracts and generalizes these properties.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>301</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000H</fr:addr><fr:route>def-000H.xml</fr:route><fr:title>Vector Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A vector space over a <fr:link href="def-0006.xml" type="local" addr="def-0006">field</fr:link> <fr:tex>F</fr:tex> is a non-empty set <fr:tex>V</fr:tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <fr:tex>V</fr:tex> are commonly called <fr:strong>vectors</fr:strong>, and the elements of <fr:tex>F</fr:tex> are called <fr:strong>scalars</fr:strong>.
    <fr:ul><fr:li>Commutativity: <fr:tex>              \forall  x, y  \in  V, x + y = y + x         </fr:tex></fr:li>
        <fr:li>Associativity: <fr:tex>              \forall  x, y, z  \in  V, (x + y) + z = x + (y + z)         </fr:tex></fr:li>
        <fr:li>Additive Identity: <fr:tex>              \exists  0  \in  V  \text { such that }  \forall  x  \in  V, x + 0 = x         </fr:tex></fr:li>
        <fr:li>Multiplicative Identity: <fr:tex>              \forall  x  \in  V, 1x = x         </fr:tex></fr:li>
        <fr:li>Additive Inverse: <fr:tex>              \forall  x  \in  V,  \exists  y  \in  V  \text { such that } x + y = 0         </fr:tex></fr:li>
        <fr:li>Distributivity: <fr:tex>              \forall  x, y  \in  V,  \forall  c, d  \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx         </fr:tex></fr:li></fr:ul></fr:p><fr:p>
    Elements of a vector space are called <fr:strong>vectors</fr:strong> or <fr:strong>points</fr:strong>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    When dealing with vector spaces, we usually interested only in subspaces.
    And the union of subspaces is rarely a subspace, thus
    we are more interested with sums of subspaces.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>302</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000I</fr:addr><fr:route>def-000I.xml</fr:route><fr:title>Linear Subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A subset <fr:tex>U</fr:tex> of a vector space <fr:tex>V</fr:tex> over a field <fr:tex>F</fr:tex> is called a <fr:strong>subspace</fr:strong> of <fr:tex>V</fr:tex> if <fr:tex>U</fr:tex> is itself a <fr:strong>vector space</fr:strong> over <fr:tex>F</fr:tex> with the operations of addition and scalar multiplication on <fr:tex>V</fr:tex>.
    The subset also satisfies the following axioms (vice versa):
    <fr:ul><fr:li>Additive identity: <fr:tex>0 \in  U</fr:tex></fr:li>
        <fr:li>Closure: <fr:tex>\forall  u,v \in  U, u+v \in  U</fr:tex></fr:li>
        <fr:li>Closed Scalar multiplication: <fr:tex>\forall  u \in  U,  \forall  c \in  F, cu \in  U</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    After that we can define the sum of subsets.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>303</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000J</fr:addr><fr:route>def-000J.xml</fr:route><fr:title>Sum of subsets</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>U_1,  \dots , U_n</fr:tex> be subsets of a vector space <fr:tex>V</fr:tex>.
    The <fr:strong>sum</fr:strong> of <fr:tex>U_1,  \dots , U_n</fr:tex> is defined as
    <fr:tex display="block">U_1 +  \dots  + U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The sum of subspaces is the smallest subspace that contains all the subspaces.
</fr:p><fr:p>
    Every element in <fr:tex>U_1 +  \dots  + U_n</fr:tex> can be written as a sum of elements <fr:tex>u_i</fr:tex> in <fr:tex>U_i</fr:tex>:
    <fr:tex display="block">         u_1+ \cdots +u_n     </fr:tex>
    We will interested in cases where each vector in <fr:tex>U_1 +  \dots  + U_n</fr:tex> can be represented in the form above
    in only one way. This leads to the definition of direct sum.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>304</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000K</fr:addr><fr:route>def-000K.xml</fr:route><fr:title>Direct Sum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>U_1,  \dots , U_n</fr:tex> be subspaces of a vector space <fr:tex>V</fr:tex>.
    The <fr:strong>direct sum</fr:strong> of <fr:tex>U_1,  \dots , U_n</fr:tex> is defined as
    <fr:tex display="block">         U_1  \oplus   \dots   \oplus  U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \}      </fr:tex>
    if every element in <fr:tex>U_1  \oplus   \dots   \oplus  U_n</fr:tex> can be written as <fr:tex>u_1 +  \dots  + u_n </fr:tex> in only one way.
    This definition requires every vector in the sum have a unique representation.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>325</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0002</fr:addr><fr:route>math-0002.xml</fr:route><fr:title>Finite Dimensional Vector Space</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>26</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of finite-dimensional vector space.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    Adding up scalar mulitples of vectors in a list gives a linear combination.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>306</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000L</fr:addr><fr:route>def-000L.xml</fr:route><fr:title>Linear Combination</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a <fr:link href="def-000H.xml" type="local" addr="def-000H">vector space</fr:link> over a field <fr:tex>F</fr:tex>.
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in <fr:tex>V</fr:tex>.
    A <fr:strong>linear combination</fr:strong> of <fr:tex>v_1,  \dots , v_n</fr:tex> is an expression of the form
    <fr:tex display="block">         a_1 v_1 +  \dots  + a_n v_n     </fr:tex>
    where <fr:tex>a_1,  \dots , a_n  \in  F</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    To talk about a structure, we usually define a collection of this structure.
    Hence we have span for linear combinations.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>307</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000M</fr:addr><fr:route>def-000M.xml</fr:route><fr:title>Linear Span</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a vector space over a field <fr:tex>F</fr:tex>.
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in <fr:tex>V</fr:tex>.
    The <fr:strong>span</fr:strong> of <fr:tex>v_1,  \dots , v_n</fr:tex> is defined as
    <fr:tex display="block">          \text {span} (v_1,  \dots , v_n) =  \{ a_1 v_1 +  \dots  + a_n v_n  \mid  a_i  \in  F \}      </fr:tex>
    The span of empty set is defined to be <fr:tex>\{ 0 \}</fr:tex>.    
</fr:p><fr:p>
    If <fr:tex>\text {span} (v_1,  \dots , v_n) = V</fr:tex>, we say that <fr:tex>v_1,  \dots , v_n</fr:tex> <fr:strong>spans</fr:strong> <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Suppose we have span <fr:tex>S= \text {span} (v_1,  \dots , v_n)</fr:tex>. (Span is trivially a subspace.)
    Obviously for all <fr:tex>v_j (1  \leq  j  \leq  n)</fr:tex>, <fr:tex>v_j  \in  S</fr:tex>.
    Because subspaces are closed under scalar multiplication and addition, every
    subspace of <fr:tex>V</fr:tex> containing <fr:tex>v_1,  \dots , v_n</fr:tex> must contain <fr:tex>S</fr:tex>.
    Thus we conclude that <fr:tex>S</fr:tex> is the smallest subspace containing <fr:tex>v_1,  \dots , v_n</fr:tex>.
</fr:p><fr:p>
    The discussion about <fr:strong>spans</fr:strong> leads to a key definition in linear algebra.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>308</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000N</fr:addr><fr:route>def-000N.xml</fr:route><fr:title>Finite-Dimensional Vector Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:link href="def-000H.xml" type="local" addr="def-000H">vector space</fr:link> <fr:tex>V</fr:tex> is called <fr:strong>finite-dimensional</fr:strong> if some <fr:link href="def-000G.xml" type="local" addr="def-000G">list</fr:link> of vectors <fr:tex>v_1,  \dots , v_n</fr:tex> <fr:link href="def-000M.xml" type="local" addr="def-000M">spans</fr:link> <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The opposite of finite-dimensional is infinite-dimensional.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>309</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000O</fr:addr><fr:route>def-000O.xml</fr:route><fr:title>Infinite-dimensional vector space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A vector space <fr:tex>V</fr:tex> is called <fr:strong>infinite-dimensional</fr:strong> if it is not <fr:link href="def-000N.xml" type="local" addr="def-000N">finite-dimensional</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Consider the situation that there is only one way to
    express a vector <fr:tex>v</fr:tex> as a linear combination of vectors in a list <fr:tex>v_1,  \dots , v_n</fr:tex>.
    What property of the list <fr:tex>v_1,  \dots , v_n</fr:tex> does this situation imply? The answer is
    linear independence.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>310</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000P</fr:addr><fr:route>def-000P.xml</fr:route><fr:title>Linearly independent</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A set of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is called <fr:strong>linearly independent</fr:strong> if
    <fr:tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</fr:tex>
    implies that <fr:tex>a_1 =  \dots  = a_n = 0</fr:tex>.
    The trivial case of <fr:tex>\{ 0 \}</fr:tex> is also considered linearly independent.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    If some vectors are not linearly independent, then there are more than one way to
    express a vector as a linear combination of vectors in the list. This leads to 
    the following definition.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>311</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000Q</fr:addr><fr:route>def-000Q.xml</fr:route><fr:title>Linearly dependent</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A set of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is called <fr:strong>linearly dependent</fr:strong> if
    <fr:tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</fr:tex>
    for some <fr:tex>a_1,  \dots , a_n  \in   \mathbb {F}</fr:tex> with at least one <fr:tex>a_i  \neq  0</fr:tex> (not all <fr:tex>0</fr:tex>).
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The following lemma is a direct consequence of the definition of linear independence.
    It states that for a given linearly dependent list, we can always remove a vector
    without changing the span.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>312</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-0001</fr:addr><fr:route>thm-0001.xml</fr:route><fr:title>Linear Dependence Lemma</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1,  \dots , v_n</fr:tex> be vectors in a vector space <fr:tex>V</fr:tex> over a field <fr:tex>\mathbb {F}</fr:tex>.
    If <fr:tex>v_1,  \dots , v_n</fr:tex> are linearly dependent, then there exists <fr:tex>1  \leq  i  \leq  n</fr:tex> such that
    <fr:ul><fr:li><fr:tex>v_i  \in   \text {span} (v_1,  \dots , v_{i-1})</fr:tex></fr:li>
        <fr:li>Remove <fr:tex>v_i</fr:tex> from the list <fr:tex>v_1,  \dots , v_n</fr:tex> and the span does not change</fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>313</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-0002</fr:addr><fr:route>thm-0002.xml</fr:route><fr:title>Length of linearly independent list <fr:tex>\leq</fr:tex> length of spanning list</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    In a finite dimensional vector space, the length of a linearly independent list is less than or equal to the length of a spanning list.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have discussed linear independent lists and spanning lists.
    Now we are ready to define a basis.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>314</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000R</fr:addr><fr:route>def-000R.xml</fr:route><fr:title>Basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A basis of <fr:tex>V</fr:tex> is a list of vectors in <fr:tex>V</fr:tex>
    that is linearly independent and spans <fr:tex>V</fr:tex>. 
</fr:p><fr:p><fr:strong>Criterion for basis</fr:strong>
    A list of vectors <fr:tex>\{ v_1,  \dots , v_n \}</fr:tex> is a basis of <fr:tex>V</fr:tex> if and only if
    every <fr:tex>v  \in  V</fr:tex> can be written <fr:strong>uniquely</fr:strong> as a linear combination of <fr:tex>v_1,  \dots , v_n</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    For instance, we have standard basis <fr:tex>\{ e_1,  \dots , e_n \}</fr:tex> for <fr:tex>\mathbb {F}^n</fr:tex>,
    where <fr:tex>e_i</fr:tex> is the vector with <fr:tex>1</fr:tex> at <fr:tex>i</fr:tex>-th position and <fr:tex>0</fr:tex> elsewhere.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>315</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0005</fr:addr><fr:route>thm-0005.xml</fr:route><fr:title>Spanning List contains a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every spanning list in a vector space can be reduced to a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    From the <fr:link href="thm-0005.xml" type="local" addr="thm-0005">theorem</fr:link> we can infer a corollary.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>316</fr:anchor><fr:taxon>Corollary</fr:taxon><fr:addr>thm-0006</fr:addr><fr:route>thm-0006.xml</fr:route><fr:title>Basis of finite-dimensional vector space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every finite-dimensional vector space has a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next result states for a spanning list can be reduced to a basis.
    We can adjoin one or more vectors to a linearly independent list to form a basis.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>317</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0007</fr:addr><fr:route>thm-0007.xml</fr:route><fr:title>Linearly dependent list extends to a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Every linearly independent list of vectors in  a finite-dimensional vector space can be extended to a basis.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Remind the definition of <fr:link href="der-000K" type="external">direct sum</fr:link>, we can now show that
    every subspace of a finite-dimensional vecrtor space can be paired
    with another subspace to form a direct sum of the whole space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>318</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0008</fr:addr><fr:route>thm-0008.xml</fr:route><fr:title>Direct Sum of Subspaces of <fr:tex>V</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose <fr:tex>V</fr:tex> is a finite dimensional vector space,
    and <fr:tex>U</fr:tex> is a subspace of <fr:tex>V</fr:tex>.
    Then there exists a subspace <fr:tex>W</fr:tex> of <fr:tex>V</fr:tex> such that
    <fr:tex>V = U  \oplus  W</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This post discusses about <fr:em>finite-dimensional vector space</fr:em>.
    But we have not yet defined what is dimension.
    We tempted to define the dimension as the length of basis intuitively.
    With this definition we should prove its well-definedness.
    That is, every basis has the same length.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>319</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0009</fr:addr><fr:route>thm-0009.xml</fr:route><fr:title>Basis length is invariant</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every basis of <fr:tex>V</fr:tex> has the same length.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This can be proved by <fr:link href="thm-0002.xml" type="local" addr="thm-0002">Lemma 8</fr:link>.
    Now we can formally define the dimension of such spaces.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>320</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-001V</fr:addr><fr:route>def-001V.xml</fr:route><fr:title>Dimension</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>dimension</fr:strong> of a finite-dimensional vector space <fr:tex>V</fr:tex> is the length of any basis of the vector space.
    Denoted by <fr:tex>\dim  V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Every subspace of a finite-dimensional vector space is also finite-dimensional.
    Hence we can talk about the dimension of a subspace.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>321</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000A</fr:addr><fr:route>thm-000A.xml</fr:route><fr:title>Dimension of a subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex>U</fr:tex> be a subspace of <fr:tex>V</fr:tex>.
    Then <fr:tex>\dim  U  \leq   \dim  V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    According to the definition of <fr:link href="def-000P.xml" type="local" addr="def-000P">linearly independent</fr:link>,
    to show a list of vectors is a basis, we only need to show it is linearly independent,
    and it spans the whole space.
    The next theorems simplifies the task:
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>322</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000B</fr:addr><fr:route>thm-000B.xml</fr:route><fr:title>Linearly independent list of the right length is a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link href="def-000P.xml" type="local" addr="def-000P">linearly independent</fr:link> list of vectors in <fr:tex>V</fr:tex> with length equal to <fr:tex>\dim  V</fr:tex> is a basis of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>323</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000C</fr:addr><fr:route>thm-000C.xml</fr:route><fr:title>Spanning list of the right length is a basis</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link href="def-000M.xml" type="local" addr="def-000M">spanning</fr:link> list of vectors in <fr:tex>V</fr:tex> with length equal to <fr:tex>\dim  V</fr:tex> is a basis of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we move to the discussion of the dimension of the sum of two subspaces.
    This is analogous to the <fr:link href="thm-000E.xml" type="local" addr="thm-000E">inclusion-exclusion principle</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>324</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000D</fr:addr><fr:route>thm-000D.xml</fr:route><fr:title>Dimension of a sum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex>U</fr:tex> and <fr:tex>W</fr:tex> be subspaces of <fr:tex>V</fr:tex>.
    Then
    <fr:tex display="block">          \dim (U + W) =  \dim  U +  \dim  W -  \dim (U  \cap  W).     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>357</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0005</fr:addr><fr:route>math-0005.xml</fr:route><fr:title>Linear Maps</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>31</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This note introduces the concept of linear maps.
    Refer to <fr:link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015">Linear Algebra Done Right</fr:link>.
</fr:p><fr:p>
    Now we arrive at the main topic of this chapter: linear maps. 
    In classic mathematics, to understand the properties of the structure or space,
    we often study the maps between them.
    For vector spaces we study the <fr:strong>linear maps</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>326</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0025</fr:addr><fr:route>def-0025.xml</fr:route><fr:title>Linear Map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>linear map</fr:strong> is a function between two vector spaces that preserves the operations of addition and scalar multiplication.
    In other words, a function <fr:tex>T: V  \to  W</fr:tex> where <fr:tex>V,W</fr:tex> are vector spaces if the following conditions are satisfied:
    <fr:ul><fr:li>Additivity: <fr:tex>T(u+v) = T(u) + T(v)</fr:tex> for all <fr:tex>u,v  \in  V</fr:tex></fr:li>
        <fr:li>Homogeneity: <fr:tex>T( \alpha  v) =  \alpha  T(v)</fr:tex> for all <fr:tex>\alpha   \in   \mathbb {F}</fr:tex> and <fr:tex>v  \in  V</fr:tex></fr:li></fr:ul>
    Sometimes we ignore the brackets and write <fr:tex>T v</fr:tex> instead of <fr:tex>T(v)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can talk about the set of all linear maps between two vector spaces.
    <fr:tex display="block">          \mathcal {L} (V,W) =  \{    T: V  \to  W | T  \text { is a linear map}   \}      </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>327</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0002</fr:addr><fr:route>eg-0002.xml</fr:route><fr:title>Differentiation is linear map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Define <fr:tex>D \in \mathcal {L} ( \mathcal {P}( \mathbb {R} ), \mathcal {P}( \mathbb {R} ))</fr:tex> (recall that <fr:tex>\mathcal {P}</fr:tex> means <fr:link href="def-0027.xml" type="local" addr="def-0027">set of polynomials</fr:link>) by
    <fr:tex display="block">         D(f) = f&apos;     </fr:tex>
    We can see that <fr:tex>D</fr:tex> a linear map.
    <fr:ul><fr:li>Additivity: <fr:tex>D(f+g) = (f+g)&apos; = f&apos; + g&apos; = D(f) + D(g)</fr:tex></fr:li>
        <fr:li>Homogeneity: <fr:tex>D( \alpha  f) = ( \alpha  f)&apos; =  \alpha  f&apos; =  \alpha  D(f)</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>328</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>eg-0003</fr:addr><fr:route>eg-0003.xml</fr:route><fr:title>Integration is linear map</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be the vector space of all continuous functions on the interval <fr:tex>[a,b]</fr:tex>.
    The map <fr:tex>I: V  \to  V</fr:tex> defined by
    <fr:tex display="block">         I(f) =  \int _a^x f(t) dt     </fr:tex>
    is a <fr:strong>linear map</fr:strong>.
    In other words, <fr:tex>I</fr:tex> preserves the operations of addition and scalar multiplication:
    For all <fr:tex>f,g  \in  V</fr:tex> and all <fr:tex>\alpha   \in   \mathbb {R}</fr:tex>,
    <fr:tex display="block">         I(f+g) = I(f) + I(g)  \quad   \text {and}  \quad  I( \alpha  f) =  \alpha  I(f)     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    We can find a linear map that takes on <fr:em>whatever values we wish</fr:em> on the 
    vectors in a basis by the following theorem.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>329</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000F</fr:addr><fr:route>thm-000F.xml</fr:route><fr:title>Linear maps and basis of domain</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1, v_2,  \ldots , v_n</fr:tex> be a basis of vector space <fr:tex>V</fr:tex>.
    Then for any vector space <fr:tex>W</fr:tex> and any vectors <fr:tex>w_1, w_2,  \ldots , w_n</fr:tex> in <fr:tex>W</fr:tex>,
    there exists a unique linear map <fr:tex>T: V  \to  W</fr:tex> such that
    <fr:tex display="block">         T(v_i) = w_i  \quad   \text {for all}  \quad  i = 1,2, \ldots ,n     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now let&apos;s turn to the algebraic operations over the set of linear maps <fr:tex>\mathcal {L} (V,W)</fr:tex>.
    We begin by defining the addition and scalar multiplication of linear maps.
    This leads to a surprising result: the set of linear maps is actually a vector space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>330</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0029</fr:addr><fr:route>def-0029.xml</fr:route><fr:title>Addition and scalar multiplication over <fr:tex>\mathcal {L} (V,W)</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T_1, T_2  \in   \mathcal {L} (V,W)</fr:tex>.
    We define the <fr:strong>addition</fr:strong> of <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex> as the linear map <fr:tex>T_1 + T_2: V  \to  W</fr:tex> such that
    <fr:tex display="block">         (T_1 + T_2)(v) = T_1(v) + T_2(v)  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    The scalar multiplication of a linear map <fr:tex>T  \in   \mathcal {L} (V,W)</fr:tex> by a scalar <fr:tex>c  \in   \mathbb {F}</fr:tex> is the linear map <fr:tex>cT: V  \to  W</fr:tex> such that
    <fr:tex display="block">         (cT)(v) = cT(v)  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    With these operations, <fr:tex>\mathcal {L} (V,W)</fr:tex> is a <fr:link href="def-000H.xml" type="local" addr="def-000H"><fr:strong>vector space</fr:strong></fr:link> over the field <fr:tex>\mathbb {F}</fr:tex>.
    Note that the additive identity of <fr:tex>\mathcal {L} (V,W)</fr:tex> is the <fr:strong>zero map</fr:strong> <fr:tex>0: V  \to  W</fr:tex> such that
    <fr:tex display="block">         0(v) = 0  \quad   \text {for all}  \quad  v  \in  V     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Usually it makes no sense to multiply two linear maps. But we can define
    an operation called the <fr:strong>product</fr:strong> of linear maps, which is just the composition of the two functions.
    This can form a <fr:strong>monoid</fr:strong> or even a <fr:strong>group</fr:strong> under certain conditions.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>331</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002A</fr:addr><fr:route>def-002A.xml</fr:route><fr:title>Product of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T_1: V  \to  W</fr:tex> and <fr:tex>T_2: W  \to  U</fr:tex> be linear maps.
    We define the <fr:strong>product</fr:strong> of <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex> as the linear map <fr:tex>T_2  \circ  T_1: V  \to  U</fr:tex> such that
    <fr:tex display="block">         (T_2  \circ  T_1)(v) = T_2(T_1(v))  \quad   \text {for all}  \quad  v  \in  V     </fr:tex>
    Note that this is just the composition of the two functions <fr:tex>T_1</fr:tex> and <fr:tex>T_2</fr:tex>. 
    And we usually denote <fr:tex>T_2  \circ  T_1</fr:tex> by <fr:tex>T_2T_1</fr:tex>.
    The product of linear maps is associative, that is,
    <fr:tex display="block">         (T_3  \circ  T_2)  \circ  T_1 = T_3  \circ  (T_2  \circ  T_1)     </fr:tex>
    for any linear maps <fr:tex>T_1: V  \to  W</fr:tex>, <fr:tex>T_2: W  \to  U</fr:tex>, and <fr:tex>T_3: U  \to  X</fr:tex>.
    The identity map <fr:tex>I_V: V  \to  V</fr:tex> is the identity element of the set of linear maps <fr:tex>\mathcal {L} (V,V)</fr:tex> under the product operation.
    That is, for any linear map <fr:tex>T: V  \to  V</fr:tex>,
    <fr:tex display="block">         I_V  \circ  T = T  \circ  I_V = T     </fr:tex>
    where <fr:tex>I_V</fr:tex> is the identity map on <fr:tex>V</fr:tex>.
    The set of all linear maps from a vector space to itself, <fr:tex>\mathcal {L} (V,V)</fr:tex>, forms a <fr:link href="def-0007.xml" type="local" addr="def-0007"><fr:strong>monoid</fr:strong></fr:link> under the product operation.
    The set of all invertible linear maps from a vector space to itself, <fr:tex>\mathcal {L} (V,V)^*</fr:tex>, forms a group under the product operation.
    The identity map is the identity element of the <fr:link href="def-0001.xml" type="local" addr="def-0001"><fr:strong>group</fr:strong></fr:link> <fr:tex>\mathcal {L} (V,V)^*</fr:tex>.
</fr:p><fr:p>
    With addition we also have the distributive law for the product of linear maps.
    That is, for any linear maps <fr:tex>S,S_1,S_2: V  \to  W</fr:tex> and <fr:tex>T,T_1,T_2: U \to  V</fr:tex>:
    <fr:tex display="block">         (S_1 + S_2)T = S_1T + S_2T  \quad   \text {and}  \quad  T(S_1 + S_2) = TS_1 + TS_2     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    In algebra, we have a structure named <fr:strong>kernel</fr:strong>, which is the set of all elements that are mapped to the zero element.
    For linear maps, the kernel is the <fr:strong>null space</fr:strong></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>332</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002C</fr:addr><fr:route>def-002C.xml</fr:route><fr:title>Null Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    For <fr:tex>T: V  \to  W</fr:tex>, the <fr:strong>null space</fr:strong> of <fr:tex>T</fr:tex> is the set of all vectors in <fr:tex>V</fr:tex> that are mapped to <fr:tex>0</fr:tex> in <fr:tex>W</fr:tex>.
    <fr:tex display="block">          \text {null }  T =  \{   v  \in  V | T(v) = 0   \}      </fr:tex>
    The null space of <fr:tex>T</fr:tex> is a subspace of <fr:tex>V</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The injective linear map is defined like normal <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link> functions.
    To check whether a linear map is injective, we can just check whether the null space is trivial.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>333</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000G</fr:addr><fr:route>thm-000G.xml</fr:route><fr:title>Injectivity equivalent to Kernel Triviality</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T: V  \to  W</fr:tex> be a linear map. Then <fr:tex>T</fr:tex> is injective if and only if <fr:tex>\text {null }  T =  \{   0   \}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The image of a linear map is the set of all elements that are mapped to by some element in the domain.
    This is called the <fr:strong>range</fr:strong> of the linear map, just like <fr:link href="def-002E.xml" type="local" addr="def-002E">range</fr:link> of normal function.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>334</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000H</fr:addr><fr:route>thm-000H.xml</fr:route><fr:title>Range is a subspace</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    If <fr:tex>T: V  \to  W</fr:tex> is a linear map, then the range of <fr:tex>T</fr:tex> is a subspace of <fr:tex>W</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    The next theorem plays a crucial role in the study of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>335</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000I</fr:addr><fr:route>thm-000I.xml</fr:route><fr:title>Fundamental Theorems of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> be finite-dimensional vector space and <fr:tex>T : V  \to  W</fr:tex> be a linear map. 
    Then <fr:tex>\text {range }  T</fr:tex> is finite-dimensional and 
    <fr:tex display="block">          \dim  V =  \dim   \text {range }  T +  \dim   \text {null }  T     </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can show that no linear map from a finite-dimensional vector space
    to a <fr:em>smaller</fr:em> (In dimension) vector space can be <fr:link href="def-002D.xml" type="local" addr="def-002D">injective</fr:link>.
    This can be easily proved by the fundamental theorem of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>336</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000M</fr:addr><fr:route>thm-000M.xml</fr:route><fr:title>Map to smaller dimension is not injective</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces, 
    and <fr:tex>\dim  V &gt;  \dim  W</fr:tex>.
    Then no linear map <fr:tex>T:V \to  W</fr:tex> is injective.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Similarly, we can show that no linear map from a finite-dimensional vector space
    to a <fr:em>larger</fr:em> (In dimension) vector space can be <fr:link href="def-002F.xml" type="local" addr="def-002F">surjective</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>337</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000N</fr:addr><fr:route>thm-000N.xml</fr:route><fr:title>Map to bigger dimension is not surjective</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces, 
    and <fr:tex>\dim  V &lt;  \dim  W</fr:tex>.
    Then no linear map <fr:tex>T:V \to  W</fr:tex> is surjective.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    These two lemmas are very important in the study of linear equations.
    The idea here is to express linear equations system in terms of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>338</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0004</fr:addr><fr:route>eg-0004.xml</fr:route><fr:title>Homogeneous Linear Equations System</fr:title></fr:frontmatter><fr:mainmatter><fr:p>Reprase in terms of a linear map the question of whether a <fr:link href="def-002Q.xml" type="local" addr="def-002Q">homogeneous system linear equations</fr:link> has a nonzero solution.</fr:p><fr:p>
        Let <fr:tex>A</fr:tex> be the coefficient matrix of a homogeneous linear system.
        <fr:tex display="block">             A =  \begin {bmatrix}                 a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\                  a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}              \end {bmatrix}         </fr:tex>
        The equation <fr:tex>A \vec {x} =  \vec {0}</fr:tex> has a trivial solution <fr:tex>\vec {x} =  \vec {0}</fr:tex>.
        The question here is whether there is a nontrivial solution.
    </fr:p><fr:p>
        Define <fr:tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</fr:tex> by
        <fr:tex display="block">             T( \vec {x}) = A \vec {x}         </fr:tex>
        Then the question of whether the homogeneous linear system has a nontrivial solution is equivalent to 
        asking <fr:tex>\text {null }  T</fr:tex> is nontrivial.
        That is, <fr:tex>T</fr:tex> is <fr:link href="thm-000G.xml" type="local" addr="thm-000G">not injective</fr:link>.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>339</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000O</fr:addr><fr:route>thm-000O.xml</fr:route><fr:title>Homogeneous system of linear equations</fr:title></fr:frontmatter><fr:mainmatter><fr:p> 
    A homogeneous system of linear equations
    with more variables than equations has 
    a nontrivial solution.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have seen that <fr:link href="thm-000M.xml" type="local" addr="thm-000M">map to smaller dimension is not injective</fr:link>.
    <fr:tex>T</fr:tex> is not injective if <fr:tex>n &gt; m</fr:tex>. This results the theorem above.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>340</fr:anchor><fr:taxon>Example</fr:taxon><fr:addr>eg-0005</fr:addr><fr:route>eg-0005.xml</fr:route><fr:title>Inhomogeneous Linear Equations System</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
        Rephrase in terms of a linear map the question of whether a inhomogeneous system linear equations has no solutions
        for some choice of constant terms.
    </fr:p><fr:p>
    Let <fr:tex>A</fr:tex> be the coefficient matrix of a inhomogeneous linear system.
    <fr:tex display="block">         A =  \begin {bmatrix}             a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\              a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\               \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\              a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}          \end {bmatrix}     </fr:tex>
    The equation <fr:tex>A \vec {x} =  \vec {b}</fr:tex> has a solution <fr:tex>\vec {x} = A^{-1} \vec {b}</fr:tex>.
    </fr:p><fr:p>
        Define <fr:tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</fr:tex> by
        <fr:tex display="block">             T( \vec {x}) = A \vec {x}         </fr:tex>
        Then the statement that inhomogeneous linear system has no solutions is equivalent to 
        <fr:tex>\vec {b}  \not \in   \text {range }  T</fr:tex>.
        Thus the question is rephrased as not having a solution for some choice of <fr:tex>\vec {b}</fr:tex>.
        What condition ensures <fr:tex>T</fr:tex> is not surjective.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>341</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000P</fr:addr><fr:route>thm-000P.xml</fr:route><fr:title>Inhomogeneous system of linear equations</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An inhomogeneous system of linear equations
    with more equations than variables has 
    no solution for some choice of the constant term.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Let <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> be a basis of <fr:tex>V</fr:tex>.
    We know that for any value of a linear map <fr:tex>T:V \to  W</fr:tex>,
    can be determined by values <fr:tex>\{   T(v_1), T(v_2),  \cdots , T(v_n)   \}</fr:tex>.
    This leads to the definition of the matrix representation of a linear map.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>342</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002R</fr:addr><fr:route>def-002R.xml</fr:route><fr:title>Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>m,n \in   \mathbb {Z} ^+</fr:tex>.
    A <fr:tex>m \times  n</fr:tex> matrix is a rectangular array of elements of a field <fr:tex>\mathbb {F}</fr:tex>
    with <fr:tex>m</fr:tex> <fr:strong>rows</fr:strong> and <fr:tex>n</fr:tex> <fr:strong>columns</fr:strong>.
    <fr:tex display="block">         A =  \begin {bmatrix}             a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\              a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\               \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\              a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}          \end {bmatrix}     </fr:tex>
    The notation <fr:tex>A_{jk}</fr:tex> refers to the element in the <fr:tex>j</fr:tex>-th row and <fr:tex>k</fr:tex>-th column.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we can define the matrix representation of a linear map.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>346</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002S</fr:addr><fr:route>def-002S.xml</fr:route><fr:title>Matrix of Linear Maps</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex>\{   v_1, \ldots ,v_n   \} \subset  V</fr:tex> be a basis of <fr:tex>V</fr:tex>,
    and <fr:tex>\{   w_1, \ldots ,w_m   \} \subset  W</fr:tex> be a basis of <fr:tex>W</fr:tex>.
    The <fr:strong>matrix of <fr:tex>T</fr:tex></fr:strong> with respect to these bases is
    the <fr:tex>m \times  n</fr:tex> matrix <fr:tex>\mathcal {M} (T)</fr:tex> such that
    <fr:tex display="block">         T(v_j) =  \sum _{i=1}^m  \mathcal {M} (T)_{ij}w_i     </fr:tex>
    Or we denote <fr:tex>\mathcal {M} (T)</fr:tex> as <fr:tex>\mathcal {M} (T, (v_1, \ldots ,v_n), (w_1, \ldots ,w_m))</fr:tex>.
</fr:p><fr:p>
    If <fr:tex>T</fr:tex> maps <fr:tex>n</fr:tex>-dimensional vector space to <fr:tex>m</fr:tex>-dimensional vector space,
    then <fr:tex>\mathcal {M} (T)</fr:tex> is a <fr:tex>m \times  n</fr:tex> matrix.
</fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>343</fr:anchor><fr:title>
    <fr:strong>Addition</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    For two same-size matrix <fr:tex>A,B</fr:tex>,
    the sum of <fr:tex>A</fr:tex> and <fr:tex>B</fr:tex> is the matrix <fr:tex>C</fr:tex> such that
    <fr:tex display="block">         C_{ij} = A_{ij} + B_{ij}     </fr:tex>
    In the language of linear maps <fr:tex>S,T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex display="block">          \mathcal {M} (T+S) =  \mathcal {M} (T) +  \mathcal {M} (S)     </fr:tex>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>344</fr:anchor><fr:title>
    <fr:strong>Scalar Multiplication</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    For a scalar <fr:tex>c</fr:tex> and a matrix <fr:tex>A</fr:tex>,
    the product of <fr:tex>c</fr:tex> and <fr:tex>A</fr:tex> is the matrix <fr:tex>B</fr:tex> such that
    <fr:tex display="block">         B_{ij} = cA_{ij}     </fr:tex>
    In the language of linear maps <fr:tex>T \in   \mathcal {L} (V,W)</fr:tex>,
    <fr:tex display="block">          \mathcal {M} (cT) = c \mathcal {M} (T)     </fr:tex>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>345</fr:anchor><fr:title>
    <fr:strong>Set of Matrices</fr:strong>
</fr:title><fr:parent>def-002S</fr:parent></fr:frontmatter><fr:mainmatter>
    The set of all <fr:tex>m \times  n</fr:tex> matrices with elements in <fr:tex>\mathbb {F}</fr:tex> is denoted as <fr:tex>\mathcal {M} _{m \times  n}( \mathbb {F} )</fr:tex>
    or <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex>.
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
    We can see that <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex> is itself a vector space.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>347</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000Q</fr:addr><fr:route>thm-000Q.xml</fr:route><fr:title><fr:tex>\dim \mathbb {F} ^{m \times  n} = mn</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p><fr:tex>\mathbb {F} ^{m \times  n}</fr:tex> is a vector space with dimension <fr:tex>mn</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Consider linear maps <fr:tex>T:U \to  V</fr:tex> and <fr:tex>S:V \to  W</fr:tex>.
    The composition of linear maps is <fr:tex>ST</fr:tex>.
    Does the composition of linear maps have a matrix representation?
    <fr:tex display="block">          \mathcal {M} (ST) =  \mathcal {M} (S) \mathcal {M} (T)     </fr:tex>
    This makes no sense now but indicates the definition of <fr:strong>matrix multiplication</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>349</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002T</fr:addr><fr:route>def-002T.xml</fr:route><fr:title>Matrix Multiplication</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be a <fr:tex>m \times  n</fr:tex> matrix and <fr:tex>B</fr:tex> be a <fr:tex>n \times  p</fr:tex> matrix.
    Then <fr:tex>AC</fr:tex> is defined as the <fr:tex>m \times  p</fr:tex> matrix <fr:tex>C</fr:tex> such that
    <fr:tex display="block">         C_{ij} =  \sum _{k=1}^n A_{ik}B_{kj}     </fr:tex></fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>348</fr:anchor><fr:title>
    <fr:strong>Derivation</fr:strong>
</fr:title><fr:parent>def-002T</fr:parent></fr:frontmatter><fr:mainmatter>
    Let <fr:tex>T:U \to  V</fr:tex> and <fr:tex>S:V \to  W</fr:tex> be linear maps.
    Denote <fr:tex>A =  \mathcal {M} (S)</fr:tex> and <fr:tex>C =  \mathcal {M} (T)</fr:tex>.
    Then the composition of linear maps <fr:tex>ST</fr:tex> is computed
    <fr:tex display="block">          \begin {align*}             (ST)(u)_k &amp;= S( \sum _{r=1}^n C_{rk}v_r)  \\              &amp;=  \sum _{r=1}^n C_{rk}S(v_r)  \\              &amp;=  \sum _{r=1}^n C_{rk} \sum _{s=1}^m A _{sr}w_s  \\              &amp;=  \sum _{s=1}^m \left ( \sum _{r=1}^n C_{rk}A_{sr} \right )w_s  \\           \end {align*}     </fr:tex>
    Thus <fr:tex>\mathcal {M} (ST)</fr:tex> is the <fr:tex>m \times  p</fr:tex> whose entries are
    <fr:tex display="block">          \mathcal {M} (ST)_{sk} =  \sum _{r=1}^n A_{sr}C_{rk}     </fr:tex>
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
    Now we see that the desired matrix multiplication holds.
    Matrix multiplication is not commutative in general.
    However, it satisfies the associative law and the distributive law.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>350</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002Y</fr:addr><fr:route>def-002Y.xml</fr:route><fr:title><fr:tex>A_{j \cdot }</fr:tex> and <fr:tex>A_{ \cdot  j}</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be a <fr:tex>m \times  n</fr:tex> matrix.
    <fr:ul><fr:li>
            If <fr:tex>1 \leq  j \leq  m</fr:tex> then <fr:tex>A_{j \cdot }</fr:tex> is the <fr:tex>j</fr:tex>-th row of <fr:tex>A</fr:tex>,
            defined as a <fr:tex>1 \times  n</fr:tex> matrix. (A row vector)
        </fr:li>
        <fr:li>
            If <fr:tex>1 \leq  j \leq  n</fr:tex> then <fr:tex>A_{ \cdot  j}</fr:tex> is the <fr:tex>j</fr:tex>-th column of <fr:tex>A</fr:tex>,
            defined as a <fr:tex>m \times  1</fr:tex> matrix. (A column vector)
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    With the notation we can think of matrix multiplication in another perspective.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>351</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000R</fr:addr><fr:route>thm-000R.xml</fr:route><fr:title>Entry pf matrix product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose <fr:tex>A</fr:tex> is an <fr:tex>m \times  n</fr:tex> matrix and <fr:tex>B</fr:tex> is an <fr:tex>n \times  p</fr:tex> matrix.
    Then the entry of the product <fr:tex>AB</fr:tex> is:
    <fr:tex display="block">         (AB)_{ij} = A_{i \cdot }B_{ \cdot  j}     </fr:tex>
    for <fr:tex>1 \leq  i \leq  m</fr:tex> and <fr:tex>1 \leq  j \leq  p</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We have an interesting observation.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>352</fr:anchor><fr:taxon>Lemma</fr:taxon><fr:addr>thm-000S</fr:addr><fr:route>thm-000S.xml</fr:route><fr:title>Linear Combination of columns</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A</fr:tex> be an <fr:tex>m \times  n</fr:tex> matrix,
    and <fr:tex>c</fr:tex> is a <fr:tex>1 \times  1</fr:tex> matrix.
    <fr:tex display="block">         c =  \begin {pmatrix} c_1  \\  c_2  \\   \vdots   \\  c_n  \end {pmatrix}     </fr:tex>
    Then <fr:tex>Ac = c_1A_{ \cdot  1} + c_2A_{ \cdot  2} +  \cdots  + c_nA_{ \cdot  n}</fr:tex>.
    In other words, <fr:tex>Ac</fr:tex> is a linear Combination of the columns of <fr:tex>A</fr:tex>,
    with the scalars that multiply the columns coming from <fr:tex>c</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Now we begin the study the invertibility of linear maps.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>353</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-002Z</fr:addr><fr:route>def-002Z.xml</fr:route><fr:title>Inverse</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A linear map <fr:tex>T \in \mathcal {L} (V,W)</fr:tex> is said to be <fr:tex>invertible</fr:tex> if 
    there exists a linear map <fr:tex>S \in \mathcal {L} (W,V)</fr:tex> such that:
    <fr:tex display="block">          \begin {align*}             T \cdot  S &amp;=  \text {id} _V  \\              S \cdot  T &amp;=  \text {id} _W          \end {align*}     </fr:tex>
    where <fr:tex>\text {id}</fr:tex> is the identity map.
    If a linear map <fr:tex>T</fr:tex> is invertible, 
    then the map <fr:tex>S</fr:tex> is <fr:strong>unique</fr:strong> and is called the <fr:strong>inverse</fr:strong> of <fr:tex>T</fr:tex>, denoted <fr:tex>T^{-1}</fr:tex>.
</fr:p><fr:p>
    An <fr:strong>isomorphism</fr:strong> is a linear map that is invertible.
    Two vector spaces are said to be <fr:strong>isomorphic</fr:strong> if there exists an isomorphism between them.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    A linear map is invertible if and only if
    it is <fr:strong>bijective</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>354</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000T</fr:addr><fr:route>thm-000T.xml</fr:route><fr:title>Isomorphism of equal dimensions</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Two finite-dimensional vector spaces over <fr:tex>\mathbb {F}</fr:tex>
    are isomorphic iff they have the same <fr:link href="def-001V.xml" type="local" addr="def-001V">dimension</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>355</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-000U</fr:addr><fr:route>thm-000U.xml</fr:route><fr:title><fr:tex>\mathcal {L} (V,W)</fr:tex> is isomorphic to <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>v_1, v_2,  \ldots , v_n</fr:tex> be a basis for <fr:tex>V</fr:tex>,
    and <fr:tex>w_1, w_2,  \ldots , w_m</fr:tex> be a basis for <fr:tex>W</fr:tex>.
    Then <fr:tex>\mathcal {M}</fr:tex> is an isomorphism between <fr:tex>\mathcal {L} (V,W)</fr:tex> and <fr:tex>\mathbb {F} ^{m \times  n}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    This has a trivial corollary.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>356</fr:anchor><fr:taxon>Corollary</fr:taxon><fr:addr>thm-000V</fr:addr><fr:route>thm-000V.xml</fr:route><fr:title>Dimension product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>V</fr:tex> and <fr:tex>W</fr:tex> be finite-dimensional vector spaces.
    Then <fr:tex>\mathcal {L} (V,W)</fr:tex> is finite-dimensional and
    <fr:tex display="block">          \dim ( \mathcal {L} (V,W)) =  \dim (V) \dim (W).     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>367</fr:anchor><fr:taxon>Category Theory</fr:taxon><fr:addr>math-0006</fr:addr><fr:route>math-0006.xml</fr:route><fr:title>Category Theory of Utilitarianism</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    This note is about the category theory and its applications.
    Instead of reading a well-organized book, I prefer to write down the things I learned
    from <fr:link href="ncatlab.xml" type="local" addr="ncatlab">ncatlab</fr:link> and papers.
</fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>358</fr:anchor><fr:title>
    <fr:strong>Ideas</fr:strong></fr:title><fr:parent>math-0006</fr:parent></fr:frontmatter><fr:mainmatter>
        Intuitively, a category is a collection of objects and arrows between them,
        such arrows can be composed and there is an identity arrow for each object.
    <fr:p>
        There are commonly two ways to define a category, which are equivalent in usual 
        foundations of mathematics. One of them generalizes the notion of <fr:strong>internal category</fr:strong>
        nicely while the other one is more convenient for <fr:strong>enriched category</fr:strong>.
    </fr:p>
    <fr:p>
        The major difference is whether they use a single collection of all morphisms or
        several collections of morphisms (<fr:strong>family of collections</fr:strong> indexed by pairs of objects)
    </fr:p>
</fr:mainmatter></fr:tree>
<fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>361</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003E</fr:addr><fr:route>def-003E.xml</fr:route><fr:title>Category</fr:title></fr:frontmatter><fr:mainmatter>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>359</fr:anchor><fr:title><fr:strong>With one collection</fr:strong></fr:title><fr:parent>def-003E</fr:parent></fr:frontmatter><fr:mainmatter>
    A <fr:strong>category</fr:strong> <fr:tex>C</fr:tex> consists
    <fr:ul><fr:li>
            A collection of <fr:strong>objects</fr:strong> <fr:tex>C_0</fr:tex> (<fr:tex>\text {Ob} (C)</fr:tex>).
        </fr:li>
        <fr:li>
            A collection <fr:tex>C_1</fr:tex> (<fr:tex>\text {Mor} (C)</fr:tex>) of <fr:strong>morphisms</fr:strong> (arrows).
        </fr:li>
        <fr:li>
            For every morphism <fr:tex>f</fr:tex> there are an object <fr:tex>s(f)</fr:tex> (<fr:strong>source</fr:strong>, domain) and an object <fr:tex>t(f)</fr:tex> (<fr:strong>target</fr:strong>, codomain).
        </fr:li>
        <fr:li>
            For every pair of morphisms <fr:tex>f, g</fr:tex> such that <fr:tex>t(f) = s(g)</fr:tex>, there is a morphism <fr:tex>g  \circ  f</fr:tex> (<fr:strong>composition</fr:strong>) (Also written <fr:tex>gf</fr:tex> or <fr:tex>f;g</fr:tex>).
        </fr:li>
        <fr:li>
            For every object <fr:tex>x</fr:tex>, there is a morphism <fr:tex>\text {id} _x</fr:tex> (or <fr:tex>1_x</fr:tex>) called <fr:strong>identity</fr:strong>.
        </fr:li>
        <fr:li>
            The following properties hold:
            <fr:ul><fr:li><fr:tex>s(g  \circ  f) = s(f)</fr:tex> and <fr:tex>t(g  \circ  f) = t(g)</fr:tex>.
                </fr:li>
                <fr:li><fr:tex>s(1_x) = x</fr:tex> and <fr:tex>t(1_x) = x</fr:tex>.
                </fr:li>
                <fr:li>
                    Composition is <fr:strong>associative</fr:strong>: <fr:tex>h  \circ  (g  \circ  f) = (h  \circ  g)  \circ  f</fr:tex> when <fr:tex>t(f) = s(g)</fr:tex>, and <fr:tex>t(g) = s(h)</fr:tex>.
                </fr:li>
                <fr:li>
                    Composition satifies the <fr:strong>identity laws</fr:strong>: <fr:tex>f  \circ   \text {id} _x = f</fr:tex> and <fr:tex>\text {id} _y  \circ  f = f</fr:tex></fr:li></fr:ul></fr:li></fr:ul>
    If the identity map and its axioms are omitted then one speaks of a <fr:strong>semicategory</fr:strong>.
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>360</fr:anchor><fr:title><fr:strong>With a family of collections of morphisms</fr:strong></fr:title><fr:parent>def-003E</fr:parent></fr:frontmatter><fr:mainmatter>
    A <fr:strong>category</fr:strong> <fr:tex>C</fr:tex> consists
    <fr:ul><fr:li>
            A collection of <fr:strong>objects</fr:strong> <fr:tex>C_0</fr:tex> (<fr:tex>\text {Ob} (C)</fr:tex>).
        </fr:li>
        <fr:li>
            For every pair of objects <fr:tex>x, y</fr:tex>, a collection <fr:tex>C_1(x, y)</fr:tex> (<fr:tex>\hom _C(x,y)</fr:tex>) of <fr:strong>morphisms</fr:strong> from <fr:tex>x</fr:tex> to <fr:tex>y</fr:tex>.
        </fr:li>
        <fr:li>
            For each pair of morphisms <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex> and <fr:tex>g</fr:tex> in <fr:tex>C_1(y,z)</fr:tex>, a morphism <fr:tex>g  \circ  f</fr:tex> in <fr:tex>C_1(x,z)</fr:tex>.
            called their <fr:strong>composition</fr:strong>.
        </fr:li>
        <fr:li>
            For each object <fr:tex>x</fr:tex>, a morphism <fr:tex>\text {id} _x</fr:tex> in <fr:tex>C_1(x,x)</fr:tex> called the <fr:strong>identity</fr:strong> on <fr:tex>x</fr:tex>.
        </fr:li>
        <fr:li>
            The following properties hold:
            <fr:ul><fr:li>Composition is <fr:strong>associative</fr:strong>: <fr:tex>h  \circ  (g  \circ  f) = (h  \circ  g)  \circ  f</fr:tex> for all <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex>, <fr:tex>g</fr:tex> in <fr:tex>C_1(y,z)</fr:tex>, and <fr:tex>h</fr:tex> in <fr:tex>C_1(z,w)</fr:tex>.</fr:li>
                <fr:li>Composition satifies the <fr:strong>identity laws</fr:strong>: <fr:tex>f  \circ   \text {id} _x = f</fr:tex> and <fr:tex>\text {id} _y  \circ  f = f</fr:tex> for all <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex>.</fr:li></fr:ul></fr:li></fr:ul>
    Usually we write <fr:tex>\text {Mor} (C)</fr:tex> for the disjoint union <fr:tex>\bigsqcup _{x,y  \in  C_0} C_1(x,y)</fr:tex>.
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
    Its common to talk about some objects and their morphisms.
    Informally, a <fr:strong>diagram</fr:strong> in a category <fr:tex>C</fr:tex> consists of some 
    objects of <fr:tex>C</fr:tex> connected by some morphisms of <fr:tex>C</fr:tex>.
</fr:p><fr:p>
    This terminology is often used when speaking about <fr:strong>limits</fr:strong> or 
    <fr:strong>colimits</fr:strong> of a diagram.
</fr:p><fr:p>
    One formal way to define a diagram is to use a <fr:strong>functor</fr:strong> from a (very) small category to <fr:tex>C</fr:tex>.
    That is, a functor whose domain is a small category.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>362</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003F</fr:addr><fr:route>def-003F.xml</fr:route><fr:title>Small Category</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:link href="def-003E.xml" type="local" addr="def-003E">category</fr:link> is said to be <fr:strong>small</fr:strong> 
    if it has a <fr:strong>samll set</fr:strong> (i.e. a set but not a proper class) of objects and morphisms.
    In other words a small category is an <fr:strong>internal category</fr:strong> in category of sets.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    We did not explain what a <fr:strong>functor</fr:strong> is, but it is very natural thought.
    Briefly, a functor is a <fr:strong>homomorphism</fr:strong> between two categories.
    It maps objects to objects and morphisms to morphisms, preserving the structure of the categories.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>363</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003G</fr:addr><fr:route>def-003G.xml</fr:route><fr:title>Functor</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>functor</fr:strong> <fr:tex>F</fr:tex> from a category <fr:tex>C</fr:tex> to a category <fr:tex>D</fr:tex> is a map
    sending each <fr:tex>x \in  C</fr:tex> to an object <fr:tex>F(x) \in  D</fr:tex> and each morphism
    <fr:tex>f:x \to  y</fr:tex> in <fr:tex>C</fr:tex> to morphism <fr:tex>F(f):F(x) \to  F(y)</fr:tex> in <fr:tex>D</fr:tex>, such that 
    <fr:ul><fr:li>
            Composition is preserved: <fr:tex>F(g \circ  f) = F(g) \circ  F(f)</fr:tex>.
        </fr:li>
        <fr:li>
            Identity is preserved: <fr:tex>F( \text {id} _x) =  \text {id} _{F(x)}</fr:tex>.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    For the sake of completeness, we state the definition of the <fr:strong>functor category</fr:strong>
    and the <fr:strong>natural transformations</fr:strong> between functors.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>364</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003I</fr:addr><fr:route>def-003I.xml</fr:route><fr:title>Functor Category</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>C</fr:tex> and <fr:tex>D</fr:tex> be categories, the functor category <fr:tex>D^C</fr:tex> 
    (or <fr:tex>[C,D]</fr:tex>) is the category whose
    <fr:ul><fr:li>
            objects are functors from <fr:tex>C</fr:tex> to <fr:tex>D</fr:tex>.
        </fr:li>
        <fr:li>
            morphisms are <fr:strong>natural transformations</fr:strong> between functors.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>365</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003J</fr:addr><fr:route>def-003J.xml</fr:route><fr:title>Natural Transformation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>C</fr:tex> and <fr:tex>D</fr:tex> be categories and <fr:tex>F,G:C \to  D</fr:tex> be functors.
    A <fr:strong>natural transformation</fr:strong> <fr:tex>\alpha :F \Rightarrow   G</fr:tex> is 
    an assignment to every object <fr:tex>x \in  C</fr:tex> of a morphism <fr:tex>\alpha _x:F(x) \to  G(x)</fr:tex> in <fr:tex>D</fr:tex>,
    (called the <fr:strong>component</fr:strong> of <fr:tex>\alpha</fr:tex> at <fr:tex>x</fr:tex>)
    the following diagram commutes in <fr:tex>D</fr:tex>:
    
    <fr:embedded-tex hash="bce411235fd5c6731abb602d7c12b697"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            {F(x)} &amp;&amp; {F(y)}  \\ 
             \\ 
            {G(x)} &amp;&amp; {G(y)}
             \arrow [&quot;{F(f)}&quot;, from=1-1, to=1-3]
             \arrow [&quot;{G(f)}&quot;, from=3-1, to=3-3]
             \arrow [&quot;{ \alpha _x}&quot;, from=1-1, to=3-1]
             \arrow [&quot;{ \alpha _y}&quot;, from=1-3, to=3-3]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex></fr:p></fr:mainmatter></fr:tree><fr:p>
    We state the concise functorial definition of diagrams of the shape of categories.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>366</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003H</fr:addr><fr:route>def-003H.xml</fr:route><fr:title>Diagram</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>C</fr:tex> be a category and <fr:tex>J</fr:tex> be a small category.
    A <fr:strong>diagram</fr:strong> of shape <fr:tex>J</fr:tex> in <fr:tex>C</fr:tex> is a functor <fr:tex>X:J \to  C</fr:tex>.
    The category of <fr:tex>J</fr:tex>-shaped diagrams in <fr:tex>C</fr:tex> is the <fr:link href="def-003I.xml" type="local" addr="def-003I">functor category</fr:link> <fr:tex>C^J</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    A limit of a diagram <fr:tex>F:D \to  C</fr:tex> is an object <fr:tex>\lim  F</fr:tex> of <fr:tex>C</fr:tex>
    equipped with morphisms to the objects <fr:tex>F(d)</fr:tex> for all <fr:tex>d \in  D</fr:tex>,
    such that everything in sight commutes.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>368</fr:anchor><fr:taxon>Compute Science</fr:taxon><fr:addr>cs-0001</fr:addr><fr:route>cs-0001.xml</fr:route><fr:title>Is JavaScript an untyped language?</fr:title><fr:date><fr:year>2024</fr:year><fr:month>1</fr:month><fr:day>29</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This is a note about the the argument that JavaScript is an untyped language.
    Most opinions came from the References.
</fr:p><fr:p>
    The first thing I want to classify is the word <fr:strong>strong typing</fr:strong> and <fr:strong>weak typing</fr:strong> are meaningless.
    In a limit case we can compare two languages that have similar type system, and talk about which one is <fr:em>stronger</fr:em>.
    But for the common case, it&apos;s totally nonsense.
</fr:p><fr:p>
    Static and dynamic typing is a meaningful classsification. But the discussion about dynamic and static languages is mostly wrong on the Internet.
    Dynamic language is a popular concept, however, it is rather a <fr:strong>marketing</fr:strong> than a well-defined terminology.
    It&apos;s designed to confuse rather than inform.
</fr:p><fr:p>
    In fact, dynamic typing is just a special case of static typing.
    It limits more than contributes.The root of the problem is the confusion 
    between type and class. It&apos;s very useful to have multiple classes of values
    of a same type.
    They are interchangeable because they represent values of the same type.
    Only the form of presentation differs.
</fr:p><fr:p>
    The distinction between two classes of the same type is dynamic.
    But this does not conflict with the fact that only one static type.
    In type theory this is what we called <fr:strong>Sum Type</fr:strong>.
    Being a sum type we can dispatch on the class of the value of the type,
    and decide what to do at runtime.
</fr:p><fr:p>
    This characteristics is same to dynamic language where values can be classified into
    various forms that can be distinguished at runtime.
    The answer is now clear: dynamic language classifies all values in this way.
    What they do just merge all values of the language into a single type.
    The so-called <fr:strong>untyped</fr:strong> language is just <fr:strong>unityped</fr:strong>.
</fr:p><fr:p>
    Therefore, JavaScript is definitely untyped.
</fr:p>
    <fr:p><fr:strong>References</fr:strong></fr:p>
    <fr:ul><fr:li><fr:link href="https://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/" type="external">Dynamic and static language</fr:link></fr:li>
        <fr:li><fr:link href="https://stackoverflow.com/questions/964910/is-javascript-an-untyped-language" type="external">stackoverflow</fr:link></fr:li>
        <fr:li><fr:link href="https://blogs.perl.org/users/ovid/2010/08/what-to-know-before-debating-type-systems.html" type="external">What to know before debating type systems</fr:link></fr:li>
        <fr:li><fr:em>Practical Foundations for Programming Languages</fr:em>, Robert Harper</fr:li></fr:ul>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>380</fr:anchor><fr:taxon>Compute Science</fr:taxon><fr:addr>cs-0002</fr:addr><fr:route>cs-0002.xml</fr:route><fr:title>Primitive Recursion in Lambda Calculus</fr:title></fr:frontmatter><fr:mainmatter><fr:p> 
    We begin with the <fr:strong>schema of iteration</fr:strong> and then proceed 
    the more complex schema of primitive recursion and general recursion.
    Refer to <fr:link href="tapl.xml" type="local" addr="tapl">TAPL</fr:link>.
</fr:p>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>369</fr:anchor><fr:title><fr:strong>Function Composition</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    Giving two functions <fr:tex>f, g</fr:tex> we can compose then to get a new function <fr:tex>f \circ  g = f(g(x))</fr:tex>.
    Using <fr:tex>\lambda</fr:tex>-notation, we can define the composition of two functions as follows:
    <fr:tex display="block">         f \circ  g =  \lambda  x.f(g(x))     </fr:tex>
    And the composition operation is also a lambda abstraction.
    <fr:tex display="block">          \circ  = B =  \lambda  f. \lambda  g. \lambda  x.f(g(x))     </fr:tex>
    Composing identity function with any function does not change the function.
    We expect the following equation to hold:
    <fr:tex display="block">         f \circ  I = f = I \circ  f     </fr:tex>
    where <fr:tex>I</fr:tex> is the identity function. This can be verified by the following calculation:
    <fr:tex display="block">          \begin {align*}             B \space  f \space  I &amp;= ( \lambda  f. \lambda  g. \lambda  x.f(g(x))) \space  f \space  I  \\              &amp; \to _ \beta   \lambda  g. \lambda  x.f(g(x)) \space  I  \\              &amp; \to _ \beta   \lambda  x.f(I(x))  \\              &amp; \to _ \beta   \lambda  x.f(x)  \\              &amp; =_ \eta  f          \end {align*}     </fr:tex>
    The last step requires an extensional equality, which is the called <fr:strong>eta-conversion</fr:strong>.
    <fr:tex display="block">          \text {for} \space  x \not \in \text {FV} (f) , \lambda  x.f(x)  =_ \eta  f     </fr:tex>
    It makes more sense to use the equation from right to left called <fr:strong>eta-expansion</fr:strong> 
    (And more discipline has to be imposed or expansion does not terminate).
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>370</fr:anchor><fr:title><fr:strong>Non-termination</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    <fr:p>
        The well-known <fr:link href="eg-0007.xml" type="local" addr="eg-0007"><fr:strong>divergent combinator</fr:strong></fr:link> implies that 
        the lambda calculus is not strongly normalizing.
    </fr:p>
    <fr:p>
        However, we can always compute a normal form if one exists.
        Though there are many reduction strategies,
        there is a complete one for expressions that have normal form.
        This kind of reduction strategy is called <fr:strong>normal order reduction</fr:strong> or
        <fr:strong>leftmost-outermost reduction</fr:strong>. It scans through the expression from left to right
        and when it find a redex, it reduces it by applying beta reduction and returns to the beginning.
    </fr:p>
    <fr:p>
        The notation of leftmost-outermost reduction is closely related to the 
        notion of <fr:strong>call-by-name evaluation</fr:strong> in programming languages.
        (A little more distance to <fr:strong>call-by-need</fr:strong> evaluation in Haskell)
    </fr:p>
    <fr:p>
        In contrast, <fr:strong>call-by-value</fr:strong> evaluation is not complete, which would 
        reduce the argument of a function before applying beta reduction.
    </fr:p>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>371</fr:anchor><fr:title><fr:strong>Church-Rosser Property</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    The outcome of a computation <fr:tex>e</fr:tex> is its normal form.
    It is naturally to ask the question whether the normal form is unique.
    The key to this question is the <fr:strong>Church-Rosser property</fr:strong> or <fr:strong>confluence</fr:strong>:
    If <fr:tex>e \to ^* e_1</fr:tex> and <fr:tex>e \to ^* e_2</fr:tex>, then there exists a term <fr:tex>e_3</fr:tex> such that
    <fr:tex display="block">         e_1 \to ^* e_3 \space \text {and} \space  e_2 \to ^* e_3     </fr:tex>
    This implies the uniqueness of the normal form.
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>373</fr:anchor><fr:title><fr:strong>Representing Natural Numbers</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    <fr:p>
        We can represent natural numbers in lambda calculus by using the 
        <fr:strong>Church numerals</fr:strong> or <fr:strong>Church encoding</fr:strong>.
        The two abstractions should be related in some ways: 
        one <fr:tex>x</fr:tex> stands for zero and the other <fr:tex>f</fr:tex> stands for the successor function.
    </fr:p>
    <fr:p>
        The Church numeral <fr:tex>n</fr:tex> is a function that takes two arguments <fr:tex>f</fr:tex> and <fr:tex>x</fr:tex> and applies <fr:tex>f</fr:tex> to <fr:tex>x</fr:tex> <fr:tex>n</fr:tex> times.
        The Church numeral <fr:tex>0</fr:tex> is defined as the identity function <fr:tex>\lambda  f. \lambda  x.x</fr:tex>.
        The Church numeral <fr:tex>1</fr:tex> is defined as the successor of <fr:tex>0</fr:tex>:
        <fr:tex display="block">             1 =  \lambda  f. \lambda  x.f(x)         </fr:tex>
        The Church numeral <fr:tex>2</fr:tex> is defined as the successor of <fr:tex>1</fr:tex>:
        <fr:tex display="block">             2 =  \lambda  f. \lambda  x.f(f(x))         </fr:tex>
        And so on.
    </fr:p>
    <fr:p>
        The Church numeral <fr:tex>n</fr:tex> is defined as the successor of <fr:tex>n-1</fr:tex>:
        <fr:tex display="block">             n =  \lambda  f. \lambda  x.f^n(x)         </fr:tex>
        where <fr:tex>f^n(x)</fr:tex> means applying <fr:tex>f</fr:tex> to <fr:tex>x</fr:tex> <fr:tex>n</fr:tex> times.
    </fr:p>
    <fr:p>
        The successor function is defined as follows:
        <fr:tex display="block">             S =  \lambda  n. \lambda  f. \lambda  x.f(n \space  f \space  x)         </fr:tex></fr:p>
    
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>372</fr:anchor><fr:taxon>Proof</fr:taxon><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
            <fr:tex display="block">                  \begin {align*}                     S \space  n &amp;= ( \lambda  n. \lambda  f. \lambda  x.f(n \space  f \space  x)) \space  n  \\                      &amp; \to _ \beta   \lambda  f. \lambda  x.f(n \space  f \space  x)  \\                      &amp; \to _ \beta   \lambda  f. \lambda  x.f^n(x)  \\                      &amp; \to _ \beta  n+1                  \end {align*}             </fr:tex>
        </fr:mainmatter></fr:tree>
 

    <fr:p>
        Using the iteration property we can define mathematical functions 
        over the natural numbers in lambda calculus.
        The addition of two Church numerals <fr:tex>m</fr:tex> and <fr:tex>n</fr:tex> is defined as follows:
        <fr:tex display="block">             m+n =  \lambda  n. \lambda  k. n \space  S \space  k         </fr:tex></fr:p>
    <fr:p>
        The multiplication of two Church numerals <fr:tex>m</fr:tex> and <fr:tex>n</fr:tex> is defined by
        iterating the addition function <fr:tex>m</fr:tex> times:
        <fr:tex display="block">             m*n =  \lambda  n. \lambda  k. n \space  (k + )  \space  0         </fr:tex></fr:p>
    <fr:p>
        The exponentiation of two Church numerals <fr:tex>m</fr:tex> and <fr:tex>n</fr:tex> is defined as follows:
        <fr:tex display="block">             m^n =  \lambda  m. \lambda  n. n \space  (m *)  \space  1         </fr:tex></fr:p>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>374</fr:anchor><fr:title><fr:strong>The Schema of Iteration</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    <fr:p>
        As we saw before, a natural number <fr:tex>n</fr:tex> is represented by a function 
        that iterates its first argument <fr:tex>n</fr:tex> times on its second argument.
        <fr:tex display="block">             n =  \lambda  g. \lambda  c.g^n(c)         </fr:tex>
        Another way to specify such a function schematically is 
        <fr:tex display="block">              \begin {align*}                 f  \space0  &amp;= c  \\                  f (n+1) &amp;= g \space  (f \space  n)              \end {align*}         </fr:tex>
        If such a function satisfies such a <fr:strong>schema of iteration</fr:strong>, then it can 
        be defined in the lambda calculus on Church numerals as
        <fr:tex display="block">             f =  \lambda  n.n  \space  g  \space  c         </fr:tex>
        This definition is <fr:strong>total</fr:strong> which means it is defined for all natural numbers.
        Let&apos;s define the multiplication again
        <fr:tex display="block">              \begin {align*}                 m*0 &amp;= 0  \\                  m*(n+1) &amp;= m + (m*n)              \end {align*}         </fr:tex>
        To fit our schema of iteration, we can define the multiplication by abstracting over <fr:tex>k</fr:tex>:
        <fr:tex display="block">              \begin {align*}                  \text {times} \space  0 &amp;=  \lambda  k.0  \\                   \text {times} \space  (n+1) &amp;=  \lambda  k.k + ( \text {times} \space  n \space  k)              \end {align*}         </fr:tex>
        where the <fr:tex>c</fr:tex> and <fr:tex>g</fr:tex> are
        <fr:tex display="block">              \begin {align*}                 c &amp;=  \lambda  k.0  \\                  g &amp;=  \lambda  r. \lambda  k.k+(r \space  k)              \end {align*}         </fr:tex>
        and we obtain
        <fr:tex display="block">              \text {times} =  \lambda  n.n( \lambda  rk. k + (r \space  k))( \lambda  k.0)         </fr:tex></fr:p>
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>379</fr:anchor><fr:title><fr:strong>The Schema of Primitive Recursion</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
    <fr:p>
        Everything appears simply until we think of a very simple function,
        the <fr:strong>predecessor function</fr:strong> <fr:tex>\text {pred}</fr:tex> defined by
        <fr:tex display="block">              \begin {align*}                  \text {pred} \space  0 = 0  \\                   \text {pred} \space  (n+1) = n              \end {align*}         </fr:tex>
        What we would need is the <fr:strong>schema of primitive recursion</fr:strong>
        <fr:tex display="block">              \begin {align*}                 f \space  0 &amp;= c  \\                  f \space  (n+1) &amp;= g \space  n \space  (f \space  n)              \end {align*}         </fr:tex>
        With which we can define the predecessor function by 
        <fr:tex display="block">             g =  \lambda  x. \lambda  y.x         </fr:tex></fr:p>
    
    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>375</fr:anchor><fr:title><fr:strong>Define predecessor function</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
        The key idea is to gain access to <fr:tex>n</fr:tex> in the schema of 
        primitive recursion by rebuilding it during the iteration.
        <fr:tex display="block">              \text {pred}_2 \space  n =  \langle  n,  \text {pred} \space  n  \rangle          </fr:tex>
        The key step is to express the definition by a schema of iteration
        rather than primitive recursion.
        <fr:tex display="block">              \text {pred}_2 \space  0 =  \langle  0, 0  \rangle          </fr:tex>
        We need a helper function for the successor case
        <fr:tex display="block">              \text {letPair} \space \langle  e_1,e_2 \rangle \space  k = k \space  e_1 \space  e_2         </fr:tex>
        This function passes the elements of the pair to a <fr:strong>continuation</fr:strong> <fr:tex>k</fr:tex>.
        <fr:tex display="block">              \text {pred}_2 (n+1) =  \text {letPair} \space  ( \text {pred}_2 \space  n) \space  ( \lambda  xy.  \langle  x+1, x  \rangle )          </fr:tex>
    </fr:mainmatter></fr:tree>

    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>376</fr:anchor><fr:title><fr:strong>Define Pairs</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
        Now we need to define pairs and <fr:tex>\text {letPair}</fr:tex>.
        The idea is to simply abstract over the continuation itself.
        <fr:tex display="block">              \begin {align*}                  \langle  x,y \rangle  &amp;=  \lambda  k.k \space  x \space  y  \\                   \text {pair} &amp;=  \lambda  x. \lambda  y. \lambda  k.k \space  x \space  y  \\                    \text {letPair} &amp;=  \lambda  p.p              \end {align*}         </fr:tex>
        The letPair is not really needed here.
    </fr:mainmatter></fr:tree>

    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>377</fr:anchor><fr:title><fr:strong>Summary</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
        Summarizing the above and we obtain the full definition of the predecessor function.
        <fr:tex display="block">              \begin {align*}                  \text {pred}_2 &amp;=  \lambda  n.n \space  ( \lambda  p.p ( \lambda  xy. \text {pair}  \space  (x+1)  \space  x)) \space   \text {pair} ( \space  0  \space  0) \\                    \text {pred} &amp;=  \lambda  n. ( \text {pred}_2 \space  n)  \space  ( \lambda  xy.y)              \end {align*}            </fr:tex>
    </fr:mainmatter></fr:tree>

    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>378</fr:anchor><fr:title><fr:strong>General Primitive Recursion</fr:strong></fr:title><fr:parent>cs-0002</fr:parent></fr:frontmatter><fr:mainmatter>
        The general case of primitive recursion follows by a similar pattern.
        We begin by defining a function <fr:tex>f_2</fr:tex>:
        <fr:tex display="block">             f_2 \space  n =  \langle  n, f \space  n  \rangle          </fr:tex>
        We can define <fr:tex>f_2</fr:tex> using the schema of iteration
        <fr:tex display="block">              \begin {align*}                 f_2 \space  0 &amp;=  \langle  0, c  \rangle   \\                  f_2 \space  (n+1) &amp;=  \text {letPair} \space  (f_2 \space  n) \space  ( \lambda  xy. \langle  x+1, g \space  x \space  y  \rangle )  \\                  f \space  n &amp;=  \text {letPair} \space  (f_2 \space  n) \space  ( \lambda  xy.y)              \end {align*}         </fr:tex>
    </fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>
<fr:p>
    When computing over natural numbers we can restrict the functions that can be 
    formed in schematic ways to obtain a language in which all functions <fr:strong>terminate</fr:strong>.
    Because if <fr:tex>c</fr:tex> and <fr:tex>g</fr:tex> are terminating then so is <fr:tex>f</fr:tex> formed from them by primitive recursion.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>383</fr:anchor><fr:taxon>Computer Science</fr:taxon><fr:addr>cs-0003</fr:addr><fr:route>cs-0003.xml</fr:route><fr:title>Recursion</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>2</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    In this note we complete the development of <fr:strong>recursion</fr:strong>.
    Refer to <fr:link href="tapl.xml" type="local" addr="tapl">TAPL</fr:link></fr:p>
  
    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>381</fr:anchor><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>2</fr:day></fr:date><fr:parent>cs-0003</fr:parent></fr:frontmatter><fr:mainmatter><fr:strong>General Recursion</fr:strong>
    <fr:p>
        Let&apos;s first consider the <fr:strong>greatest common divisor</fr:strong> function <fr:tex>\gcd (a,b)</fr:tex></fr:p>
    <fr:tex display="block">          \begin {align*}              \gcd \space  a \space  a &amp;= a  \\               \gcd \space  a \space  b &amp;=  \gcd \space  (a-b) \space  b   \text { if } b &gt; a  \\               \gcd \space  a \space  b &amp;=  \gcd \space  a \space  (b-a)   \text { if } a &gt; b          \end {align*}     </fr:tex>
    This recursion is terminating because the arguments are decreasing.
    We can deal with this case currently and let&apos;s be hold.
    We consider the most general schema of recursion.
    <fr:tex display="block">         f = h \space  f     </fr:tex>
    which means that in the right-hand side we can make arbitrary recursive
    calls to the function <fr:tex>f</fr:tex>. For <fr:tex>\gcd</fr:tex> we have
    <fr:tex display="block">         h =  \lambda  gab.  \text {if } (a=b) \space  a \space ((              \text {if } \space (a&gt;b) \space (g \space  (a-b) \space  b) \space (g \space  a \space  (b-a))         ))     </fr:tex>
    How can we define <fr:tex>f</fr:tex> explicitly when given <fr:tex>h</fr:tex> so that <fr:tex>f = h \space  f</fr:tex>,
    which called a <fr:strong>fixed point</fr:strong> pf <fr:tex>h</fr:tex>. If we believe <fr:strong>Church-Turing thesis</fr:strong>,
    then any partial recursive function should be representable on Church numerals in lambda calculus.
    Hence we can find such <fr:tex>f</fr:tex> and the answer is called <fr:strong>Y-combinator</fr:strong>.
    We want that if <fr:tex>f = Y \space  h</fr:tex> and <fr:tex>f=h \space  f</fr:tex>, so we get <fr:tex>Y \space  h = h  \space  (Y \space  h)</fr:tex>.
    <fr:tex display="block">         Y \space  h = h \space  (Y \space  h) = h \space  (h \space  (Y \space  h)) = h \space  (h \space  (h \space  (Y \space  h))) =  \cdots      </fr:tex>
    This iterates infinitely. The definition of <fr:tex>Y</fr:tex> is:
    <fr:tex display="block">         Y =  \lambda  h.( \lambda  x. h \space  (x \space  x)) \space  ( \lambda  x. h \space  (x \space  x))     </fr:tex>
    The application <fr:tex>x \space  x</fr:tex> will replicate <fr:tex>Y \space  h</fr:tex>:
    <fr:tex display="block">          \begin {align*}             Y \space  h &amp;= ( \lambda  x. h \space  (x \space  x)) \space  ( \lambda  x. h \space  (x \space  x))  \\              &amp;= h \space  (( \lambda  x. h \space  (x \space  x)) \space  ( \lambda  x. h \space  (x \space  x)))  \\              &amp;= h \space  (Y \space  h)          \end {align*}     </fr:tex>
    The partial recursive functions include functions that are <fr:strong>undefined</fr:strong> (have no normal form) 
    on some arguments, hence we can&apos;t always find an answer.
    Consider <fr:tex>f=f</fr:tex> as a recursion schema and <fr:tex>h= \text {id}</fr:tex>.
    <fr:tex display="block">         Y \space  h = Y \space   \text {id}  = ( \lambda  x.  \text {id} \space  (x \space  x)) \space  ( \lambda  x.  \text {id} \space  (x \space  x))         = ( \lambda  x. x \space  x) \space  ( \lambda  x. x \space  x) =  \Omega      </fr:tex>
    The function <fr:tex>f= \Omega</fr:tex> solves the equation <fr:tex>f=f</fr:tex> by giving a divergent result.
</fr:mainmatter></fr:tree>
  

  
    
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>382</fr:anchor><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>2</fr:day></fr:date><fr:parent>cs-0003</fr:parent></fr:frontmatter><fr:mainmatter><fr:strong>Define Functions By Recursion</fr:strong>
    <fr:p>Consider the factorial function:</fr:p>
    <fr:tex display="block">          \text {fact} \space  n =  \text {if } (n=0) \space  1 \space  (n \space   \text {fact} \space  (n-1))     </fr:tex>
    This requires a test <fr:tex>\text {if0}</fr:tex> satisfies:
    <fr:tex display="block">          \begin {align*}              \text {if0}(0,c,d) &amp;=c \\               \text {if0}(n+1,c,d) &amp;=d          \end {align*}     </fr:tex>
    We can define <fr:tex>\text {if0}</fr:tex> by (Recall that <fr:tex>K= \lambda  xy.x</fr:tex>):
    <fr:tex display="block">          \text {if0} =  \lambda  ncd. n \space (K \space  d) \space  c     </fr:tex>
    The argument of Y combinator is defined:
    <fr:tex display="block">         h_ \text {fact} =  \lambda  g.  \lambda  n.  \text {if0} \space  n \space  1 \space  (n \space  g \space  (n-1))     </fr:tex>
    and
    <fr:tex display="block">          \text {fact} = Y \space  h_ \text {fact}     </fr:tex>
</fr:mainmatter></fr:tree>
  
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>390</fr:anchor><fr:taxon>Computer Science</fr:taxon><fr:addr>cs-0004</fr:addr><fr:route>cs-0004.xml</fr:route><fr:title>Scanners</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The scanner&apos;s task is to transform a stream of characters into a stream 
    of words in the input language. Each word must be classified into a 
    <fr:strong>syntactic category</fr:strong>.
    This note refers to <fr:link href="eng-compiler-2022.xml" type="local" addr="eng-compiler-2022">Engineering a compiler</fr:link></fr:p><fr:p>
    The first stage of a compiler is to perform <fr:strong>lexical analysis</fr:strong> by a scanner.
    The parser or <fr:strong>syntax analyzer</fr:strong> will fit the stream of words to a grammatical 
    model of the input language.
</fr:p><fr:p>
    Scanner construction has a strong foundation in formal language theory.
    Scanners are based on <fr:strong>recognizers</fr:strong> that simulate <fr:strong>deterministic finite automata</fr:strong>.
    We can specify the lexical structure using a set of <fr:strong>regular expression</fr:strong>.
</fr:p><fr:p>
    Each time a scanner recognizes a word, it will return a <fr:strong>token</fr:strong> that
    contains the word (<fr:strong>lexeme</fr:strong>) and its syntactic category.
    The scanner uses <fr:strong>microsyntax</fr:strong> (the lexical structure of a language) to 
    find and classify words. <fr:strong>Keywords</fr:strong> are <fr:strong>identifiers</fr:strong> but have special meanings.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>384</fr:anchor><fr:title>A first look at recognizers</fr:title><fr:parent>cs-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        A char-by-char algorithm to recognize words is trivial.
        Consider we want to recognize the word <fr:code>new</fr:code>.
        We can write down the following code.
    </fr:p><fr:pre>    c &lt;- nextChar();
    if (c == &apos;n&apos;) {
        c &lt;- nextChar();
        if (c == &apos;e&apos;) {
            c &lt;- nextChar();
            if (c == &apos;w&apos;) {
                return newToken();
            }
        }
    }
    reportError();</fr:pre><fr:p>
        We can also represent the code fragment using the simple <fr:strong>transition diagram</fr:strong>.
    </fr:p>
    <fr:embedded-tex hash="6e7465cf950ac87387ac76b9da5fb72d"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            {S_0} &amp; {S_1} &amp; {S_2} &amp; {S_3}
             \arrow [&quot;n&quot;, from=1-1, to=1-2]
             \arrow [&quot;e&quot;, from=1-2, to=1-3]
             \arrow [&quot;w&quot;, from=1-3, to=1-4]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>387</fr:anchor><fr:title>A formalism for recognizers</fr:title><fr:parent>cs-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Transition diagrams can be viewed as formal mathematics objects called <fr:strong>finite automata</fr:strong>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>385</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003M</fr:addr><fr:route>def-003M.xml</fr:route><fr:title>Finite Automata</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>finite automata (FA)</fr:strong> is a five-tuple <fr:tex>(S, \Sigma , \delta ,s_0,S_A)</fr:tex> where
    <fr:ul><fr:li><fr:tex>S</fr:tex> is the finite set of states in the recognizer including <fr:tex>s_e</fr:tex>,
            the error state.
        </fr:li>
        <fr:li><fr:tex>\Sigma</fr:tex> is the finite alphabet used by the recognizer. 
            <fr:tex>\Sigma</fr:tex> is the union of the edge labels in the transition diagram.
        </fr:li>
        <fr:li><fr:tex>\delta (s, c)</fr:tex> is the recognizer&apos;s transition function, which 
            maps each state <fr:tex>s \in  S</fr:tex> and character <fr:tex>c \in \Sigma</fr:tex> into some next state.
            In state <fr:tex>s_i</fr:tex> with input character <fr:tex>c</fr:tex> the FA takes the transition
            <fr:tex>s_i  \xrightarrow {c}  \delta (s_i, c)</fr:tex>.
        </fr:li>
        <fr:li><fr:tex>s_0 \in  S</fr:tex> is the initial state of the recognizer.
        </fr:li>
        <fr:li><fr:tex>S_A</fr:tex> is the set of accepting states, <fr:tex>S_A \subseteq  S</fr:tex>.
        </fr:li></fr:ul>
    <fr:tex>\delta</fr:tex> is only partially defined. For all other combinations of the 
    state <fr:tex>s_i</fr:tex> and input char <fr:tex>c</fr:tex> we can define <fr:tex>\delta (s_i,c)=s_e</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        An FA <fr:strong>accpets</fr:strong> a string <fr:tex>x</fr:tex> and iff starting in <fr:tex>s_0</fr:tex>,
        the sequence of chars in  <fr:tex>x</fr:tex> takes the FA to an accepting state
        when the entire string has been consumed.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>386</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003N</fr:addr><fr:route>def-003N.xml</fr:route><fr:title>Accepts</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    If the string <fr:tex>x</fr:tex> consists characters <fr:tex>x_1, x_2,  \ldots , x_n</fr:tex> then the
    FA <fr:tex>(S, \Sigma , \delta ,s_0,S_A)</fr:tex> <fr:strong>accpets</fr:strong> <fr:tex>x</fr:tex> iff there is a sequence
    <fr:tex display="block">          \delta (              \delta (                  \dots \delta ( \delta (                      \delta (s_0,x_1),x_2),x_3) \dots ,                 x_{n-1}             )             ,x_n         ) \in  S_A     </fr:tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>388</fr:anchor><fr:title>Recognize more complex words</fr:title><fr:parent>cs-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The char-by-char model is very simple and now we consider about numbers.
        For simplicity, we consider only unsigned integers: An unsigned integer is either
        zero or series of one or more digits where the first one is non-zero.
    </fr:p>
    <fr:embedded-tex hash="50bfeb9a1f9d7a5d006a58e636b046a2"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            &amp; {S_2}
             \arrow [out=65, in=25 ,loop,&quot;0..9&quot;]
             \\ 
            {S_0}  \\ 
            &amp; {S_1}
             \arrow [&quot;0&quot;, from=2-1, to=3-2]
             \arrow [&quot;{1..9}&quot;, from=2-1, to=1-2]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex>
<fr:p>
        And the code implementation can be:
    </fr:p><fr:pre>    state &lt;- s0;
    char &lt;-nextChar();
    while (state != se and char != eof) {
        state &lt;- delta(state, char);
        char &lt;- nextChar();
    }
    if (state in SA) {
        return Acceptance();
    } else {
        reportError();
    }</fr:pre><fr:p>
        Another example is to recognize <fr:strong>identifiers</fr:strong> which are sequences of letters and digits,
        starting with a letter. Many languages include other special characters for identifiers.
        The FA for unsigned integers and identifiers are different in syntactic categories.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>389</fr:anchor><fr:title>Regular Expressions</fr:title><fr:parent>cs-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The set of words accpeted by a finite automata <fr:tex>F</fr:tex> forms a language <fr:tex>L(F)</fr:tex>.
        The transition diagram of <fr:tex>F</fr:tex> specifies the syntactic structure of <fr:tex>L(F)</fr:tex>.
        But such representation is complex and non-intuitive.
        Most systems use a notation called <fr:strong>regular expressions</fr:strong> to specify the language.
        Any language described by an RE is considered a <fr:strong>regular language</fr:strong>.
        RE is equivalent to FA.
    </fr:p><fr:p>
        To work with REs in a rigorous way, we need a foraml definition.
    </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>399</fr:anchor><fr:taxon>Computer Science</fr:taxon><fr:addr>cs-0005</fr:addr><fr:route>cs-0005.xml</fr:route><fr:title>Simply Typed Lambda Calculus and Representation Theorems</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    We have explored the power of lambda calculus.
    Church&apos;s original purpose of the pure calculus of functions 
    was a new foundations of mathematics distinct from set theory.
    Unfortunately the original lambda calculus is <fr:strong>inconsistent</fr:strong> (Every proposition has a proof).
    Church returned to the ideas by Russell and Whitehead and developed the <fr:strong>Church&apos;s Simple Theory of Types</fr:strong>.
    <fr:strong>SLTC</fr:strong> is a typed interpretation of the lambda calculus with only one type constructor <fr:tex>\to</fr:tex>
    that builds function types. 
</fr:p><fr:p>
    We follow the converntion that function type constructor <fr:tex>\to</fr:tex> is right-associative.
    We write <fr:tex>e: \tau</fr:tex> if expression <fr:tex>e</fr:tex> has type <fr:tex>\tau</fr:tex>.
    <fr:tex display="block">          \lambda  x.x: \tau \to \tau      </fr:tex>
    But the type is not unique. The booleans can be typed:
    <fr:tex display="block">          \begin {align*}              \text {true} &amp;=  \lambda  x. \lambda  y.x :  \alpha \to ( \beta \to \alpha ) \\               \text {false} &amp;=  \lambda  x. \lambda  y.y :  \alpha \to ( \beta \to \beta )          \end {align*}     </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>391</fr:anchor><fr:title>Typing Judgment</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date><fr:parent>cs-0005</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Wem can formalize judgments about expressions and types using <fr:strong>inference rules</fr:strong>.
        For instance:
        <fr:tex display="block">              \frac {                 e_1: \tau _1 \quad  e_2: \tau _2             }{                 e_1 \space  e_2: \tau _2             }         </fr:tex>
        The application <fr:tex>e_1 \space  e_2</fr:tex> has type <fr:tex>\tau _2</fr:tex> if <fr:tex>e_1</fr:tex> has type 
        <fr:tex>\tau _1 \to \tau _2</fr:tex> and <fr:tex>e_2</fr:tex> has type <fr:tex>\tau _1</fr:tex>.
    </fr:p><fr:p>
        We can record the types of variable in a <fr:strong>typing context</fr:strong>.
        <fr:tex display="block">              \Gamma  : \equiv  x_1: \tau _1, \ldots ,x_n: \tau _n         </fr:tex>
        And we always assume that all variables declared in a context are distinct.
        This avoids any ambiguity when we try to determine the type of a variable.
        The typing judgment now becomes
        <fr:tex display="block">              \Gamma \vdash  e: \tau          </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>392</fr:anchor><fr:title>The Limits of Simple Types</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date><fr:parent>cs-0005</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Are there expressions that cannot be typed in the simple type system?
        Yes, for example, <fr:tex>\Omega = \lambda  x.x \space  x</fr:tex> cannot be typed.
        But how do we prove that  <fr:tex>\Omega</fr:tex> cannot be typed?
    </fr:p><fr:p>
        We can apply the typing rules and get a contradiction.
        <fr:tex>\Omega</fr:tex> is a lambda abstraction hence we can assume that it has type <fr:tex>\tau \to \sigma</fr:tex>.
        Then <fr:tex>x</fr:tex> has type <fr:tex>\tau</fr:tex> and <fr:tex>x \space  x</fr:tex> has type <fr:tex>\sigma</fr:tex>.
        By the application of <fr:tex>x \space  x</fr:tex> we get that <fr:tex>\tau = \tau \to \sigma</fr:tex>, 
        which does not exist.
    </fr:p><fr:p>
        To recover from this in full generality we need <fr:strong>recursive types</fr:strong>.
        <fr:tex display="block">              \tau  =F \tau          </fr:tex>
        where <fr:tex>F= \lambda \alpha . \alpha \to \sigma</fr:tex> and we might have a solution with 
        <fr:tex>\tau =Y \space  F</fr:tex>. But such solution is not available to us. We do not have 
        function from types to types <fr:tex>F</fr:tex> and a type level Y combinator.
        However it is ok to construct recursive types (we would do later).
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>395</fr:anchor><fr:title>Characterizing the Booleans</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date><fr:parent>cs-0005</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        We now show that the representation of the booleans is correct.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>393</fr:anchor><fr:title>Representation of Booleans</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            If <fr:tex>\emptyset \vdash  e: \alpha \to ( \alpha \to \alpha )</fr:tex> and <fr:tex>e</fr:tex> is a normal form, 
            then <fr:tex>e =  \text {true}</fr:tex> or <fr:tex>e =  \text {false}</fr:tex>.
        </fr:p></fr:mainmatter></fr:tree><fr:p>We will later combine this with the following theorems which yields 
    correctness of the representation of the booleans.</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>394</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003O</fr:addr><fr:route>def-003O.xml</fr:route><fr:title>Weak Normalization</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    If <fr:tex>\Gamma \vdash  e: \tau</fr:tex> then <fr:tex>e \to _{ \beta }^*e&apos;</fr:tex> for a <fr:strong>normal form</fr:strong> <fr:tex>e&apos;</fr:tex>.
    And we can define <fr:strong>subject reduction</fr:strong>, if <fr:tex>\Gamma \vdash  e: \tau</fr:tex> and <fr:tex>e \to _{ \beta }e&apos;</fr:tex> then <fr:tex>\Gamma \vdash  e&apos;: \tau</fr:tex>.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>396</fr:anchor><fr:title>Reduction revised</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date><fr:parent>cs-0005</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Our characterization of normal forms is quite simple: terms that do not reduce.
        However, this is a <fr:strong>negative</fr:strong> condition, which is difficult to work with in proofs.
        We would like to have a <fr:strong>positive</fr:strong> condition, which is easier to work with.
    </fr:p><fr:p>
        We tend to give definitions in the form of inference rules.
        The property then holds if the judgment can be derived using the rules.
        (This closely related to the <fr:strong>inductive deefintion</fr:strong>).
        Before defining the normal forms we formally define <fr:strong>beta reduction</fr:strong>.
        The judgment here <fr:tex>e \to  e&apos;</fr:tex> expressing that <fr:tex>e</fr:tex> reduces to <fr:tex>e&apos;</fr:tex>.
        <fr:tex display="block">              \begin {align*}                  \frac {}{( \lambda  x.e_1)e_2 \to  e_1[x:=e_2]} ( \text {red/beta})  \\                   \frac {e \to  e&apos;}{ \lambda  x.e  \to   \lambda  x.e&apos;} ( \text {red/lam})  \\                   \frac {e_1 \to  e_1&apos;}{e_1 \space  e_2 \to  e_1&apos; \space  e_2} ( \text {red/app}_1)  \\                   \frac {e_2 \to  e_2&apos;}{e_1 \space  e_2 \to  e_1 \space  e_2&apos;} ( \text {red/app}_2)                              \end {align*}         </fr:tex></fr:p><fr:p>
        A <fr:strong>normal form</fr:strong> is an expression that does not reduce.
        To give a proper formalization,, we need a separate judgment for <fr:strong>neutral terms</fr:strong>
        which do not create a redex when applied to an argument.
        <fr:tex display="block">                                        \begin {align*}                  \frac {e \text { normal} }{ \lambda  x.e \text { normal} } ( \text {normal/lam})  \\                   \frac {e \text { neutral} }{e \text { normal} } ( \text {normal/var})  \\                   \frac {}{x \text { neutral} } ( \text {neutral/var})  \\                   \frac {e_1 \text { neutral} \quad  e_2 \text { normal} }{e_1 \space  e_2 \text { neutral} } ( \text {neutral/app})  \\               \end {align*}         </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>398</fr:anchor><fr:title>Normal Forms and Reduction</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>5</fr:day></fr:date><fr:parent>cs-0005</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The characterization of normal forms via inference rules is compact,
        but is it really the same as saying that an expression does not reduce?
        We break this down into the following two properties.
        <fr:ul><fr:li>
                For all expressions <fr:tex>e</fr:tex>, either <fr:tex>e</fr:tex> reduces or <fr:tex>e</fr:tex> is normal
            </fr:li>
            <fr:li>
                For all expressions <fr:tex>e</fr:tex>, it is not that case <fr:tex>e</fr:tex> reduces and <fr:tex>e</fr:tex> is normal
            </fr:li></fr:ul></fr:p><fr:p>
        We have theorem that ensures that the first property holds. (Proof is omitted).
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>397</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0010</fr:addr><fr:route>thm-0010.xml</fr:route><fr:title>Reduction and normal forms</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    For every expression <fr:tex>e</fr:tex>, either <fr:tex>e \to  e&apos;</fr:tex> for some expression <fr:tex>e&apos;</fr:tex> or <fr:tex>e</fr:tex> is a normal form.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>436</fr:anchor><fr:taxon>Computer Science</fr:taxon><fr:addr>cs-0006</fr:addr><fr:route>cs-0006.xml</fr:route><fr:title>Introduction to Programming Language Semantic</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    I decided to read one paper or article every week.
    This week&apos;s topic is programming language semantics, refer to <fr:strong>Graham Huttons</fr:strong>&apos;s 
    paper <fr:link href="pl-123.xml" type="local" addr="pl-123">Programming language semantics: It&apos;s easy as 1,2,3</fr:link>.
</fr:p><fr:p><fr:strong>Semantics</fr:strong> is the general term for the study of meaning.
    <fr:strong>Programming language semantics</fr:strong> gives precise mathematical meaning to programs.
    We use a simple <fr:strong>arithmetic expression language</fr:strong> 
    (including integers and addition only) to illustrate the basic concepts.
    This is an example of <fr:strong>Occam&apos;s razor</fr:strong>, a philosophical principle that favours the 
    simplest explanation for a phenomenon.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>401</fr:anchor><fr:title>Arithmetic Expressions</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Now let&apos;s define our language of arithmetic expressions
        built up from the set of integers and the operation of addition.
        Use a <fr:strong>context-free</fr:strong> grammar.
        <fr:tex display="block">             E: \equiv \mathbb {Z} | E+E         </fr:tex></fr:p><fr:p>
        An expression is either an integer value or the addition of two sub-expressions.
        We assume that parentheses can be <fr:strong>freely</fr:strong> used as required to disambiguate expressions 
        written in normal textual form. This grammar can be easily translated into 
        a <fr:strong>Haskell</fr:strong> data type.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">data Expr = Val Integer | Add Expr Expr</html:code></fr:pre>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>406</fr:anchor><fr:title>Denotational Semantics</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Now we consider <fr:strong>denotational semantics</fr:strong>, 
        where the terms in a language is defined using a 
        <fr:strong>valuation function</fr:strong> that maps terms into values in an appropriate <fr:strong>semantic domain</fr:strong>.
    </fr:p><fr:p>
        Formally, for a language <fr:tex>T</fr:tex> of syntactic terms comprises
        two components: a set <fr:tex>V</fr:tex> of <fr:strong>semantic values</fr:strong> and a 
        <fr:strong>valuation function</fr:strong> of type <fr:tex>T \to  V</fr:tex> that maps terms to 
        their meanings as values.
        This function is written by enclosing a term in a <fr:strong>semantic brackets</fr:strong> 
        (Also known as Oxford or Strachey brackets),
        writing <fr:tex>\llbracket  t \rrbracket</fr:tex> for the value of term <fr:tex>t</fr:tex>.
        In addition, the valuation function is required to be <fr:strong>compositional</fr:strong>,
        the meaning  of a <fr:strong>compound term</fr:strong> is defined purely in terms of the meaning
        of its sub-terms.
    </fr:p><fr:p>
        Compositionality aids understanding by ensuring that the semantics is modular
        and supports the use of simple <fr:strong>equational reasoning</fr:strong> techniques for proving properties of
        the semantics. When the set of semantic values is clear, a denotational semantics is often
        identified with the underlying valuation function.
    </fr:p><fr:p>
        Taking <fr:tex>V</fr:tex> the Haskell type <fr:code>Integer</fr:code> of integers and define a valuation function
        of type <fr:code>Expr -&gt; Integer</fr:code> (by following equations) we can define the denotational semantics of our expression language.
        <fr:tex display="block">              \begin {align*}                  \llbracket \text {Val}   \space  n \rrbracket  &amp;= n  \\                   \llbracket \text {Add}   \space  e_1 \space  e_2 \rrbracket  &amp;=  \llbracket  e_1 \rrbracket  +  \llbracket  e_2 \rrbracket               \end {align*}         </fr:tex>
        This definition satisfies the compositionality requirement obviously.
        Note that the symbol <fr:tex>+</fr:tex> has two different purposes.
        On the left side, it is a <fr:strong>syntactic</fr:strong> constructor for building terms,
        while on the right side, it is a <fr:strong>semantic</fr:strong> operator for adding integers. 
    </fr:p><fr:p>
        Compositionality simplifies reasoning because it allows us to 
        replace <fr:strong>equals by equals</fr:strong>. For example,
        <fr:tex display="block">              \frac {                  \llbracket  e_1 \rrbracket  = n_1  \quad   \llbracket  e_2 \rrbracket  = n_2             }{                  \llbracket \text {Add}   \space  e_1 \space  e_2 \rrbracket  =                  \llbracket \text {Add}   \space  n_1 \space  n_2 \rrbracket              }         </fr:tex>
        we can freely replace the two argument expressions of an addition by other expressions with the same meanings, 
        and the meaning of the whole addition will remain unchanged.
        Using the definition of the valuation function, we can prove this property.
        <fr:tex display="block">              \begin {align*}                  \llbracket \text {Add}   \space  e_1 \space  e_2 \rrbracket  &amp;=                   \llbracket  e_1 \rrbracket  +  \llbracket  e_2 \rrbracket  ( \text {By definition of }  \llbracket- \rrbracket )  \\                  &amp;=  \llbracket  n_1 \rrbracket  +  \llbracket  n_2 \rrbracket  ( \text {Assumptions})  \\                   &amp;=  \llbracket \text {Add}   \space  n_1 \space  n_2 \rrbracket  ( \text {By definition of }  \llbracket- \rrbracket )              \end {align*}         </fr:tex></fr:p><fr:p>
        Given that terms and their semantics are built up <fr:strong>inductively</fr:strong>,
        proofs about denotational semantics typically  proceed using <fr:strong>structural induction</fr:strong>.
        Let us show that our expression semantics is <fr:strong>total</fr:strong>,
        that is, for every expression <fr:tex>e</fr:tex> there is an integer <fr:tex>n</fr:tex> such that <fr:tex>\llbracket  e \rrbracket  = n</fr:tex>.
    </fr:p>
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>402</fr:anchor><fr:taxon>Proof</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date></fr:frontmatter><fr:mainmatter>
        For the base case <fr:tex>e =  \text {Val}   \space  n</fr:tex>, we have <fr:tex>\llbracket  e \rrbracket  = n</fr:tex> trivially.
        For the inductive case <fr:tex>e =  \text {Add}   \space  e_1 \space  e_2</fr:tex>,
        we can assume by induction that <fr:tex>\llbracket  e_1 \rrbracket  = n_1</fr:tex> and <fr:tex>\llbracket  e_2 \rrbracket  = n_2</fr:tex>
        for some integers <fr:tex>n_1</fr:tex> and <fr:tex>n_2</fr:tex>. Then <fr:tex>\llbracket  e \rrbracket  = n_1 + n_2</fr:tex> by definition of the valuation function,
        indicates this case is also true. Therefore, the semantics is total.
    </fr:mainmatter></fr:tree>
 
<fr:p>
        The valuation function can be translated into a Haskell function
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval :: Expr -&gt; Integer
eval (Val n) = n
eval (Add x y) = eval x + eval y</html:code></fr:pre>
<fr:p>
        More generally, a denotational semantics can be viewed as an evaluator (or <fr:strong>interpreter</fr:strong>).
        Even <fr:strong>eval</fr:strong> is defined recursively, the semantics is compositional its behavior
        can be understood  as simply replacing the <fr:strong>constructors</fr:strong> for expressions by other functions.
        In this manner, a denotational semantics can also be viewed as an evaluation function that
        is defined by <fr:strong>folding</fr:strong> over the syntax of the source language.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval :: Expr -&gt; Integer
eval = fold id (+)</html:code></fr:pre>
<fr:p>
        The fold operator captures the ideas of replacing constructors
        of the language by other functions
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">fold :: (Integer -&gt; a) -&gt; (a -&gt; a -&gt; a) -&gt; Expr -&gt; a 
fold f g (Val n) = f n
fold f g (Add x y) = g (fold f g x) (fold f g y)</html:code></fr:pre>
<fr:p>
        Note that the above semantics for expressions does not specify the order
        of evaluation. If we do wish to make evaluation order explicit 
        this requires the introduction of additional structure into the semantics,
        named <fr:strong>abstract machines</fr:strong> (Discuss later).
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>411</fr:anchor><fr:title>Small-Step Operational Semantics</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Another popular approach to semantics is the <fr:strong>operational approach</fr:strong>,
        where the meaning of terms is defined using an <fr:strong>execution relation</fr:strong>
        that specifies how terms can be executed in an appropriate machine model.
        There are two basic forms of operational semantics:
        <fr:ul><fr:li><fr:strong>small-step</fr:strong>: describes the individual steps of execution
            </fr:li>
            <fr:li><fr:strong>big-step</fr:strong>: describes the overall results of execution
            </fr:li></fr:ul>
        In this section we consider the small-step approach, 
        which is also known as <fr:strong>structural operational semantics</fr:strong>.
    </fr:p><fr:p>
        Formally, a small-step operational semantics for a language <fr:tex>T</fr:tex> of syntactic terms
        comprises two components:
        a set <fr:tex>S</fr:tex> of <fr:strong>execution states</fr:strong> and 
        a <fr:strong>transition relation</fr:strong> of type <fr:tex>S \to  S</fr:tex> that specifies how terms can be executed.
        If there is a transition from state <fr:tex>s</fr:tex> to state <fr:tex>s&apos;</fr:tex> in a single execution step, we write <fr:tex>s \to  s&apos;</fr:tex>.
    </fr:p><fr:p>
        Arithmetic expressions have a simple small-step operational semantics,
        given by taking <fr:tex>S</fr:tex> as the Haskell type. And we define transition relation 
        on <fr:code>Expr</fr:code> by the following inference rules.
        <fr:tex display="block">              \begin {align*}                  \frac {}{                      \text {Add} \space ( \text {Val} \space  n_1) \space ( \text {Val} \space  n_2) \to \text {Val} \space (n_1+n_2)                 }  \\                   \frac {x \to  x&apos;}{ \text {Add}   \space  x \space  y \to \text {Add}   \space  x&apos; \space  y}                   \quad                    \frac {y \to  y&apos;}{ \text {Add}   \space  x \space  y \to \text {Add}   \space  x \space  y&apos;}              \end {align*}         </fr:tex></fr:p><fr:p>
        The first rule states that two values can be added to give a single value and is called a
        <fr:strong>reduction</fr:strong> (or <fr:strong>contraction</fr:strong>) rule.
        An expression that matches such a rule is termed a reducible expression or <fr:strong>redex</fr:strong>.
        The last two rules are called <fr:strong>structural</fr:strong> (or <fr:strong>congruence</fr:strong>) rules as 
        they specify how larger terms can be reduced.
    </fr:p><fr:p>
        The semantics is <fr:strong>non-deterministic</fr:strong> because an expression
        may have more than one possible transition.
        This is obviously from the structural rules, which allow either sub-expression to be reduced first.
    </fr:p><fr:p>
        We can now capture a the relation between the denotational and operational semantics,
        namely that making a transition does not change the denotation of an expression.
        <fr:tex display="block">              \frac {                 e \to  e&apos;             }{                  \llbracket e \rrbracket  =  \llbracket e&apos; \rrbracket              }         </fr:tex>
        This property can be proved by induction on the structure of the expression <fr:tex>e</fr:tex>.
        Note that by using the &quot;equals by equals&quot; and the assumption <fr:tex>x \to  x&apos;</fr:tex> we can easily 
        prove the inductive case. The details are omitted here as it involves quite a bit of 
        case analysis. We will later see the <fr:strong>principle of rule induction</fr:strong>, which gives 
        a simpler and more direct way to prove such properties.
    </fr:p><fr:p>
        Evaluation of an expression using the small-step semantics proceeds by a series of zero
        or more transition steps. Formally we can write <fr:tex>e \to ^* e&apos;</fr:tex> to indicate that <fr:tex>e</fr:tex> can be
        reduced to <fr:tex>e&apos;</fr:tex> in zero or more steps.
        We can generate a transition tree that captures all possible execution
        paths for an expression. Using the list comprehension we can define a 
        function that returns the list of all expressions that can be reduced 
        from a given expression <fr:tex>e</fr:tex> in a single transition.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">trans :: Expr -&gt; [Expr]
trans (Val n) = []
trans (Add (Val n) (Val m)) = [Val (n + m)]
trans (Add x y) = [Add x&apos; y | x&apos; &lt;- trans x] ++ [Add x y&apos; | y&apos; &lt;- trans y]</html:code></fr:pre>
<fr:p>
        We can define a Haskell datatype for transition trees 
        and an execution function that converts expressions into 
        transition trees.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">data Tree a = Node a [Tree a]
exec :: Expr -&gt; Tree Expr
exec e = Node e [exec e&apos; | e&apos; &lt;- trans e]</html:code></fr:pre>
<fr:p>
        Though <fr:code>exec</fr:code> is defined recursively, its behavior can be understood as simply applying
        the identity function to give the root of the tree and the transition function to generate a 
        list of residual expressions to be processed to give the subtrees.
        A small-step semantics can be viewed as giving rise to an execution
        function that is defined by <fr:strong>unfolding</fr:strong> to transition trees.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">exec :: Expr -&gt; Tree Expr
exec = unfold id trans</html:code></fr:pre>
<fr:p>
        The <fr:code>unfold</fr:code> function captures the idea of generating a tree 
        from a seed value <fr:tex>x</fr:tex> by applying a function <fr:tex>f</fr:tex> to give the root 
        and a function <fr:tex>g</fr:tex> to give a list of residual values to be processed
        for the subtrees.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">unfold :: (t -&gt; a) -&gt; (t -&gt; [t]) -&gt; t -&gt; Tree a
unfold f g x = Node (f x) [unfold f g x&apos; | x&apos; &lt;- g x]</html:code></fr:pre>
<fr:p>
        The operational semantics corresponds to <fr:strong>unfolding to transition trees</fr:strong>,
        while denotational semantics corresponds to <fr:strong>folding over syntax trees</fr:strong>.
        Thinking about semantics in terms of recursion operators reveals a duality
    </fr:p><fr:p>
        The above semantics for expressions does not specify the order of evaluation.
        But we can modify the inference rules to achieve this. Replace the second <fr:tex>\text {Add}</fr:tex> 
        rule by the following rule ensures the first argument of addition is 
        always reduced first.
        <fr:tex display="block">              \frac {                 y \to  y&apos;             }{                  \text {Add}  ( \text {Val} \space  n) \space  y  \to   \text {Add}  ( \text {Val} \space  n) \space  y&apos;             }         </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>413</fr:anchor><fr:title>Rule induction</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        For denotational semantics we have structural induction,
        dual to this, for operational semantics we have <fr:strong>rule induction</fr:strong>.
        This allows us to perform proofs by considering the structure of the rules 
        that are used to define the semantics.
    </fr:p><fr:p>
        We introduce the idea of rule induction using a simple numeric example.
        We begin by inductively defining a set of natural numbers.
        <fr:tex display="block">                  \frac {}{0 \in \mathbb {N} }  \quad                    \frac {n \in \mathbb {N} }{n+1 \in \mathbb {N} }         </fr:tex>
        This is the standard definition of the natural numbers using peano axioms,
        where the first rule states that zero is a natural number and the second rule states that
        if <fr:tex>n</fr:tex> is a natural number then so is <fr:tex>n+1</fr:tex>.
    </fr:p><fr:p>
        For the inductively defined set <fr:tex>\mathbb {N}</fr:tex>. The principle of rule induction
        states that in order to prove a property <fr:tex>P(n)</fr:tex> for all natural numbers <fr:tex>n</fr:tex>,
        it suffices to prove that <fr:tex>P(0)</fr:tex> holds and that if <fr:tex>P(n)</fr:tex> holds then <fr:tex>P(n+1)</fr:tex> holds.
        <fr:tex display="block">              \frac {                 P(0) \quad \forall  n \in \mathbb {N} . P(n) \to  P(n+1)             }{                  \forall  n \in \mathbb {N} . P(n)             }         </fr:tex>
        Notice that this is the well-known <fr:strong>principle of mathematical induction</fr:strong>.
    </fr:p><fr:p>
        The concept of rule induction can easily be generalised to multiple base and 
        inductive cases, to rule with multiple preconditions and so on.
        For the small-step semantics of expressions, we have one base case and two inductive cases.
        Hence if we want to show that some property <fr:tex>P(e,e&apos;)</fr:tex> on pairs of expression holds for 
        all transition <fr:tex>e \to  e&apos;</fr:tex>, we can use rule induction:
        <fr:tex display="block">              \frac {                  \begin {align*}                     P( \text {Add} \space ( \text {Val} \space  n_1) \space ( \text {Val} \space  n_2), \text {Val} \space (n_1+n_2))  \\                       \forall  x \to  x&apos;. P(x,x&apos;) \to  P( \text {Add} \space  x \space  y, \text {Add} \space  x&apos; \space  y)  \\                       \forall  y \to  y&apos;. P(y,y&apos;) \to  P( \text {Add} \space  x \space  y, \text {Add} \space  x \space  y&apos;)                  \end {align*}             }{                  \forall  e \to  e&apos;. P(e,e&apos;)             }         </fr:tex>
        We write <fr:tex>\forall  x \to  y.P(x,y)</fr:tex> as shorthand for 
        <fr:tex display="block">\forall  x,y.x \to  y \Rightarrow  P(x,y)</fr:tex>. Now we give the proof 
        of the property <fr:tex>\llbracket e \rrbracket  =  \llbracket e&apos; \rrbracket</fr:tex> for all transitions <fr:tex>e \to  e&apos;</fr:tex>.
        <fr:tex display="block">              \forall  e \to  e&apos;.  \llbracket e \rrbracket  =  \llbracket e&apos; \rrbracket          </fr:tex></fr:p>
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>412</fr:anchor><fr:taxon>Proof</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date></fr:frontmatter><fr:mainmatter>
        The proof consists of three parts: the base case, the reduction rule and the structural rule.
        <fr:tex display="block">              \begin {align*}                  \llbracket \text {Add} \space ( \text {Val} \space  n) \space ( \text {Val} \space  m) \rrbracket                  &amp;=  \llbracket \text {Val} \space  n \rrbracket  +  \llbracket \text {Val} \space  m \rrbracket   \\                  &amp;= n + m  \\                  &amp;=  \llbracket \text {Val} \space (n+m) \rrbracket               \end {align*}         </fr:tex>
        and
        <fr:tex display="block">              \begin {align*}                  \llbracket \text {Add} \space  x \space  y \rrbracket                  &amp;=  \llbracket x \rrbracket  +  \llbracket y \rrbracket    \\                  &amp;=  \llbracket x&apos; \rrbracket  +  \llbracket y \rrbracket  ( \text {By assumption } \llbracket x \rrbracket = \llbracket x&apos; \rrbracket )  \\                  &amp;=  \llbracket \text {Add} \space  x&apos; \space  y \rrbracket               \end {align*}         </fr:tex>
        and 
        <fr:tex display="block">              \begin {align*}                  \llbracket \text {Add} \space  x \space  y \rrbracket                  &amp;=  \llbracket x \rrbracket  +  \llbracket y \rrbracket    \\                  &amp;=  \llbracket x \rrbracket  +  \llbracket y&apos; \rrbracket  ( \text {By assumption } \llbracket y \rrbracket = \llbracket y&apos; \rrbracket )  \\                   &amp;=  \llbracket \text {Add} \space  x \space  y&apos; \rrbracket               \end {align*}         </fr:tex>
    </fr:mainmatter></fr:tree>
 
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>419</fr:anchor><fr:title>Contextual Semantics</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The small-step semantics for expressions above has one basic reduction rule 
        for adding values and two structural rules that allow addition to be performed
        in larger expressions. Separating these two kinds of rules results 
        the notion of <fr:strong>contextual semantics</fr:strong> (or <fr:strong>reduction semantics</fr:strong>).
    </fr:p><fr:p>
        Informally, a context in this setting is a term with a &quot;<fr:strong>hole</fr:strong>&quot;, 
        usually written as <fr:tex>[-]</fr:tex>, which can be filled with another term later.
        In a contextual semantics, the hole represents the location where a <fr:strong>single</fr:strong>
        basic step of execution may take place within a term.
    </fr:p><fr:p>
        Consider the following transition in our small-step semantics.
        <fr:tex display="block">             (1+2)+(3+4) \to  3+(3+4)         </fr:tex>
        The addition is performed on the left side.
        We say that we can perform the basic step <fr:tex>1+2 \to3</fr:tex> in the 
        <fr:strong>context</fr:strong> <fr:tex>[-] +(3+4)</fr:tex> where <fr:tex>[-]</fr:tex> implies the location of the
        addition takes place.
    </fr:p><fr:p>
        The language <fr:tex>C</fr:tex> of contexts of arithmetic expressions can be formally defined by 
        <fr:tex display="block">             C: \equiv [-] |C+E|E+C         </fr:tex>
        As previously, we can define a Haskell datatype for contexts.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">data Cont = Hole | Add Cont Expr | Add Expr Cont</html:code></fr:pre>
<fr:p>
        The kind of context is known as &quot;outside-in&quot; as locating the hole involves
        navigating from the outside of the context inwards. To fill the hole in 
        a context <fr:tex>c</fr:tex> with an expression <fr:tex>e</fr:tex> we write <fr:tex>c \space [e]</fr:tex>:
        <fr:tex display="block">              \begin {align*}                  \text {Hole} \space [e] &amp;= e  \\                  ( \text {AddL} \space c \space r ) \space [e] &amp;=  \text {Add} \space  (c \space [e]) \space  r  \\                  ( \text {AddR} \space l \space c ) \space [e] &amp;=  \text {Add} \space  l \space (c \space [e])              \end {align*}         </fr:tex></fr:p><fr:p>
        Use the idea of hole filling we can redefine the small-step semantics
        for expressions in contextual style.
        <fr:tex display="block">              \frac {}{                  \text {Add} \space ( \text {Val} \space  n_1) \space ( \text {Val} \space  n_2) \rightarrowtail   \text {Val} \space (n_1+n_2)             }  \quad               \frac {                 e  \rightarrowtail  e&apos;             }{                 c \space  [e]  \to  c \space  [e&apos;]             }         </fr:tex>
        This first rule defines a reduction relation <fr:tex>\rightarrowtail</fr:tex> that captures the basic behavior of addition,
        while the second defines a transition relation <fr:tex>\to</fr:tex> that allows the first rule to be applied in 
        any context.
    </fr:p><fr:p>
        We have now refactored the small-step semantics into a single reduction rule and a single structural rule.
        If we subsequently want to extend the language with other features,
        it only requires adding new reduction rules and extending the notion of contexts
        but not need to adding new structural rules.
    </fr:p><fr:p>
        Now we define the hole filling function in Haskell.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">fill :: Cont -&gt; Expr -&gt; Expr
fill Hole e = e
fill (AddL c r) e = Add (fill c e) r
fill (AddR l c) e = Add l (fill c e)</html:code></fr:pre>
<fr:p>The dual operation which splits an expression into all possible pairs of 
    contexts and expressions can be defined:</fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">split :: Expr -&gt; [(Cont,Expr)]
split e = (Hole, e) : case e of
Val n -&gt; []
Add l r -&gt; [(AddL c r, x) | (c, x) &lt;- split l] ++ 
            [(AddR l c, x) | (c, x) &lt;- split r]</html:code></fr:pre>
<fr:p>
        A pair <fr:tex>(c,x)</fr:tex> comprising a context #[c] and an expression <fr:tex>x</fr:tex> is
        an element of the list returned by <fr:code>split e</fr:code> precisely when <fr:code>fill c x = e</fr:code>.
        The contextual semantics can be translated into Haskell function that returns
        the lists of all expressions that can be reached by performing a single reduction step.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">reduce :: Expr -&gt; [Expr]
reduce (Add (Val n) (Val m)) = [Val (n + m)]
reduce _ = []</html:code></fr:pre>
<fr:p>
        or a single transition step.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">trans :: Expr -&gt; [Expr]
trans e = [fill c x&apos; | (c, x) &lt;- split e, x&apos; &lt;- reduce x]</html:code></fr:pre>
<fr:p>
        This function splits the given expression into all possible context 
        and expression pairs, then considering any reduction that can made by each component
        expression, and finally filling the hole in the context with the reduced expression.
    </fr:p><fr:p>
        Notice that the contextual semantics does not specify an evaluation
        order for addition and is non-deterministic. We can modify the language
        of contexts to achieve so.
        <fr:tex display="block">             C: \equiv [-] |C+E| \mathbb {Z} +C         </fr:tex>
        This version of the semantics also satisfies a <fr:strong>unique decomposition property</fr:strong>,
        that is, any expression <fr:tex>e</fr:tex> that is not a value can be uniquely decomposed into the 
        form <fr:tex>e=c \space [x]</fr:tex> for some context <fr:tex>c</fr:tex> and reducible expression <fr:tex>x</fr:tex>. This can be 
        proved by induction on the expression <fr:tex>e</fr:tex>.
    </fr:p><fr:p>
        Contexts are related to a number of other important concepts in
        programming and semantics, including the use of continuations to make control flow
        explicit (John C. Reynolds 1972).
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>421</fr:anchor><fr:title>Big-step Semantics</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Big-step semantics is also known as <fr:strong>natural semantics</fr:strong>,
        which focus on large execution step. For a language T of syntactic terms
        comprises two components: a set <fr:tex>V</fr:tex> of values and 
        an evaluation relation between <fr:tex>T</fr:tex> and <fr:tex>V</fr:tex> that relates each term 
        to all values that can be reached by fully executing the term.
        If a term <fr:tex>t</fr:tex> and a value <fr:tex>v</fr:tex> are related, we say that <fr:tex>t</fr:tex> can evaluate to <fr:tex>v</fr:tex> 
        and write this as <fr:tex>t \Downarrow  v</fr:tex></fr:p><fr:tex display="block">          \frac {}{              \text {Val} \space  n \Downarrow  n         }          \quad           \frac {             x \Downarrow  n \quad  y \Downarrow  m          }{              \text {Add} \space  x \space  y \Downarrow  n+m         }     </fr:tex><fr:p>
        The Haskell function definition is similar to the small-step semantics,
        by using the list comprehension.
    </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval :: Expr -&gt; [Integer]
eval (Val n) = [n]
eval (Add x y) = [n + m | n &lt;- eval x, m &lt;- eval y]</html:code></fr:pre>
<fr:p>
        This is similar to denotational semantics but using inference rules
        rather than a functional manner.
        However, there is no need for a big-step semantics to be compositional.
        Formally, the denotational and big-step semantics for the expression language
        are equivalent, which can be captured by the following property:
        <fr:tex display="block">              \llbracket e \rrbracket  = n  \iff  e \Downarrow  n         </fr:tex>
        This is easily verified by induction.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>435</fr:anchor><fr:title>Abstract Machine</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date><fr:parent>cs-0006</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        All the exmaples we have meet focused on explaining semantic ideas,
        now we show how language of integers and addition can also be used to help 
        discover semantic ideas.
        We show how it can be used as the basis for discovering how to implement 
        an <fr:strong>abstract machine</fr:strong>.
    </fr:p><fr:p>
        Remember the evaluation order problem we meet before,
        if we want to make evaluation order explicit, we can introduce additional
        structure into the semantics by constructing an abstract machine.
    </fr:p><fr:p>
        Formally, an abstract machine is usually deifned by a set of syntactic rewrite ruless 
        that make explicit how each step of evaluation proceeds.
        This section we show how an abstract machine for our example language can 
        be systematically derived from the evaluation function using steps
        based on two important semantic concepts, <fr:strong>continuations</fr:strong> and <fr:strong>defunctionalisation</fr:strong>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>426</fr:anchor><fr:title>Add Continuations</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            We want to make the order of evaluation explicit in the semantics itself.
            A standard technique for achieving this aim is to rewrite the semantics
            in <fr:strong>continuation-passing style</fr:strong>. 
        </fr:p><fr:p>
            In our setting, a continuation is a function that will be applied to the result of an
            evaluation. Formally, for our semantics <fr:code>eval :: Expr -&gt; Integer</fr:code>, a continuation
            is a function of type <fr:code>Integer -&gt; Integer</fr:code> that will be applied to the resulting integer
            to give a new integer. (This type can be generalized to <fr:code>Integer -&gt; a</fr:code>, but we do not need now)
            We capture the notion of such a continuation using the following type declaration:
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">type Continuation = Integer -&gt; Integer</html:code></fr:pre>
<fr:p>
            We now define a new semantics <fr:tex>\text {eval}&apos;</fr:tex>, which takes an expression and returns
            an integer as previously but also takes a continuation as an additional argument,
            which is applied to the result of evaluating the expression.
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval&apos; :: Expr -&gt; Continuation -&gt; Integer</html:code></fr:pre>
<fr:p>
            The behavior of <fr:tex>\text {eval}&apos;</fr:tex> should be:
        </fr:p><fr:tex display="block">              \text {eval}&apos; \space  e \space  c =  \text {c (eval e)}         </fr:tex><fr:p>
            We want to calculate a definition that satisfies the specification.
            Using structural induction on the expression <fr:tex>e</fr:tex>, we construct 
            the term <fr:tex>\text {eval}&apos; \space  e \space  c</fr:tex> by gradually removing the reference to <fr:code>eval</fr:code>.
            For the base case, <fr:tex>e =  \text {Val} \space  n</fr:tex> we have
        </fr:p><fr:tex display="block">              \begin {align*}                  \text {eval}&apos; \space ( \text {Val} \space  n) \space  c                  &amp;= c \space  ( \text {eval} \space  ( \text {Val} \space  n))  \\                  &amp;= c \space  n              \end {align*}         </fr:tex><fr:p>
            For the inductive case, <fr:tex>e =  \text {Add} \space  x \space  y</fr:tex> we begin in the same way:
        </fr:p><fr:tex display="block">              \begin {align*}                  \text {eval}&apos; \space ( \text {Add} \space  x \space  y) \space  c                  &amp;= c \space  ( \text {eval} \space  ( \text {Add} \space  x \space  y))  \\                  &amp;= c \space  ( \text {eval} \space  x +  \text {eval} \space  y)              \end {align*}         </fr:tex><fr:p>
            However, no further definition can be applied now, so we consider the inductive hypothesis:
            Forall <fr:tex>c&apos;</fr:tex> and <fr:tex>c&apos;&apos;</fr:tex> we have <fr:tex>\text {eval}&apos; \space  x \space  c&apos; = c&apos;( \text {eval} \space  x)</fr:tex> and
            <fr:tex>\text {eval}&apos; \space  y \space  c&apos;&apos; = c&apos;&apos;( \text {eval} \space  y)</fr:tex>. This can readily be achieved by 
            abstracting over <fr:tex>\text {eval} \space  x</fr:tex> and <fr:tex>\text {eval} \space  y</fr:tex> using lambda abstraction.
        </fr:p><fr:tex display="block">              \begin {align*}                 &amp; c \space  ( \text {eval} \space  x +  \text {eval} \space  y)  \\                  =&amp; ( \lambda  n \to  c \space (n+ \text {eval} \space  y))  \\                  =&amp;  \text {eval}&apos; \space  x \space  ( \lambda  n \to  c \space (n+ \text {eval} \space  y))  \\                   =&amp;  \text {eval}&apos; \space  x \space  ( \lambda  n \to  ( \lambda  m \to  c \space (n+m))( \text {eval} \space  y))  \\                   =&amp;  \text {eval}&apos; \space  x \space  ( \lambda  n \to   \text {eval}&apos; \space  y \space  ( \lambda  m \to  c \space (n+m)))              \end {align*}         </fr:tex><fr:p>
            The final term does not refer to <fr:tex>\text {eval}</fr:tex> now.
            In summary we have calculated the following definition
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval&apos; :: Expr -&gt; Continuation -&gt; Integer
eval&apos; (Val n) c = c n 
eval&apos; (Add x y) c = eval&apos; x (\n -&gt; eval&apos; y (\m -&gt; c (n + m)))</html:code></fr:pre>
<fr:p>
            Our original semantics can be recovered from the new semantics by
            using the identity continuation <fr:tex>\lambda  n  \to  n</fr:tex></fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval e = eval&apos; e (\n -&gt; n)</html:code></fr:pre>
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>434</fr:anchor><fr:title>Defunctionalise</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>11</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            We use continuation to make the order of evaluation explicit in the semantics,
            but this also makes the semantics into a higher-order function.
            Hence our second step is to regain the first-order nature of the original semantics by 
            eliminating the use of continuations but <fr:strong>retaining</fr:strong> the explicit order of evaluation they introduced.
        </fr:p><fr:p>
            A standard technique for eliminating the use of functions as arguments is <fr:strong>defunctionalisation</fr:strong>.
            We do not usually need the entire function-space of possible argument functions, 
            there only a few forms of such functions are actually used.
            Hence we represent the argument functions that we actually need using 
            a datatype rather than functions.
        </fr:p><fr:p>
            We begin by defining three combinators <fr:strong>halt</fr:strong>, <fr:strong>next</fr:strong> and <fr:strong>add</fr:strong> 
            for constructing the continuations we used.
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">halt :: Continuation
halt n = n

next :: Expr -&gt; Continuation -&gt; Continuation
next y c = \n -&gt; eval&apos; y (add n c)

add :: Integer -&gt; Continuation -&gt; Continuation
add n c = \m -&gt; c (n + m)</html:code></fr:pre>
<fr:p>
            Use the combinators, our continuation semantics can now be written as:
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval :: Expr -&gt; Integer
eavl e = eval&apos; e halt

eval&apos; :: Expr -&gt; Continuation -&gt; Integer
eval&apos; (Val n) c = c n 
eval&apos; (Add x y) c = eval&apos; x (next y c)</html:code></fr:pre>
<fr:p>
            Now we declare a new datatype for continuations, consists of three constructors.
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">data CONT = HALT | NEXT Expr CONT | ADD Integer CONT</html:code></fr:pre>
<fr:p>
            The following translation function forms a denotational semantics for <fr:code>CONT</fr:code></fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">exec :: CONT -&gt; Continuation
exec HALT = halt
exec (NEXT y c) = next y (exec c)
exec (ADD n c) = add n (exec c)</html:code></fr:pre>
<fr:p>
            This function is usually called <fr:strong>apply</fr:strong>, which can be viewed as 
            applying a representation of a continuation to an integer to give another integer.
            We want to define a new semantics <fr:tex>\text {eval}&apos;</fr:tex> which behaves in the same way 
            as our previous <fr:tex>\text {eval}&apos;</fr:tex> except that it uses values of type <fr:code>CONT</fr:code> 
            rather than <fr:code>Continuation</fr:code>.
            
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval&apos;&apos; :: Expr -&gt; CONT -&gt; Integer</html:code></fr:pre>

            The desired behavior of <fr:tex>\text {eval}&apos;&apos;</fr:tex> is:
            <fr:tex display="block">                  \text {eval}&apos;&apos; \space  e \space  c =  \text {eval}&apos; \space  e \space  ( \text {exec} \space  c)             </fr:tex></fr:p><fr:p>
            As before, we proceed by structural induction on expression <fr:tex>e</fr:tex>.
            The base case <fr:tex>e= \text {Val} \space  n</fr:tex> is trivial
            <fr:tex display="block">                  \begin {align*}                      \text {eval}&apos;&apos; \space ( \text {Val} \space  n) \space  c                     &amp;=  \text {eval}&apos; \space ( \text {Val} \space  n) \space  ( \text {exec} \space  c)  \\                      &amp;=  \text {exec} \space  c \space  n  \\                   \end {align*}             </fr:tex></fr:p><fr:p>
            For the inductive case <fr:tex>e =  \text {Add} \space  x \space  y</fr:tex>:
            <fr:tex display="block">                  \begin {align*}                      \text {eval}&apos;&apos; \space ( \text {Add} \space  x \space  y) \space  c                      &amp;=  \text {eval}&apos; \space ( \text {Add} \space  x \space  y) \space  ( \text {exec} \space  c)  \\                      &amp;=  \text {eval}&apos; \space  x \space ( \text {next} \space  y \space ( \text {exec} \space  c))  \\                       &amp;=  \text {eval}&apos; \space  x \space ( \text {exec} \space ( \text {NEXT} \space  y \space  c))  \\                      &amp;=  \text {eval}&apos;&apos; \space  x \space  ( \text {NEXT} \space  y \space  c)                  \end {align*}             </fr:tex>
            The last step uses the inductive hypothesis for <fr:tex>x</fr:tex></fr:p><fr:p>
            In the basic case, <fr:tex>\text {exec}</fr:tex> still refers to the semantic <fr:tex>\text {eval}&apos;</fr:tex>,
            via the combinator <fr:tex>\text {next}</fr:tex>. Hence we need to compute a new definition 
            for <fr:tex>\text {exec}</fr:tex> that refers to our new <fr:tex>\text {eval}&apos;&apos;</fr:tex>.
        </fr:p><fr:tex display="block">              \begin {align*}                  \text {exec} \space \text {HALT} \space  n                  &amp;=  \text {halt} \space  n                  \\                   &amp;= n                              \end {align*}         </fr:tex><fr:p>The other case is also easy to compute, no need to induction.</fr:p><fr:tex display="block">              \begin {align*}                  \text {exec} \space ( \text {NEXT} \space  y \space  c) \space  n                  &amp;=  \text {eval}&apos;&apos; \space  y \space ( \text {ADD} \space  n \space  c)                  \\                    \text {exec} \space ( \text {ADD} \space  n \space  c) \space  m                  &amp;=  \text {exec} \space  c \space (n+m)              \end {align*}         </fr:tex><fr:p>
            Our original semantics <fr:tex>\text {eval}</fr:tex> can be recovered from the new 
            semantics <fr:tex>\text {eval}&apos;&apos;</fr:tex> too.
        </fr:p><fr:tex display="block">              \begin {align*}                  \text {eval} \space  e                  &amp;=  \text {eval}&apos; \space  e \space ( \lambda  n \to  n)  \\                   &amp;=  \text {eval}&apos; \space  e \space \text {halt}   \\                   &amp;=  \text {eval}&apos; \space  e \space ( \text {exec} \space \text {HALT} )  \\                   &amp;=  \text {eval}&apos;&apos; \space  e \text {HALT}               \end {align*}         </fr:tex><fr:p>
            In summary, we have calculated the following definitions:
        </fr:p>
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">eval&apos;&apos; :: Expr -&gt; CONT -&gt; Integer
eval&apos;&apos; (Val n) c = exec c n 
eval&apos;&apos; (Add x y) c = eval&apos;&apos; x (NEXT y c)

exec :: CONT -&gt; Integer -&gt; Integer
exec HALT n = n 
exec (NEXT y c) n = eval&apos;&apos; y (ADD n c)
exec (ADD n c) m = exec c (n + m)

eval :: Expr -&gt; Integer
eval e = eval&apos;&apos; e HALT</html:code></fr:pre>
<fr:p>
            The four components (<fr:tex>\text {eval}&apos;&apos;</fr:tex>, <fr:tex>\text {eval}</fr:tex>, <fr:tex>\text {exec}</fr:tex> and <fr:code>CONT</fr:code>)
            forms an abstract machine.
        </fr:p><fr:p><fr:code>CONT</fr:code> is the type of <fr:strong>control stack</fr:strong> which comprises 
            instructions that determine how the machine should continue after evaluating
            the current expression. Sometimes it is called an &quot;eval/continue&quot; machine.
            The control stack can also be defined as a list of instructions.
            
  <fr:pre><html:code xmlns:html="http://www.w3.org/1999/xhtml" class="language-haskell">type CONT = [INST]
data INST = NEXT Expr | ADD Integer</html:code></fr:pre></fr:p><fr:p><fr:tex>\text {eval}</fr:tex> evaluates an expression and give an integer by simply 
            call the <fr:tex>\text {eval}&apos;&apos;</fr:tex> with empty control stack <fr:tex>\text {HALT}</fr:tex>.
        </fr:p><fr:p><fr:tex>\text {eval}&apos;&apos;</fr:tex> evaluates an expression in the context of a control stack.
            If the expression is an integer, we execute the control stack using this 
            integer as an argument. If the expression is an addition, 
            we evaluate the first argument <fr:tex>x</fr:tex> and place the instruction <fr:tex>\text {NEXT} \space  y</fr:tex>
            on the top of the control stack.
        </fr:p><fr:p><fr:tex>\text {exec}</fr:tex> executes the control stack. If the control stack is empty,
            then just return the integer argument as the result. If the top instruction
            is <fr:tex>\text {NEXT} \space  y</fr:tex>, we evaluate <fr:tex>y</fr:tex> and place the instruction <fr:tex>\text {ADD} \space  n</fr:tex>
            to the stack top. If the top instruction is <fr:tex>\text {ADD} \space  n</fr:tex>,evaluation of the 
            two arguments of an addition is complete, and we execute the remaining control stack 
            in the context of the sum of the resulting integers.
        </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>455</fr:anchor><fr:taxon>Type Theory</fr:taxon><fr:addr>cs-0007</fr:addr><fr:route>cs-0007.xml</fr:route><fr:title>Categorical Semantics for Type Theories</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    This is a collection of notes on categorical semantics for type theories.
    The notes are based on the <fr:link href="cs-tt-2020.xml" type="local" addr="cs-tt-2020">paper</fr:link> by Jason Z.S. Hu and <fr:link href="ncatlab.xml" type="local" addr="ncatlab">NLab</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>437</fr:anchor><fr:title>Introduction</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date><fr:parent>cs-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Over the last few decades, many type systems are designed for different purposes:
        general program safety, security, and correctness. The <fr:strong>categorical semantics</fr:strong>
        is a collection of methods which define meanings of types and programs in category theory.
    </fr:p><fr:p>
        Category theory is a branch of mathematics studying an abstract kind of mappings, called morphisms,
        and their algebraic relations. Its generality serves as a common language for navigating connections
        between different concepts in different areas. We will first go over some basic concepts in category theory.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>442</fr:anchor><fr:title>Basic Category Theory concepts</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date><fr:parent>cs-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Formally, a definition in category theory consists of two parts: data and axioms.
        The most basic definition is the <fr:strong>category</fr:strong></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>438</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003E</fr:addr><fr:route>def-003E.xml</fr:route><fr:title>Category</fr:title></fr:frontmatter><fr:mainmatter>
    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>359</fr:anchor><fr:title><fr:strong>With one collection</fr:strong></fr:title><fr:parent>def-003E</fr:parent></fr:frontmatter><fr:mainmatter>
    A <fr:strong>category</fr:strong> <fr:tex>C</fr:tex> consists
    <fr:ul><fr:li>
            A collection of <fr:strong>objects</fr:strong> <fr:tex>C_0</fr:tex> (<fr:tex>\text {Ob} (C)</fr:tex>).
        </fr:li>
        <fr:li>
            A collection <fr:tex>C_1</fr:tex> (<fr:tex>\text {Mor} (C)</fr:tex>) of <fr:strong>morphisms</fr:strong> (arrows).
        </fr:li>
        <fr:li>
            For every morphism <fr:tex>f</fr:tex> there are an object <fr:tex>s(f)</fr:tex> (<fr:strong>source</fr:strong>, domain) and an object <fr:tex>t(f)</fr:tex> (<fr:strong>target</fr:strong>, codomain).
        </fr:li>
        <fr:li>
            For every pair of morphisms <fr:tex>f, g</fr:tex> such that <fr:tex>t(f) = s(g)</fr:tex>, there is a morphism <fr:tex>g  \circ  f</fr:tex> (<fr:strong>composition</fr:strong>) (Also written <fr:tex>gf</fr:tex> or <fr:tex>f;g</fr:tex>).
        </fr:li>
        <fr:li>
            For every object <fr:tex>x</fr:tex>, there is a morphism <fr:tex>\text {id} _x</fr:tex> (or <fr:tex>1_x</fr:tex>) called <fr:strong>identity</fr:strong>.
        </fr:li>
        <fr:li>
            The following properties hold:
            <fr:ul><fr:li><fr:tex>s(g  \circ  f) = s(f)</fr:tex> and <fr:tex>t(g  \circ  f) = t(g)</fr:tex>.
                </fr:li>
                <fr:li><fr:tex>s(1_x) = x</fr:tex> and <fr:tex>t(1_x) = x</fr:tex>.
                </fr:li>
                <fr:li>
                    Composition is <fr:strong>associative</fr:strong>: <fr:tex>h  \circ  (g  \circ  f) = (h  \circ  g)  \circ  f</fr:tex> when <fr:tex>t(f) = s(g)</fr:tex>, and <fr:tex>t(g) = s(h)</fr:tex>.
                </fr:li>
                <fr:li>
                    Composition satifies the <fr:strong>identity laws</fr:strong>: <fr:tex>f  \circ   \text {id} _x = f</fr:tex> and <fr:tex>\text {id} _y  \circ  f = f</fr:tex></fr:li></fr:ul></fr:li></fr:ul>
    If the identity map and its axioms are omitted then one speaks of a <fr:strong>semicategory</fr:strong>.
</fr:mainmatter></fr:tree>

    <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>360</fr:anchor><fr:title><fr:strong>With a family of collections of morphisms</fr:strong></fr:title><fr:parent>def-003E</fr:parent></fr:frontmatter><fr:mainmatter>
    A <fr:strong>category</fr:strong> <fr:tex>C</fr:tex> consists
    <fr:ul><fr:li>
            A collection of <fr:strong>objects</fr:strong> <fr:tex>C_0</fr:tex> (<fr:tex>\text {Ob} (C)</fr:tex>).
        </fr:li>
        <fr:li>
            For every pair of objects <fr:tex>x, y</fr:tex>, a collection <fr:tex>C_1(x, y)</fr:tex> (<fr:tex>\hom _C(x,y)</fr:tex>) of <fr:strong>morphisms</fr:strong> from <fr:tex>x</fr:tex> to <fr:tex>y</fr:tex>.
        </fr:li>
        <fr:li>
            For each pair of morphisms <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex> and <fr:tex>g</fr:tex> in <fr:tex>C_1(y,z)</fr:tex>, a morphism <fr:tex>g  \circ  f</fr:tex> in <fr:tex>C_1(x,z)</fr:tex>.
            called their <fr:strong>composition</fr:strong>.
        </fr:li>
        <fr:li>
            For each object <fr:tex>x</fr:tex>, a morphism <fr:tex>\text {id} _x</fr:tex> in <fr:tex>C_1(x,x)</fr:tex> called the <fr:strong>identity</fr:strong> on <fr:tex>x</fr:tex>.
        </fr:li>
        <fr:li>
            The following properties hold:
            <fr:ul><fr:li>Composition is <fr:strong>associative</fr:strong>: <fr:tex>h  \circ  (g  \circ  f) = (h  \circ  g)  \circ  f</fr:tex> for all <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex>, <fr:tex>g</fr:tex> in <fr:tex>C_1(y,z)</fr:tex>, and <fr:tex>h</fr:tex> in <fr:tex>C_1(z,w)</fr:tex>.</fr:li>
                <fr:li>Composition satifies the <fr:strong>identity laws</fr:strong>: <fr:tex>f  \circ   \text {id} _x = f</fr:tex> and <fr:tex>\text {id} _y  \circ  f = f</fr:tex> for all <fr:tex>f</fr:tex> in <fr:tex>C_1(x,y)</fr:tex>.</fr:li></fr:ul></fr:li></fr:ul>
    Usually we write <fr:tex>\text {Mor} (C)</fr:tex> for the disjoint union <fr:tex>\bigsqcup _{x,y  \in  C_0} C_1(x,y)</fr:tex>.
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:p>
        We only talk about <fr:strong>collections</fr:strong> here, which is vague, because we do not specify 
        they are sets or classes. If both objects and morphisms fit in sets, we say the category
        is <fr:strong>small</fr:strong>. For a counterexample, the category of all sets is not small. However,
        all functions between sets can be contained in a set. In this case, the category is <fr:strong>locally small</fr:strong>.
        When morphisms between two objects fit in a set, we call the set <fr:strong>hom-set</fr:strong>.
    </fr:p><fr:p>
        Since category theory is constructed to study structures and a category is actually a structure,
        we can talk about the category of all small categories <fr:tex>\mathbf {Cat}</fr:tex>. Similar to morphisms, we can 
        define <fr:strong>functor</fr:strong> between categories.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>439</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003G</fr:addr><fr:route>def-003G.xml</fr:route><fr:title>Functor</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>functor</fr:strong> <fr:tex>F</fr:tex> from a category <fr:tex>C</fr:tex> to a category <fr:tex>D</fr:tex> is a map
    sending each <fr:tex>x \in  C</fr:tex> to an object <fr:tex>F(x) \in  D</fr:tex> and each morphism
    <fr:tex>f:x \to  y</fr:tex> in <fr:tex>C</fr:tex> to morphism <fr:tex>F(f):F(x) \to  F(y)</fr:tex> in <fr:tex>D</fr:tex>, such that 
    <fr:ul><fr:li>
            Composition is preserved: <fr:tex>F(g \circ  f) = F(g) \circ  F(f)</fr:tex>.
        </fr:li>
        <fr:li>
            Identity is preserved: <fr:tex>F( \text {id} _x) =  \text {id} _{F(x)}</fr:tex>.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
        We can push this idea further by considering functors as objects and <fr:strong>natural transformations</fr:strong> as morphisms.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>440</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003I</fr:addr><fr:route>def-003I.xml</fr:route><fr:title>Functor Category</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>C</fr:tex> and <fr:tex>D</fr:tex> be categories, the functor category <fr:tex>D^C</fr:tex> 
    (or <fr:tex>[C,D]</fr:tex>) is the category whose
    <fr:ul><fr:li>
            objects are functors from <fr:tex>C</fr:tex> to <fr:tex>D</fr:tex>.
        </fr:li>
        <fr:li>
            morphisms are <fr:strong>natural transformations</fr:strong> between functors.
        </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
        Here we use a <fr:strong>commutative diagram</fr:strong> to represent a natural transformation.
        When a diagram commutes, morphisms composed by different paths with the same end points
        are equal. The following diagram represents the equality that <fr:tex>G(f) \circ \alpha _x =  \alpha _y \circ  F(f)</fr:tex>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>441</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003J</fr:addr><fr:route>def-003J.xml</fr:route><fr:title>Natural Transformation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>C</fr:tex> and <fr:tex>D</fr:tex> be categories and <fr:tex>F,G:C \to  D</fr:tex> be functors.
    A <fr:strong>natural transformation</fr:strong> <fr:tex>\alpha :F \Rightarrow   G</fr:tex> is 
    an assignment to every object <fr:tex>x \in  C</fr:tex> of a morphism <fr:tex>\alpha _x:F(x) \to  G(x)</fr:tex> in <fr:tex>D</fr:tex>,
    (called the <fr:strong>component</fr:strong> of <fr:tex>\alpha</fr:tex> at <fr:tex>x</fr:tex>)
    the following diagram commutes in <fr:tex>D</fr:tex>:
    
    <fr:embedded-tex hash="bce411235fd5c6731abb602d7c12b697"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            {F(x)} &amp;&amp; {F(y)}  \\ 
             \\ 
            {G(x)} &amp;&amp; {G(y)}
             \arrow [&quot;{F(f)}&quot;, from=1-1, to=1-3]
             \arrow [&quot;{G(f)}&quot;, from=3-1, to=3-3]
             \arrow [&quot;{ \alpha _x}&quot;, from=1-1, to=3-1]
             \arrow [&quot;{ \alpha _y}&quot;, from=1-3, to=3-3]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>447</fr:anchor><fr:title>Basic Category Theory Structures</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date><fr:parent>cs-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        Though the theory is already rich by only considering sets and categories, 
        it would not be interesting enough. We want to know a little more about the 
        category that we are working with. To achieve so, we can require some additional
        structures on the category. A common structure is the cartesian product.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>443</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003P</fr:addr><fr:route>def-003P.xml</fr:route><fr:title>Cartesian Product</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Given any category <fr:tex>\mathcal {C}</fr:tex>, and any set <fr:tex>\{ X_i \} _{i \in  I}</fr:tex> of
    its objects, the product of all these objects is, if it exists, an object
    <fr:tex>          \prod _{i \in  I} X_i  \in   \mathcal {C}     </fr:tex>
    equipped with morphisms (projections)
    <fr:tex display="block">         p_i :  \left ( \prod _{i \in  I} X_i \right )  \to  X_i     </fr:tex>
    for each <fr:tex>i \in  I</fr:tex>, such that it is <fr:strong>universal with this property</fr:strong>, i.e.
    such that given any other object <fr:tex>Q \in  C</fr:tex> with morphisms
    <fr:tex>         Q  \xrightarrow {f_i} X_i      </fr:tex>
    there is a <fr:strong>unique</fr:strong> morphism
    <fr:tex display="block">         (f_i)_{i \in  I} : Q  \to   \prod _{i \in  I} X_i     </fr:tex>
    where the following diagram commutes:
    
    <fr:embedded-tex hash="8571ab6c82137327eb6286482d37b972"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            Q  \\ 
             \\ 
            { \prod _{i \in  I} X_i} &amp;&amp; {X_i}
             \arrow [&quot;{p_i}&quot;, from=3-1, to=3-3]
             \arrow [&quot;{f_i}&quot;, from=1-1, to=3-3]
             \arrow [&quot;{(f_i)_{i \in  I}}&quot;&apos;, from=1-1, to=3-1]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex></fr:p></fr:mainmatter></fr:tree><fr:p>
        With this definition, it is natural to ask what can serve as a <fr:strong>nullary product</fr:strong>.
        The concept is characterized by terminal objects.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>444</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003Q</fr:addr><fr:route>def-003Q.xml</fr:route><fr:title>Terminal Object</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>terminal object</fr:strong> in a category <fr:tex>\mathcal {C}</fr:tex> is an object <fr:tex>\top</fr:tex> of <fr:tex>\mathcal {C}</fr:tex> 
    satisfying the following universal property: for any object <fr:tex>X</fr:tex> in <fr:tex>\mathcal {C}</fr:tex>,
    there exists a unique morphism <fr:tex>!:X \to   \top</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        When making math statements, we often encounter concepts that are dual to each other.
        In category theory, this phenomenon is captured by the concept of <fr:strong>duality</fr:strong>.
        Intuitively, duality offers us free dual theorem from the original one.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>445</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003R</fr:addr><fr:route>def-003R.xml</fr:route><fr:title>Opposite Category</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    For a category <fr:tex>\mathcal {C}</fr:tex>, the <fr:strong>opposite category</fr:strong> <fr:tex>\mathcal {C}^{op}</fr:tex> 
    has the same objects as <fr:tex>\mathcal {C}</fr:tex>, but the morphisms are reversed.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        For example, the product in the opposite category, all <fr:strong>universal properties</fr:strong> corresponds
        to a dual concept.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>446</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003S</fr:addr><fr:route>def-003S.xml</fr:route><fr:title>Coproduct</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    For <fr:tex>\mathcal {C}</fr:tex> a category and <fr:tex>X, Y  \in \text {Ob} { \mathcal {C}}</fr:tex>,
    the <fr:strong>coproduct</fr:strong> is an object <fr:tex>X \sqcup   Y</fr:tex> equipped with 
    two morphisms <fr:tex>i_X:X \to  X \sqcup   Y</fr:tex> and <fr:tex>i_Y:Y \to  X \sqcup   Y</fr:tex> such that
    it is universal with this property. That is, for any object <fr:tex>Z</fr:tex> and morphisms
    <fr:tex>f:X \to  Z</fr:tex> and <fr:tex>g:Y \to  Z</fr:tex>, there exists a unique morphism <fr:tex>\langle  f, g \rangle :X \sqcup   Y \to  Z</fr:tex>
    such that the following diagram commutes:
    
    <fr:embedded-tex hash="30ab044e12bbf7d397055a75bff79872"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
         \begin {tikzcd}
            X &amp;&amp; {X \sqcup  Y} &amp;&amp; Y  \\ 
             \\ 
            &amp;&amp; Z
             \arrow [&quot;{[f,g]}&quot;&apos;, dashed, from=1-3, to=3-3]
             \arrow [&quot;f&quot;&apos;, from=1-1, to=3-3]
             \arrow [&quot;{i_Y}&quot;&apos;, from=1-5, to=1-3]
             \arrow [&quot;{i_X}&quot;, from=1-1, to=1-3]
             \arrow [&quot;g&quot;, from=1-5, to=3-3]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>454</fr:anchor><fr:title>Logic, Types and Categories</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date><fr:parent>cs-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        One important principle in type theory is the <fr:strong>Curry-Howard Isomorphism</fr:strong> (Propositions as types).
        It depicts the connection between logic and types. A program can represent a logical argument, and 
        operations in logic find meaningful correspondences in program execution.
        The principle was later extended with category theory due to <fr:strong>Lambek</fr:strong>. In his work, he showed
        a correspondence between STLC and <fr:strong>Cartesian Closed Categories (CCC)</fr:strong> and revealed the connection
        between types and categories. The correspondence is called the <fr:strong>Curry-Howard-Lambek Isomorphism</fr:strong>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>448</fr:anchor><fr:title>Syntax and Semantics</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            In general, there are two approaches to understand or design a type system: the <fr:strong>syntactic</fr:strong> view 
            and <fr:strong>semantic</fr:strong> view.

            The syntactic view focuses on the syntactic structure of types and programs. We study about <fr:strong>subject reduction</fr:strong>,
            <fr:strong>cut elimination</fr:strong> and etc, simply by manipulating the syntax. It is usually more direct and easier to understand
            as it is often conducted via induction on some syntactic structures. And it also suggest algorithms which can be implemented.
            The disadvantage is that it is limited and hard to proof some properties like normalization.

            The semantic appoaches are more powerful in general. It is based on mathematics models of type systems.
            In exchange of the strength and generality, it is usually harder to understand and heavyweight, requries
            more intuition of the concepts.
        </fr:p><fr:p>
            One clasical semantic approach to logic is algebraic logic. A logical system is modeled by some algebraic theory.
            (often related to <fr:strong>lattices</fr:strong> and <fr:strong>semi-lattices</fr:strong>). Famous examples include <fr:strong>Boolean algebras</fr:strong>
            for classic propositional logic and <fr:strong>Heyting algebras</fr:strong> for intuitionistic counterpart. 
            The algebraic logic is a powerful tool to study the properties of logical systems, but has a limitation that 
            all operations are limited in one structured set.
        </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>451</fr:anchor><fr:title>Computations as Monads</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            An important result from ategorical semantics could be <fr:strong>monads</fr:strong>.
            In <fr:strong>Moggi</fr:strong>&apos;s paper, he showed that monads can be used to model computational effects.
        </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>449</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003T</fr:addr><fr:route>def-003T.xml</fr:route><fr:title>Monad</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    
    A <fr:strong>monad</fr:strong> of a category <fr:tex>\mathcal {C}</fr:tex> is an endofunctor <fr:tex>M: \mathcal {C} \to \mathcal {C}</fr:tex> with two natural
    transformations <fr:tex>\eta : \text {id} _{ \mathcal {C} } \Rightarrow  M</fr:tex> and <fr:tex>\mu :M^2 \Rightarrow  M</fr:tex> satisfying the following conditions:
    
    <fr:embedded-tex hash="e43e60118657fa7ecf74efa573d03648"><fr:embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </fr:embedded-tex-preamble><fr:embedded-tex-body>
         
                 \begin {tikzcd}
            {M^2(X)} &amp;&amp; {M(X)} &amp;&amp; {M^2(X)}  \\ 
            &amp;&amp; {M(X)}  \\ 
             \\ 
            &amp; {M^3(X)} &amp;&amp; {M^2(X)}  \\ 
            &amp; {M^2(X)} &amp;&amp; {M(X)}
             \arrow [&quot;{ \mu _{M(X)}}&quot;&apos;, from=4-2, to=5-2]
             \arrow [&quot;{ \mu _X}&quot;, from=5-2, to=5-4]
             \arrow [&quot;{1_{M(X)}}&quot;, from=1-3, to=2-3]
             \arrow [&quot;{ \mu _X}&quot;&apos;, from=1-1, to=2-3]
             \arrow [&quot;{M( \eta _X)}&quot;&apos;, from=1-3, to=1-1]
             \arrow [&quot;{ \eta _{ M(X)}}&quot;, from=1-3, to=1-5]
             \arrow [&quot;{ \mu _X}&quot;, from=1-5, to=2-3]
             \arrow [&quot;{ \mu _X}&quot;, from=4-4, to=5-4]
             \arrow [&quot;{M( \mu _X)}&quot;, from=4-2, to=4-4]
         \end {tikzcd}
     
    </fr:embedded-tex-body></fr:embedded-tex></fr:p></fr:mainmatter></fr:tree><fr:p>
            It requires an operation over functors named <fr:strong>whiskering</fr:strong></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>450</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003U</fr:addr><fr:route>def-003U.xml</fr:route><fr:title>Whiskering</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>F,G:C \to  D</fr:tex> and <fr:tex>H,D \to  E</fr:tex> be functors and <fr:tex>\eta :F \to  G</fr:tex> be a natural 
    transformation whose coordinate at any object <fr:tex>A</fr:tex> of <fr:tex>C</fr:tex> is <fr:tex>\eta _A</fr:tex>, then 
    <fr:strong>whiskering</fr:strong> <fr:tex>H</fr:tex> and <fr:tex>\eta</fr:tex> yields the natural transformation 
    <fr:tex>H \circ \eta :H \circ  F \to  H \circ  G</fr:tex> whose coordinate at <fr:tex>A</fr:tex> is <fr:tex>H( \eta _A)</fr:tex>.
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>453</fr:anchor><fr:title>Logic as Adjoint Functors</fr:title><fr:date><fr:year>2024</fr:year><fr:month>3</fr:month><fr:day>21</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
            Categorical logic is a new approach to logic, due to <fr:strong>Lawvere</fr:strong>. 
            He showed that logical constructs are fundamentally just <fr:strong>adjoint functors</fr:strong>.
            This allows us to capture many logical constructs by using only one categorical concept.
            Adjoint also provides a strong guarantee about the derived syntactic formulation.
        </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>452</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003V</fr:addr><fr:route>def-003V.xml</fr:route><fr:title>Adjoint Functor</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>\mathcal {C}</fr:tex> and <fr:tex>\mathcal {D}</fr:tex> be categories and a pair of functors 
    <fr:tex>F: \mathcal {C} \to \mathcal {D}</fr:tex> and <fr:tex>G: \mathcal {D} \to \mathcal {C}</fr:tex>. This is called 
    pair of <fr:strong>adjoint functors</fr:strong> (or <fr:strong>adjunction</fr:strong>) with <fr:tex>F</fr:tex> the left adjoint
    and <fr:tex>G</fr:tex> the right adjoint denoted 
    <fr:tex display="block">         F \dashv  G     </fr:tex>
    if there is a natural isomorphism between the hom-functors:
    <fr:tex display="block">          \hom _{ \mathcal {D}}(F(-),-) \cong \hom _{ \mathcal {C}}(-,G(-))     </fr:tex>
    which means forall objects <fr:tex>C \in \mathcal {C}</fr:tex> and <fr:tex>D \in \mathcal {D}</fr:tex>, there is a bijection
    <fr:tex display="block">          \hom _{ \mathcal {D}}(F(C),D) \cong \hom _{ \mathcal {C}}(C,G(D))  \\           (F(C) \xrightarrow {f}D)  \mapsto  (C \xrightarrow {G(f)}G(D))     </fr:tex>
    which is natural in both <fr:tex>C</fr:tex> and <fr:tex>D</fr:tex>.                                                                     
</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>469</fr:anchor><fr:taxon>Differential Geometry</fr:taxon><fr:addr>math-0007</fr:addr><fr:route>math-0007.xml</fr:route><fr:title>Vector Calculus and Geometry of Space</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:p>
    Notes about multi-variable calculus, geometry of space and linear algebra.
    Refer to <fr:link href="A%20Visual%20Introduction%20to%20Differential%20Forms%20and%20Calculus%20on%20Manifolds" type="external">df-cm-2018</fr:link>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>458</fr:anchor><fr:title>Review of Vector Spaces</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date><fr:parent>math-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        We now start with introducing the vector space over the field of real numbers <fr:tex>\mathbb {R}</fr:tex>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>456</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-000H</fr:addr><fr:route>def-000H.xml</fr:route><fr:title>Vector Space</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A vector space over a <fr:link href="def-0006.xml" type="local" addr="def-0006">field</fr:link> <fr:tex>F</fr:tex> is a non-empty set <fr:tex>V</fr:tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <fr:tex>V</fr:tex> are commonly called <fr:strong>vectors</fr:strong>, and the elements of <fr:tex>F</fr:tex> are called <fr:strong>scalars</fr:strong>.
    <fr:ul><fr:li>Commutativity: <fr:tex>              \forall  x, y  \in  V, x + y = y + x         </fr:tex></fr:li>
        <fr:li>Associativity: <fr:tex>              \forall  x, y, z  \in  V, (x + y) + z = x + (y + z)         </fr:tex></fr:li>
        <fr:li>Additive Identity: <fr:tex>              \exists  0  \in  V  \text { such that }  \forall  x  \in  V, x + 0 = x         </fr:tex></fr:li>
        <fr:li>Multiplicative Identity: <fr:tex>              \forall  x  \in  V, 1x = x         </fr:tex></fr:li>
        <fr:li>Additive Inverse: <fr:tex>              \forall  x  \in  V,  \exists  y  \in  V  \text { such that } x + y = 0         </fr:tex></fr:li>
        <fr:li>Distributivity: <fr:tex>              \forall  x, y  \in  V,  \forall  c, d  \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx         </fr:tex></fr:li></fr:ul></fr:p><fr:p>
    Elements of a vector space are called <fr:strong>vectors</fr:strong> or <fr:strong>points</fr:strong>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        Use <fr:tex>\mathbb {R} ^2</fr:tex> as an example we can see (Note that we always treat elements of vector spaces as 
        column vectors and never as row vectors):
        <fr:tex display="block">             c  \cdot   \begin {bmatrix}                 a  \\  b              \end {bmatrix} =  \begin {bmatrix}                 c  \cdot  a  \\  c  \cdot  b              \end {bmatrix}         </fr:tex></fr:p><fr:p>
        Now we will consider a certain type of transformation between vector spaces called a <fr:link href="def-0025.xml" type="local" addr="def-0025"><fr:strong>linear transformation</fr:strong></fr:link>.
        Suppose <fr:tex>T</fr:tex> is a mapping between <fr:tex>\mathbb {R} ^n</fr:tex> and <fr:tex>\mathbb {R} ^m</fr:tex>, that is <fr:tex>T: \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex>, then <fr:tex>T</fr:tex> is a linear transformation if:
        <fr:tex display="block">             T(c  \cdot   \vec {v}) = c  \cdot  T( \vec {v})              \\               T( \vec {v} +  \vec {w}) = T( \vec {v}) + T( \vec {w})         </fr:tex>
        If <fr:tex>T</fr:tex> is a linear transformation from <fr:tex>\mathbb {R} ^m</fr:tex> to <fr:tex>\mathbb {R}</fr:tex> we simply call it a <fr:strong>linear function</fr:strong> or a <fr:strong>linear functional</fr:strong>.
    </fr:p><fr:p>
        We now turn our attention to the relationship between linear transformation and matrices. 
        We just stick to vector spaces <fr:tex>\mathbb {R} ^n</fr:tex> and the standard basis made up of the <fr:strong>Euclidian unit vectors</fr:strong>.
        In order to write linear transformation <fr:tex>T: \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex> as a matrix we need ordered bases for both <fr:tex>\mathbb {R} ^n</fr:tex> and <fr:tex>\mathbb {R} ^m</fr:tex>.
        We can use the intuitively obvious order <fr:tex>e_1 &lt; e_2 &lt;  \cdots  &lt; e_n</fr:tex>.
        Now we can give formal definition of the matrix representation of a linear transformation.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>457</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003W</fr:addr><fr:route>def-003W.xml</fr:route><fr:title>Matrix Representation of Linear Transformation over <fr:tex>\mathbb {R} ^n</fr:tex></fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Suppose that <fr:tex>T: \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex> is a linear transformation between vector spaces <fr:tex>\mathbb {R} ^n</fr:tex> and <fr:tex>\mathbb {R} ^m</fr:tex>.
    Let <fr:tex>e_1, e_2,  \ldots , e_n</fr:tex> be the standard basis of <fr:tex>\mathbb {R} ^n</fr:tex> and <fr:tex>f_1, f_2,  \ldots , f_m</fr:tex> be the standard basis of <fr:tex>\mathbb {R} ^m</fr:tex>.
    Then the matrix representation of <fr:tex>T</fr:tex> is the <fr:tex>m  \times  n</fr:tex> matrix <fr:tex>A</fr:tex> such that for <fr:tex>1 \leq  j \leq  n</fr:tex>:
    <fr:tex display="block">         T(e_j) =  \sum _{i=1}^m A_{ij} f_i     </fr:tex>
    where the matrix representation of <fr:tex>T</fr:tex> is given by the <fr:tex>m \times  n</fr:tex> matrix with entries <fr:tex>A_{ij}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        The last major topic in this section is the definition of the <fr:link href="def-003X.xml" type="local" addr="def-003X">dual space</fr:link>.
        In our discussion, we only concern the dual space of <fr:tex>\mathbb {R} ^n</fr:tex> which is denoted as <fr:tex>( \mathbb {R} ^n)^*</fr:tex>.
        Now let&apos;s consider the <fr:strong>dual basis</fr:strong> of <fr:tex>( \mathbb {R} ^n)^*</fr:tex> which is denoted as <fr:tex>\{ T_1,  \cdots , T_n \}</fr:tex>, 
        which is defined by:
        <fr:tex display="block">             T_i(e_j) = e^i(e_j) =  \langle  e^i, e_j  \rangle  =  \delta _{j}^i         </fr:tex>
        where <fr:tex>\delta _{ij}</fr:tex> is the <fr:link href="def-001P.xml" type="local" addr="def-001P">Kronecker delta</fr:link>. We say that <fr:tex>T_i</fr:tex> is dual to the vector <fr:tex>e_i</fr:tex>.
        Note that we also denote <fr:tex>T_i</fr:tex> as <fr:tex>e^i</fr:tex> using superscript notation. And the notation <fr:tex>\langle  e^i, e_j  \rangle</fr:tex> d
        indicates the products of row vector <fr:tex>e^i</fr:tex> and column vector <fr:tex>e_j</fr:tex> (Usually used in quantum computing).
        <fr:tex display="block">              \alpha (v) =  \langle   \alpha , v  \rangle  = [a,b]  \times   \begin {bmatrix}                 x  \\  y              \end {bmatrix} = ax + by         </fr:tex>
        This explains wht we always denote elements of the vector space as column vectors, because elements of the dual space 
        are written as row vectors and its very important to distinguish between them.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>461</fr:anchor><fr:title>Dot Products</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date><fr:parent>math-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        In linear algebra, <fr:strong>dot product</fr:strong> or <fr:strong>scalar product</fr:strong> is an operation that takes two vectors and returns a scalar.
        Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them.
        Dot product is also used to define lengths and angles.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>459</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0041</fr:addr><fr:route>def-0041.xml</fr:route><fr:title>Dot Product (Coordinate Form)</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>dot product</fr:strong> of two vectors <fr:tex>\vec {a} = (a_1, a_2,  \cdots , a_n)</fr:tex> and <fr:tex>\vec {b} = (b_1, b_2,  \cdots , b_n)</fr:tex> is defined as
    <fr:tex display="block">          \vec {a} \cdot \vec {b} = a_1b_1 + a_2b_2 +  \cdots  + a_nb_n =  \sum _{i=1}^n a_ib_i.     </fr:tex>
    The dot product is also called the <fr:strong>inner product</fr:strong> or <fr:strong>scalar product</fr:strong>.
    The dot product satisfies the following properties:
    <fr:ul><fr:li><fr:strong>Commutative</fr:strong>: <fr:tex>\vec {a} \cdot \vec {b} =  \vec {b} \cdot \vec {a}</fr:tex></fr:li>
        <fr:li><fr:strong>Distributive</fr:strong>: <fr:tex>\vec {a} \cdot ( \vec {b} +  \vec {c}) =  \vec {a} \cdot \vec {b} +  \vec {a} \cdot \vec {c}</fr:tex></fr:li>
        <fr:li><fr:strong>Bilinear</fr:strong>: <fr:tex>\vec {a} \cdot (k \vec {b}) = k( \vec {a} \cdot \vec {b}) = ( \vec {a} \cdot  k \vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Scalar Multiplication</fr:strong>: <fr:tex>(c_1 \vec {a})  \cdot  (c_2 \vec {b}) = c_1c_2( \vec {a} \cdot \vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Orthogonality</fr:strong>: If <fr:tex>\vec {a} \cdot \vec {b} = 0</fr:tex>, then <fr:tex>\vec {a}</fr:tex> and <fr:tex>\vec {b}</fr:tex> are <fr:strong>orthogonal</fr:strong></fr:li>
        <fr:li><fr:strong>Product Rule</fr:strong>: If <fr:tex>\vec {a}</fr:tex> and <fr:tex>\vec {b}</fr:tex> are vector valued differentiable functions then the derivative 
            of <fr:tex>\vec {a} \cdot \vec {b}</fr:tex> is given by the rule <fr:tex>( \vec {a} \cdot \vec {b})&apos; =  \vec {a}&apos; \cdot \vec {b} +  \vec {a} \cdot \vec {b}&apos;</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>460</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0042</fr:addr><fr:route>def-0042.xml</fr:route><fr:title>Dot Product (Geometric Form)</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    In <fr:strong>Euclidean space</fr:strong>, a <fr:strong>Euclidean vector</fr:strong> is a geometric object that possesses both 
    a norm and a direction. The <fr:strong>dot product</fr:strong> of two vectors <fr:tex>\vec {a}</fr:tex> and <fr:tex>\vec {b}</fr:tex> is defined as
    <fr:tex display="block">          \vec {a} \cdot \vec {b} =  \lVert \vec {a} \rVert \lVert \vec {b} \rVert \cos \theta      </fr:tex>
    where <fr:tex>\theta</fr:tex> is the angle between the two vectors.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        The geometric definition of dot product helps us express the projection of one vector onto another as well as the component of 
        one vector in the direction of another. By simple geometry we can derive the formula for the <fr:strong>projection</fr:strong>
        <fr:tex display="block">              \text {proj}_{ \vec {a}} \vec {b} =  \frac { \vec {a} \cdot \vec {b}}{ \lVert \vec {a} \rVert } \frac { \vec {a}}{ \lVert \vec {a} \rVert }         </fr:tex>
        and the <fr:strong>component</fr:strong> of <fr:tex>\vec {b}</fr:tex> in the direction <fr:tex>\vec {a}</fr:tex> is given by
        <fr:tex display="block">              \text {comp}_{ \vec {a}} \vec {b} =  \lVert \text {proj}_{ \vec {a}} \vec {b} \rVert  =  \frac { \vec {a} \cdot \vec {b}}{ \lVert \vec {a} \rVert }         </fr:tex></fr:p><fr:p>
        Two points determine a line, and so does a point and a vector. Define the base point vector <fr:tex>\vec {b}=(x,y,z)</fr:tex> and
        the direction vector <fr:tex>\vec {v}=(a,b,c)</fr:tex> then the line is given by <fr:tex>\vec {r}(t)</fr:tex>
        <fr:tex display="block">              \vec {r}(t) = t \vec {v} +  \vec {b} = (at+x, bt+y, ct+z)         </fr:tex>
        Solving for <fr:tex>t</fr:tex> in the equation we get
        <fr:tex display="block">             t =  \frac {x-at}{a} =  \frac {y-bt}{b} =  \frac {z-ct}{c}         </fr:tex>
        which is the <fr:strong>equation of line</fr:strong>.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>467</fr:anchor><fr:title>Volume and Determinants</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date><fr:parent>math-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The <fr:strong>determinant</fr:strong> has various properties and applications in linear algebra and geometry.
        For us the most useful thing about it will be how it relates to volume:
        the determinant of a matrix gives the <fr:strong>signed volume</fr:strong> of the parallelepiped that 
        is generated by the vectors given by the matrix columns.
    </fr:p><fr:p>
        Determinants can be introduced in a variety of different ways but many of them are not at all clear.
        It usually relates to volume hence we will actually use our intuitive understanding of volumes and 
        three properties that we expected volume to have to derive the determinant (It is <fr:strong>uniquely</fr:strong> determined!).
    </fr:p><fr:p>
        So how do we expect volume to behave?
        First we expect a unit cube to have a volume of one.
        Second we expect the <fr:strong>degenerate</fr:strong> parallelepiped to have a volume of zero. Basically in <fr:tex>n</fr:tex> dimensions any 
        <fr:tex>n-1</fr:tex> dimensions object has zero <fr:tex>n</fr:tex>-D volume.
        Third we expect that volumes to be <fr:strong>linear</fr:strong>.
        Now with these three properties we move to the actual mathematics.
    </fr:p><fr:p>
        Suppose we have a parallelepiped <fr:tex>\mathscr {P} \in \mathbb {R} ^n</fr:tex> whose edges are given by <fr:tex>v_1, v_2,  \cdots , v_n \in \mathbb {R} ^n</fr:tex>.
        We sat that the parallelepiped <fr:tex>\mathscr {P}</fr:tex> is the <fr:strong>span</fr:strong> of the vectors <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> and 
        write <fr:tex>\mathscr {P}= \text {span} \{ v_1, v_2,  \cdots , v_n \}</fr:tex> (Note that this span is different from linear span).
        We want to find function <fr:tex>D: \mathbb {R} ^{n \times  n} \to \mathbb {R}</fr:tex> which takes <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> or a matrix with <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> as columns
        to a real number which is the volume of <fr:tex>\mathscr {P}</fr:tex>. Now we present the three properties in mathematical form.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>462</fr:anchor><fr:title>Properties of Volume</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:ul><fr:li><fr:tex> D(I) = I </fr:tex> where <fr:tex>I = [e_1, e_2,  \cdots , e_n]</fr:tex> is the identity matrix.
            </fr:li>
            <fr:li><fr:tex> D(v_1, v_2,  \cdots , v_n) = 0 </fr:tex> if <fr:tex>v_i = v_j</fr:tex> for any <fr:tex>i \neq  j</fr:tex>.
            </fr:li>
            <fr:li><fr:tex> D(v_1,  \cdots , v_{j-1}, v+cw, v_{j+1},  \cdots , v_n)  \\                   = D(v_1,  \cdots , v_{j-1}, v, v_{j+1},  \cdots , v_n) + cD(v_1,  \cdots , v_{j-1}, w, v_{j+1},  \cdots , v_n) </fr:tex>
                for any <fr:tex>1  \leq  j  \leq  n</fr:tex>, that is, <fr:tex>D</fr:tex> is linear.
            </fr:li></fr:ul></fr:mainmatter></fr:tree><fr:p>
        Now we use these properties of volume to derive several other useful properties.
        The first property is that the volumes are signed.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>463</fr:anchor><fr:title>Derived Properties of Volume Function</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date></fr:frontmatter><fr:mainmatter><fr:ul><fr:li><fr:tex>D</fr:tex> is alternating, if we switch any two vectors the sign changes.
                <fr:tex display="block">                     D(v_1,  \cdots , v_i,  \cdots , v_j,  \cdots , v_n) = -D(v_1,  \cdots , v_j,  \cdots , v_i,  \cdots , v_n)                 </fr:tex></fr:li> 
            <fr:li>
                If <fr:tex>v_1, v_2,  \cdots , v_n</fr:tex> are <fr:link href="def-000Q.xml" type="local" addr="def-000Q">linear dependent</fr:link> then
                <fr:tex display="block">                     D(v_1, v_2,  \cdots , v_n) = 0                 </fr:tex></fr:li>
            <fr:li>
                Adding a multiple of one vector to another does not change the determinant.
            </fr:li></fr:ul></fr:mainmatter></fr:tree><fr:p>
        We almost ready to derive the formula for determinant. The final ingredient we need to do is <fr:strong>permutations</fr:strong>.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>464</fr:anchor><fr:taxon>Defintion</fr:taxon><fr:addr>def-003Y</fr:addr><fr:route>def-003Y.xml</fr:route><fr:title>Permutation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>permutation</fr:strong> of a set <fr:tex>S</fr:tex> is a bijection from <fr:tex>S</fr:tex> to itself.
    The set of permutation of <fr:tex>\{ 1, \cdots , n \}</fr:tex> is usually denoted by <fr:tex>S_n</fr:tex>.
    We often denote a particular permutation <fr:tex>\sigma</fr:tex> by <fr:strong>Cauchy&apos;s two-line notation</fr:strong>:
    <fr:tex display="block">          \begin {bmatrix}             1 &amp; 2 &amp;  \cdots  &amp; n  \\               \sigma (1) &amp;  \sigma (2) &amp;  \cdots  &amp;  \sigma (n)          \end {bmatrix}     </fr:tex>
    or <fr:strong>Cauchy&apos;s one-line notation</fr:strong>: <fr:tex>( \sigma (1), \sigma (2), \cdots , \sigma (n))</fr:tex>.
    Another common notation is the <fr:strong>cycle notation</fr:strong>:
    <fr:tex display="block">         (i_1 \  i_2 \  \cdots \  i_k)     </fr:tex> which means <fr:tex>i_1  \to  i_2  \to   \cdots   \to  i_k  \to  i_1</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>465</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-003Z</fr:addr><fr:route>def-003Z.xml</fr:route><fr:title>Transposition</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:link href="def-003Y.xml" type="local" addr="def-003Y">permutation</fr:link> in which only two elements are exchanged is called a <fr:strong>transposition</fr:strong>.
    The notation is <fr:tex>\tau _{i,j}</fr:tex> where <fr:tex>i</fr:tex> and <fr:tex>j</fr:tex> are the two elements exchanged while the others remain fixed.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        Notice that the composition of two permutations is also a permutation. 
        And for any permutation <fr:tex>\sigma</fr:tex> we can perform a series of transpositions to get the identity permutation.
        It turns out that the count of the number of transpositions needed to get the identity permutation is always the same,
        which is called the <fr:strong>parity</fr:strong> of the permutation.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>466</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0040</fr:addr><fr:route>def-0040.xml</fr:route><fr:title>Sign of Permutation</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>sign</fr:strong> of a <fr:link href="def-003Y.xml" type="local" addr="def-003Y">permutation</fr:link> <fr:tex>\sigma \in  S_n</fr:tex> is a function <fr:tex>\text {sgn} :S_n \to \{ -1,1 \}</fr:tex> defined as
    <fr:tex>\text {sgn} ( \sigma ) = 1</fr:tex> if <fr:tex>\sigma</fr:tex> requires an even number of permutations and 
    <fr:tex>\text {sgn} ( \sigma ) = -1</fr:tex> if <fr:tex>\sigma</fr:tex> requires an odd number of permutations to get the identity permutation.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        Now we define the permutation of unit vectors <fr:tex>E_ \sigma  = [e_{ \sigma (1)}, e_{ \sigma (2)},  \cdots , e_{ \sigma (n)}]</fr:tex>.
        We got the property that
        <fr:tex display="block">             D(E_ \sigma ) =  \text {sgn} ( \sigma )D(I) =  \text {sgn} ( \sigma )         </fr:tex>
        Now we have all the pieces necessary to find a formula that will give the volume of the parallelepiped spanned
        by <fr:tex>n</fr:tex> vectors.
        <fr:tex display="block">              \begin {align*}                 D \left ( \begin {bmatrix}                     a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\                      a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\                       \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                      a_{n1} &amp; a_{n2} &amp;  \cdots  &amp; a_{nn}                  \end {bmatrix} \right ) &amp;=  \sum _{i_1=1}^n a_{i_11}D \left ( \begin {bmatrix}                     | &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\                      e_{i_1} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\                      | &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                      | &amp; a_{n2} &amp;  \cdots  &amp; a_{nn}                  \end {bmatrix} \right )  \\                   &amp;=  \sum _{i_1=1}^n a_{i_11}  \sum _{i_2=1}^n a_{i_22}D \left ( \begin {bmatrix}                     | &amp; | &amp;  \cdots  &amp; a_{1n}  \\                      e_{i_1} &amp; e_{i_2} &amp;  \cdots  &amp; a_{2n}  \\                      | &amp; | &amp;  \vdots  &amp;  \vdots   \\                      | &amp; | &amp;  \cdots  &amp; a_{nn}                  \end {bmatrix} \right )  \\                  &amp;=  \vdots   \\                   &amp;=  \sum _{i_1, i_2,  \cdots , i_n = 1}^{n} a_{i_11}a_{i_22} \cdots  a_{i_nn}D \left (                      \begin {bmatrix}                         | &amp; | &amp;  &amp; |  \\                          e_{i_1} &amp; e_{i_2} &amp;  \cdots  &amp; e_{i_n}  \\                          | &amp; | &amp;  &amp; |  \\                       \end {bmatrix}                  \right )  \\                   &amp;=  \sum _{ \sigma \in  S_n} a_{ \sigma (1)1} \cdots  a_{ \sigma (n)n}                 D \left (                      \begin {bmatrix}                         | &amp; | &amp;  &amp; |  \\                          e_{ \sigma (1)} &amp; e_{ \sigma (2)} &amp;  \cdots  &amp; e_{ \sigma (n)}  \\                          | &amp; | &amp;  &amp; |  \\                       \end {bmatrix}                  \right )  \\                   &amp;=  \sum _{ \sigma \in  S_n} a_{ \sigma (1)1}a_{ \sigma (2)2} \cdots  a_{ \sigma (n)n}  \text {sgn} ( \sigma )  \\                   &amp;=  \sum _{ \sigma \in  S_n}  \text {sgn} ( \sigma )  \prod _{i=1}^n a_{ \sigma (i)i}              \end {align*}         </fr:tex>
        In the forth step we transform the terms because the value of <fr:tex>D</fr:tex> is zero for any <fr:tex>{i_j} = {i_k}</fr:tex>,
        non-zero terms should be permutation of <fr:tex>S_n</fr:tex>.
    </fr:p><fr:p>
        It&apos;s easy to validate that the following properties of the determinant holds:
        <fr:ul><fr:li><fr:tex>D(AB) = D(A)D(B)</fr:tex></fr:li>
            <fr:li><fr:tex>D(A) = D(A^T)</fr:tex></fr:li></fr:ul>
        The second statement for transpose of <fr:tex>A</fr:tex> indicates that all the properties above also holds for row as well. 
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>468</fr:anchor><fr:title>Derivatives of Multivariable Functions</fr:title><fr:date><fr:year>2024</fr:year><fr:month>4</fr:month><fr:day>5</fr:day></fr:date><fr:parent>math-0007</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        In this section we will introduce the idea of the derivative of a multivariable function. 
        Recall that a function <fr:tex>f: \mathbb {R} \to \mathbb {R}</fr:tex> the derivative of <fr:tex>f</fr:tex> at <fr:tex>x_0 \in \mathbb {R}</fr:tex> is given by
        <fr:tex display="block">             f&apos;(x_0) =  \lim _{h \to  0}  \frac {f(x_0+h) - f(x_0)}{h}         </fr:tex>
        if the limit exists. Now let&apos;s do some transformations:
        <fr:tex display="block">              \begin {align*}                 &amp; f&apos;(x_0) =  \lim _{h \to  0}  \frac {f(x_0+h) - f(x_0)}{h}  \\                   \implies  &amp;  \lim _{h \to  0}  \frac {f(x_0+h) - f(x_0) -f&apos;(x_0)h }{h} = 0  \\                   \implies  &amp;  \lim _{x \to  x_0}  \frac {f(x) - f(x_0) - f&apos;(x_0)(x-x_0)}{x-x_0} = 0  \\                    \implies  &amp;  \lim _{x \to  x_0}  \frac {|f(x) - f(x_0) - f&apos;(x_0)(x-x_0)|}{|x-x_0|} = 0              \end {align*}         </fr:tex></fr:p><fr:p>
        Since <fr:tex>f&apos;(x_0)</fr:tex> represents the slope of the line tangent to the graph of <fr:tex>f</fr:tex> at <fr:tex>(x_0, f(x_0))</fr:tex>,
        differentiability of <fr:tex>f</fr:tex> at <fr:tex>x_0</fr:tex> means that there exists a number <fr:tex>m</fr:tex> st
        <fr:tex display="block">              \lim _{x \to  x_0}  \frac {|f(x) - f(x_0) - m(x-x_0)|}{|x-x_0|} = 0         </fr:tex>
        Now consider the function <fr:tex>T: \mathbb {R} \to \mathbb {R}</fr:tex> where <fr:tex>T(s) = ms</fr:tex>
        <fr:tex display="block">             T(s+t) = m(s+t) = ms + mt = T(s) + T(t)              \\               T(cs) = mcs = c(ms) = cT(s)         </fr:tex>
        then <fr:tex>T</fr:tex> is a linear transformation. In fact <fr:tex>T</fr:tex> is the linear function that most closely approximates the 
        function <fr:tex>f</fr:tex> at the point <fr:tex>(x_0, f(x_0))</fr:tex>. So for <fr:tex>x</fr:tex> values that are very close to <fr:tex>x_0</fr:tex> we have
        <fr:tex display="block">             f(x)  \approx  m(x-x_0) + f(x_0)         </fr:tex></fr:p><fr:p>
        Now let&apos;s generalize the concept of derivatives to functions of the form <fr:tex>f: \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex>.
        We assume the function <fr:tex>f</fr:tex> has the form
        <fr:tex display="block">              \begin {align*}                 &amp;f(x_1, x_2,  \cdots , x_n) =                   \\                   &amp;(f_1(x_1, x_2,  \cdots , x_n), f_2(x_1, x_2,  \cdots , x_n),  \cdots , f_m(x_1, x_2,  \cdots , x_n))              \end {align*}         </fr:tex>
        We want to search for this linear transformation which we will denoted by <fr:tex>Df</fr:tex>,
        that most closely approximates this function <fr:tex>f: \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex> at some specific point <fr:tex>x_0=(x_{1_0}, x_{2_0},  \cdots , x_{n_0})  \in   \mathbb {R} ^n</fr:tex>.
        If <fr:tex>f</fr:tex> is differentiable at <fr:tex>x_0</fr:tex> then there exists a linear transformation <fr:tex>Df(x_0): \mathbb {R} ^n \to \mathbb {R} ^m</fr:tex> such that
        <fr:tex display="block">              \lim _{x \to  x_0}  \frac {                  \lVert                      f(x) - f(x_0) - Df(x_0)(x-x_0)                  \rVert              }{ \lVert x-x_0 \rVert } = 0         </fr:tex>
        The <fr:tex>\lVert \cdot \rVert</fr:tex> represents the <fr:strong>Euclidean norm</fr:strong> of the vector (Multi-dimensional version of the absolute value)
        <fr:tex display="block">              \lVert \vec {x} \rVert  =  \sqrt {x_1^2 + x_2^2 +  \cdots  + x_n^2} =  \sqrt { \sum _{i=1}^n x_i^2}         </fr:tex>
        which is just the length of the vector. This allows us to perform dividing.
    </fr:p><fr:p>
        As before we have
        <fr:tex display="block">             f(x)  \approx  Df(x_0)(x-x_0) + f(x_0)         </fr:tex>
        Now we want to write <fr:tex>Df(x)</fr:tex> as a matrix. Denote the basis of <fr:tex>\mathbb {R} ^n</fr:tex> as <fr:tex>e_j</fr:tex> and the basis of <fr:tex>\mathbb {R} ^m</fr:tex> as <fr:tex>f_i</fr:tex>.
        Then we want to find <fr:tex>a_{ij}</fr:tex> st
        <fr:tex display="block">             Df(x)(e_j) =  \sum _{i=1}^{m} a_{ij} f_j =  \begin {bmatrix}                 a_{1j}  \\  a_{2j}  \\   \vdots   \\  a_{mj}              \end {bmatrix}         </fr:tex>
        In other words, the <fr:tex>i</fr:tex>-th component of the <fr:tex>j</fr:tex>-th column of <fr:tex>Df(x)</fr:tex> is just the <fr:tex>i</fr:tex>-th component of the <fr:tex>Df(x)(e_j)</fr:tex></fr:p><fr:p>
        Recall from vector calculus that given a function <fr:tex>f: \mathbb {R} ^n \to \mathbb {R}</fr:tex> we defined the <fr:strong>partial derivative</fr:strong> of <fr:tex>f</fr:tex> with respect to the <fr:tex>x_j</fr:tex> as 
        <fr:tex display="block">              \frac { \partial  f}{ \partial  x_j} =  \lim _{h \to0 }              \frac {f(x_1, \cdots ,x_j+h, \cdots ,x_n) - f(x_1, \cdots ,x_n)}{h}         </fr:tex>
        Hence we can define the partial derivatives for each <fr:tex>f_i (1 \leq  i \leq  m)</fr:tex> with respect to each <fr:tex>x_j (1 \leq  j \leq  n)</fr:tex>.
        <fr:tex display="block">              \frac { \partial  f_i}{ \partial  x_j} =  \lim _{h \to0 }              \frac {f_i(x_1, \cdots ,x_j+h, \cdots ,x_n) - f_i(x_1, \cdots ,x_n)}{h}         </fr:tex>
        Thus we have
        <fr:tex display="block">              \frac { \partial  f_i}{ \partial  x_j} = a_{ij}         </fr:tex>
        To find <fr:tex>a_{ij}</fr:tex> of <fr:tex>Df(x_0)</fr:tex> we need to find the <fr:tex>i</fr:tex>-th element of <fr:tex>Df(x_0)(e_j)</fr:tex>. Let
        <fr:tex display="block">             x =  \begin {bmatrix}                 x_{1_0}  \\  x_{2_0}  \\   \vdots   \\  x_{n_0}              \end {bmatrix} +  \begin {bmatrix}                 0  \\   \vdots   \\  1  \\   \vdots   \\  0              \end {bmatrix} = x_0 + he_j         </fr:tex>
        We have 
        <fr:tex display="block">              \lim _{x \to  x_0} \frac { \lVert f(x)-f(x_0)-Df(x_0)(he_j) \rVert }{ \lVert he_j \rVert }              \\   \implies                \lim _{h \to0 } \frac { \lVert                  f(x_0+he_j) - f(x_0) -hDf(x_0)(e_j)              \rVert }{ \lVert h \rVert } = 0         </fr:tex>
        The component is given by 
        <fr:tex display="block">              \lim _{h \to0 } \frac { \lVert f_i(x_0+he_j)-f_i(x_0)-ha_{ij} \rVert }{ \lVert h \rVert } = 0              \\   \implies               a_{ij} =  \lim _{h \to0 } \frac {f_i(x_0+he_j) - f_i(x_0)}{h}         </fr:tex>
        which is exactly <fr:tex>\frac { \partial  f_i}{ \partial  x_j}</fr:tex>. Thus the matrix representation of <fr:tex>Df(x)</fr:tex> is given by 
        a matrix called the <fr:strong>Jacobin matrix</fr:strong> of <fr:tex>f</fr:tex>.
        <fr:tex display="block">             Df(x) =  \begin {bmatrix}                  \frac { \partial  f_1}{ \partial  x_1} &amp;  \frac { \partial  f_1}{ \partial  x_2} &amp;  \cdots  &amp;  \frac { \partial  f_1}{ \partial  x_n}  \\                   \frac { \partial  f_2}{ \partial  x_1} &amp;  \frac { \partial  f_2}{ \partial  x_2} &amp;  \cdots  &amp;  \frac { \partial  f_2}{ \partial  x_n}  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                   \frac { \partial  f_m}{ \partial  x_1} &amp;  \frac { \partial  f_m}{ \partial  x_2} &amp;  \cdots  &amp;  \frac { \partial  f_m}{ \partial  x_n}              \end {bmatrix} =  \left [                  \frac { \partial  f_i}{ \partial  x_j}              \right ]         </fr:tex>
        where <fr:tex>i</fr:tex> ranges row and <fr:tex>j</fr:tex> ranges column.
    </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>486</fr:anchor><fr:taxon>Linear Algebra</fr:taxon><fr:addr>math-0008</fr:addr><fr:route>math-0008.xml</fr:route><fr:title>Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    This post shows operations and applications over matrix.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>470</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0043</fr:addr><fr:route>def-0043.xml</fr:route><fr:title>Transpose</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The <fr:strong>transpose</fr:strong> of a matrix <fr:tex>A</fr:tex>, denoted by <fr:tex>A^T</fr:tex> is
    the matrix obtained by swapping the rows and columns of <fr:tex>A</fr:tex>.
    It satisfies the following properties:
    <fr:ul><fr:li><fr:tex>(A^T)^T = A</fr:tex></fr:li>
        <fr:li><fr:tex>(A + B)^T = A^T + B^T</fr:tex></fr:li>
        <fr:li><fr:tex>(cA)^T = cA^T</fr:tex></fr:li>
        <fr:li><fr:tex>(AB)^T = B^TA^T</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    If the following condition satisfies:
    <fr:tex display="block">         a_{ij} = a_{ji}  \quad   \forall  i,j     </fr:tex>
    Then the matrix is called symmetric.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>471</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-001N</fr:addr><fr:route>def-001N.xml</fr:route><fr:title>Symmetric Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A square matrix <fr:tex>A</fr:tex> is symmetric if it is equal to its transpose:
    <fr:tex display="block">         A = A^T     </fr:tex>
    This also implies <fr:tex>A^{-1} A^T = I</fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>472</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0044</fr:addr><fr:route>def-0044.xml</fr:route><fr:title>Determinant</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The determinant of a <fr:tex>n \times  n</fr:tex> square matrix <fr:tex>A</fr:tex> is commonly denoted <fr:tex>\det  A</fr:tex> or <fr:tex>|A|</fr:tex>.
    It satisfies the following properties:
    <fr:ul><fr:li><fr:tex>\det  A^T =  \det  A</fr:tex></fr:li>
        <fr:li><fr:tex>\det  AB =  \det  A  \det  B</fr:tex></fr:li>
        <fr:li><fr:tex>\det   \lambda  A =  \lambda ^n  \det  A</fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:p>
    To compute the inverse of a matrix, we need <fr:strong>Adjugate matrix</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>473</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0045</fr:addr><fr:route>def-0045.xml</fr:route><fr:title>First Minor and Cofactor</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    If <fr:tex>A</fr:tex> is a square matrix, then the <fr:strong>minor</fr:strong> of the entry in the i-th row and j-th 
    column (also called the <fr:tex>(i, j)</fr:tex> minor, or a first minor) is the <fr:strong>determinant</fr:strong> of 
    the sub-matrix formed by deleting the i-th row and j-th column.
    The <fr:tex>(i, j)</fr:tex> minor is denoted as <fr:tex>M_{ij}</fr:tex>.
    The <fr:strong>Cofactor</fr:strong> is obtained by multiplying the minor by <fr:tex>(-1)^{i+j}</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>474</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0046</fr:addr><fr:route>def-0046.xml</fr:route><fr:title>Cofactor Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    The matrix formed by all of the <fr:link href="def-0045.xml" type="local" addr="def-0045">cofactors</fr:link> of a square matrix <fr:tex>A</fr:tex> is called the cofactor matrix,
    or <fr:strong>comatrix</fr:strong>:
    <fr:tex display="block">         C =  \left [               \begin {array}{cccc}                 C_{11} &amp; C_{12} &amp;  \cdots  &amp; C_{1n}  \\                  C_{21} &amp; C_{22} &amp;  \cdots  &amp; C_{2n}  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  C_{n1} &amp; C_{n2} &amp;  \cdots  &amp; C_{nn}              \end {array}          \right ]     </fr:tex>
    The <fr:strong>Adjugate matrix</fr:strong> of <fr:tex>A</fr:tex> is the transpose of the cofactor matrix.
</fr:p></fr:mainmatter></fr:tree><fr:p>
    Then the inverse of <fr:tex>A</fr:tex> is the transpose of the cofactor matrix times the reciprocal of the determinant of <fr:tex>A</fr:tex>:
    <fr:tex display="block">         A^{-1} =  \frac {1}{ \det  A}  \cdot   \text {adj} A =  \frac {1}{ \det  A}  \cdot  C^T     </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>475</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0047</fr:addr><fr:route>def-0047.xml</fr:route><fr:title>Singular Matrix</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A square matrix that is not <fr:strong>invertible</fr:strong> is called <fr:strong>singular</fr:strong> or degenerate
</fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>477</fr:anchor><fr:title>An important property of the inverse of a matrix</fr:title><fr:parent>math-0008</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:tex display="block">             A  \cdot   \text {adj} A =  \text {adj} A  \cdot  A =  \det  A  \cdot  I         </fr:tex></fr:p>
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>476</fr:anchor><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
        Let <fr:tex>A  \cdot   \text {adj} A = (b_{ij})</fr:tex> and we have
        <fr:tex display="block">             b_{ij} = a_{i1}A_{j1} + a_{i2}A_{j2} +  \cdots  + a_{in}A_{jn} =  \delta _{ij}  \cdot   \det  A         </fr:tex>
        Hence we have <fr:tex>A  \cdot   \text {adj} A =  \det  A  \cdot  I</fr:tex> 
    </fr:mainmatter></fr:tree>
 
</fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>479</fr:anchor><fr:title>Matrix Polynomial and Computation</fr:title><fr:parent>math-0008</fr:parent></fr:frontmatter><fr:mainmatter><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>478</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0048</fr:addr><fr:route>def-0048.xml</fr:route><fr:title>Matrix Polynomial</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    A <fr:strong>matrix polynomial</fr:strong> is a polynomial with square matrices as variables.
    The general form of a matrix polynomial is:
    <fr:tex display="block">         P(A) =  \sum _{i=0}^{n} a_i A^i     </fr:tex>
    where <fr:tex>A^0 = I</fr:tex> is the identity matrix.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        If <fr:tex>A</fr:tex> is a diagonal matrix, then the polynomial of <fr:tex>A</fr:tex> is the diagonal matrix of the polynomial of the diagonal elements of <fr:tex>A</fr:tex>.
        <fr:tex display="block">             p(A) =  \begin {bmatrix}                 p(a_{11}) &amp; 0 &amp;  \cdots  &amp; 0  \\                  0 &amp; p(a_{22}) &amp;  \cdots  &amp; 0  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  0 &amp; 0 &amp;  \cdots  &amp; p(a_{nn})              \end {bmatrix}         </fr:tex></fr:p><fr:p>
        If <fr:tex>A = P \Lambda  P^{-1}</fr:tex>, then <fr:tex>A^k = P  \Lambda  ^k P^{-1}</fr:tex> and hence
        <fr:tex display="block">             p(A) = a_0 I + a_1 A + a_2 A^2 +  \cdots  + a_n A^n = P  \Lambda  P^{-1}         </fr:tex></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>482</fr:anchor><fr:title>Solving a Linear System</fr:title><fr:parent>math-0008</fr:parent></fr:frontmatter><fr:mainmatter><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>480</fr:anchor><fr:taxon>Theorem</fr:taxon><fr:addr>thm-0011</fr:addr><fr:route>thm-0011.xml</fr:route><fr:title>Cramer&apos;s rule</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Consider a system of <fr:tex>n</fr:tex> linear equations for <fr:tex>n</fr:tex> unknowns, represented in matrix multiplication form as follows:
    <fr:tex display="block">         A  \cdot  X = B     </fr:tex>
    where <fr:tex>A</fr:tex> is a square matrix of order <fr:tex>n</fr:tex>, <fr:tex>X</fr:tex> is a column matrix of order <fr:tex>n</fr:tex> and <fr:tex>B</fr:tex> is a column matrix of order <fr:tex>n</fr:tex>.
    <fr:tex display="block">         X =  \begin {bmatrix} x_1  \\  x_2  \\   \vdots   \\  x_n  \end {bmatrix}     </fr:tex>
    The Cramer&apos;s rule states that the solution to the system of equations is given by:
    <fr:tex display="block">         x_i =  \frac { \text {det}(A_i)}{ \text {det}(A)}     </fr:tex>
    where <fr:tex>A_i</fr:tex> is the matrix obtained by replacing the <fr:tex>i</fr:tex>th column of <fr:tex>A</fr:tex> by <fr:tex>B</fr:tex>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        Matrix partitioning is the process of dividing a matrix into smaller submatrices. 
        This is often done to simplify the computation of matrix operations, such as matrix multiplication.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>481</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-0049</fr:addr><fr:route>def-0049.xml</fr:route><fr:title>Matrix Partitioning</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Let <fr:tex>A  \in   \mathbb {C} ^{m \times  n} </fr:tex>. A <fr:strong>partitioning</fr:strong> of <fr:tex>A</fr:tex> is a representation of <fr:tex>A</fr:tex> in the form
    <fr:tex display="block">         A =  \begin {bmatrix}             A_{11} &amp; A_{12} &amp;  \cdots  &amp; A_{1q}  \\              A_{21} &amp; A_{22} &amp;  \cdots  &amp; A_{2q}  \\               \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\              A_{p1} &amp; A_{p2} &amp;  \cdots  &amp; A_{pq}          \end {bmatrix}     </fr:tex>
    where <fr:tex>A_{ij}  \in   \mathbb {C} ^{m_i  \times  n_j} </fr:tex> for <fr:tex>1  \leq  i  \leq  p</fr:tex> and <fr:tex>1  \leq  j  \leq  q</fr:tex> such that
    <fr:tex display="block">          \sum _{i=1}^p m_i = m  \quad   \text {and}  \quad   \sum _{j=1}^q n_j = n.     </fr:tex>
    The partitioned matrix operations are similar to the operations on the normal matrix. 
</fr:p></fr:mainmatter></fr:tree><fr:p>
        If the partitioned matrix is formed as diagonal blocks, then we can compute the determinant of the matrix by the following formula:
        <fr:tex display="block">              \det  A =  \det  A_1  \cdot   \det  A_2  \cdots   \det  A_n         </fr:tex>
        And the inverse of the matrix is
        <fr:tex display="block">             A^{-1} =  \begin {bmatrix}                 A_1^{-1} &amp; O &amp;  \cdots  &amp; O  \\                  O &amp; A_2^{-1} &amp;  \cdots  &amp; O  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  O &amp; O &amp;  \cdots  &amp; A_n^{-1}              \end {bmatrix}         </fr:tex></fr:p><fr:p>
        The column partitioning of matrix is useful. 
        If we have <fr:tex>m \times  s</fr:tex> matrix <fr:tex>A = (a_{ij})</fr:tex> and <fr:tex>s \times  n</fr:tex> matrix <fr:tex>B=(b_{ij})</fr:tex>,
        their product can be written:
        <fr:tex display="block">             AB =  \begin {bmatrix} A_1  \\  A_2  \\   \vdots  A_m  \end {bmatrix}              \begin {bmatrix}                 B_1 &amp; B_2 &amp;  \cdots  &amp; B_n              \end {bmatrix} =               \begin {bmatrix}                 A_1B_1 &amp; A_1B_2 &amp;  \cdots  &amp; A_1B_n  \\                  A_2B_1 &amp; A_2B_2 &amp;  \cdots  &amp; A_2B_n  \\                   \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\                  A_mB_1 &amp; A_mB_2 &amp;  \cdots  &amp; A_mB_n              \end {bmatrix}         </fr:tex>
        We can show that <fr:tex>A=O \iff  A^TA=O</fr:tex>.
    </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>485</fr:anchor><fr:title>Matrix Transformation</fr:title><fr:parent>math-0008</fr:parent></fr:frontmatter><fr:mainmatter><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>483</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-004A</fr:addr><fr:route>def-004A.xml</fr:route><fr:title>Elementary Operations</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    There are three types of elementary matrices, which correspond to three types of row operations
    (respectively, column operations, row operations are equivalent to multiplying on the left by the
    corresponding elementary matrix, and column operations are equivalent to multiplying on the right
    by the corresponding elementary matrix):
    <fr:ul><fr:li><fr:strong>Row switching</fr:strong>: A row within the matrix can be switched with another row.
            <fr:tex display="block">                 P_{i,j} =  \begin {bmatrix}                     1  \\                      &amp;  \ddots   \\                      &amp; &amp; 0 &amp; &amp;  1  \\                       &amp; &amp; &amp;  \ddots   \\                       &amp; &amp; 1 &amp; &amp; 0  \\                       &amp; &amp; &amp; &amp; &amp;  \ddots   \\                      &amp; &amp; &amp; &amp; &amp; &amp; 1                  \end {bmatrix}             </fr:tex></fr:li>
        <fr:li><fr:strong>Row multiplication</fr:strong>: Each element in a row can be multiplied by a non-zero constant.
            <fr:tex display="block">                 D_i(k) =  \text {diag} (1,  \cdots , k,  \cdots , 1)             </fr:tex></fr:li>
        <fr:li><fr:strong>Row additio</fr:strong>: A row can be replaced by the sum of that row and a multiple of another row.
            <fr:tex display="block">                 T_{i,j} =  \begin {bmatrix}                     1  \\                      &amp;  \ddots   \\                      &amp; &amp; 1 &amp; &amp; k  \\                       &amp; &amp; &amp;  \ddots   \\                       &amp; &amp; &amp; &amp; 1  \\                       &amp; &amp; &amp; &amp; &amp;  \ddots   \\                      &amp; &amp; &amp; &amp; &amp; &amp; 1                  \end {bmatrix}             </fr:tex></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>484</fr:anchor><fr:taxon>Definition</fr:taxon><fr:addr>def-004B</fr:addr><fr:route>def-004B.xml</fr:route><fr:title>Column / Row Equivalence</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Two matrices <fr:tex>A,B</fr:tex> are column / row equivalent if one can 
    be obtained from the other by a finite sequence of <fr:link href="def-004A.xml" type="local" addr="def-004A">elementary operations</fr:link>,
    denoted <fr:tex>A  \sim  B</fr:tex>.
    The column / row equivalence is an <fr:link href="def-000X.xml" type="local" addr="def-000X">equivalence relation</fr:link>.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        We can show that a matrix <fr:tex>A</fr:tex> is invertible iff there are finite elementary matrices
        <fr:tex>E_1, E_2,  \cdots , E_n</fr:tex> such that
        <fr:tex display="block">             A = E_1E_2 \cdots  E_n         </fr:tex></fr:p><fr:p>
        From above we can deduce that a square matrix <fr:tex>A</fr:tex> is invertible iff <fr:tex>A \sim  E</fr:tex>.
        This trick can be used for solving a linear system and computing the inverse of a matrix.
    </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="false" root="false"><fr:frontmatter><fr:anchor>500</fr:anchor><fr:taxon>Mechanics</fr:taxon><fr:addr>phy-0004</fr:addr><fr:route>phy-0004.xml</fr:route><fr:title>Classical Mechanics</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    Notes about the classic mechanics. 
    Most of the content is based on the Wikipedia page about the subject.
</fr:p><fr:p>
    The motion of a body can only be described relative to something else—other bodies, 
    observers, or a set of spacetime coordinates. These are called <fr:strong>frames of reference</fr:strong>. 
    All physical laws take their simplest form in an <fr:strong>inertial</fr:strong> frame.
    <fr:strong>Galilean invariance</fr:strong> or <fr:strong>Galilean relativity</fr:strong> states that the 
    laws of motion are the same in all <fr:strong>inertial frames of reference</fr:strong>.
</fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>487</fr:anchor><fr:title>Center of mass</fr:title><fr:parent>phy-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p>
        The center of mass of a distribution of mass in space is the unique point 
        at any given time where the weighted relative position of the distributed mass sums to zero.
        <fr:ul><fr:li><fr:strong>System of particles</fr:strong>
                <fr:tex display="block">                      \vec {R} =  \frac { \sum  m_i  \vec {r}_i}{ \sum  m_i}                 </fr:tex></fr:li>
            <fr:li><fr:strong>Continuous volume</fr:strong>
                <fr:p>
                    If the mass is distributed continuously, the center of mass is given by the
                    following formula:
                    <fr:tex display="block">                          \vec {R} =  \frac { \int   \vec {r} dm}{ \int  dm}                     </fr:tex></fr:p></fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>491</fr:anchor><fr:title>Work and Energy</fr:title><fr:parent>phy-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:strong>Work</fr:strong> is the energy transferred to or from an object via the application of force along a displacement.
        <fr:ul><fr:li>Positive Work: The force has a component in the direction of the displacement.</fr:li>
            <fr:li>Negative Work: The force has a component opposite to the direction of the displacement.</fr:li></fr:ul>
        Both force and displacement are vectors. The work done is given by the dot product of the two vectors,
        where the result is a scalar. The work can be given by line integrals:
        <fr:tex display="block">             W =  \int _C  \vec {F}  \cdot  d \vec {r}         </fr:tex>
        where <fr:tex>d \vec {r}</fr:tex> is the tiny displacement vector along the path <fr:tex>C</fr:tex>.
        For motion along a straight line, we have a degenerated case of the line integral:
        <fr:tex display="block">             W =  \vec {F}  \cdot   \vec {r}         </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>488</fr:anchor><fr:taxon>Principle</fr:taxon><fr:addr>thm-0012</fr:addr><fr:route>thm-0012.xml</fr:route><fr:title>Work-Energy Principle</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
    An increase in the kinetic energy of a <fr:strong>rigid body</fr:strong> is caused by an equal amount 
    of positive work done on the body by the resultant force acting on that body. 
    Conversely, a decrease in kinetic energy is caused by an equal amount of negative work done by the resultant force.
</fr:p></fr:mainmatter></fr:tree><fr:p>
        Work on a free (no fields), rigid (no internal degrees of freedom) body, is equal to the change
        in kinetic energy <fr:tex>E_k</fr:tex> corresponding to the linear velocity and angular velocity of that body.
        <fr:tex display="block">             W =  \Delta  E_k         </fr:tex></fr:p><fr:p>
        The work of forces generated by a potential function is known as potential energy 
        and the forces are said to be <fr:strong>conservative</fr:strong>. 
        Work on an object that is merely displaced in a conservative force field, without 
        change in velocity or rotation, is equal to minus the change of potential energy <fr:tex>E_p</fr:tex> of the object
        <fr:tex display="block">             W = - \Delta  E_p         </fr:tex></fr:p><fr:p>
        The time derivative of the work is called <fr:strong>power</fr:strong>:
        <fr:tex display="block">             P =  \frac {dW}{dt}         </fr:tex>
        <fr:tex>dW</fr:tex> can be written as the dot product of the force and the velocity of the object <fr:tex>dW =  \vec {F}  \cdot  d \vec {r}</fr:tex>,
        hence the power can be written as:
        <fr:tex display="block">             P =  \vec {F}  \cdot   \frac {d \vec {r}}{dt} =  \vec {F}  \cdot   \vec {v}         </fr:tex>
        The work then can be expressed as the integral of the power over time:
        <fr:tex display="block">             W =  \int _{ \Delta  t} P dt =  \int _{ \Delta  t}  \vec {F}  \cdot   \vec {v} dt          </fr:tex></fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>490</fr:anchor><fr:title>Kinetic Energy</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            The kinetic energy of a point object, or a non-rotating rigid body depends on the 
            mass of the body as well as its speed.
            <fr:tex display="block">                 E_k =  \frac {1}{2} m v^2 =  \frac {p^2}{2m}             </fr:tex></fr:p>
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>489</fr:anchor><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
            The work done in accelerating a particle with mass m during the infinitesimal time 
            interval <fr:tex>dt</fr:tex> is given by the dot product of force <fr:tex>\vec {F}</fr:tex> and the infinitesimal displacement <fr:tex>d \vec {x}</fr:tex>
            <fr:tex display="block">                 dW =  \vec {F}  \cdot  d \vec {x}                  =  \frac {d \vec {p}}{dt}  \cdot   \vec {v}dt                 =  \vec {v} \cdot  d \vec {p} =  \vec {v}  \cdot  d(m \vec {v})             </fr:tex>
            Applying the product rule of differentiation, we get:
            <fr:tex display="block">                 d( \vec {v} \cdot \vec {v}) = 2 \vec {v}  \cdot  d \vec {v}             </fr:tex>
            Therefore we have:
            <fr:tex display="block">                  \vec {v}  \cdot  d(m \vec {v}) =  \frac {m}{2} d( \vec {v}  \cdot   \vec {v})              </fr:tex>
            Since this is a total differential (that is, it only depends on the final state, 
            not how the particle got there), we can integrate it and call the result kinetic energy:
            <fr:tex display="block">                 E_k =  \int _{v_1}^{v_2}  \vec {p}  \cdot  d \vec {v} =  \frac {1}{2} m (v_2^2-v_1^2)             </fr:tex>
        </fr:mainmatter></fr:tree>
 
<fr:p>
            If a rigid body <fr:tex>Q</fr:tex> is rotating about any line through the center of mass then it has <fr:strong>rotational kinetic energy</fr:strong>
            (<fr:tex>E_r</fr:tex>) which is simply the sum of the kinetic energies of its moving parts, and is thus given by:
            <fr:tex display="block">                 E_r =  \int _Q  \frac {v^2dm}{2} =  \int _Q  \frac {(r \omega )^2dm}{2} =  \frac { \omega ^2}{2} \int _Qr^2dm =  \frac {1}{2}I \omega ^2             </fr:tex>
            <fr:ul><fr:li><fr:tex>I =  \int _Qr^2dm</fr:tex> is the moment of inertia of the body.
                </fr:li>
                <fr:li><fr:tex>\omega</fr:tex> is the angular velocity of the body.
                </fr:li>
                <fr:li><fr:tex>r</fr:tex> is the distance from the axis of rotation.
                </fr:li></fr:ul></fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>497</fr:anchor><fr:title>Momentum</fr:title><fr:parent>phy-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:p><fr:strong>Momentum</fr:strong> depends on the frame of reference, but in any inertial frame it is a conserved quantity,
        meaning that if a closed system is not affected by external forces, its total linear momentum does not change.
    </fr:p><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>492</fr:anchor><fr:title>Definition in Classic Mechanics</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            For a system with one or more particles, the total momentum is the sum of the momenta of the individual particles.
            <fr:tex display="block">                  \vec {p} =  \sum  m_i  \vec {v}_i             </fr:tex>
            Or use the center of mass:
            <fr:tex display="block">                  \vec {p} = M  \vec {V}             </fr:tex>
            where <fr:tex>M</fr:tex> is the total mass of the system and <fr:tex>\vec {V}</fr:tex> is the velocity of the center of mass.
            This formula is known as the <fr:strong>Euler&apos;s first law of motion</fr:strong>.
        </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>493</fr:anchor><fr:title>Relation to force</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            From Newton&apos;s second law, the rate of change of the momentum of a particle is equal to the 
            instantaneous force <fr:tex>F</fr:tex> acting on it
            <fr:tex display="block">                  \vec {F} =  \frac {d \vec {p}}{dt}             </fr:tex>
            Hence the change in momentum in time interval <fr:tex>(t_1, t_2)</fr:tex> can be written as:
            <fr:tex display="block">                 I =  \Delta \vec {p} =  \int _{t_1}^{t_2}  \vec {F} dt =  \int _{ \vec {p_1}}^{ \vec {p_2}} d \vec {p}             </fr:tex>
            We read this as the <fr:strong>impulse</fr:strong> <fr:tex>I</fr:tex> is equal to the change in momentum.
        </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>494</fr:anchor><fr:title>Law of Conservation of Momentum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            In a closed system the total momentum remains constant.
            A closed system means that the system is not affected by external forces.
            Or approximately the external forces are extremely small.
        </fr:p></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>496</fr:anchor><fr:title>Angular Momentum</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            A force applied perpendicularly to a lever multiplied by its distance from the 
            lever&apos;s fulcrum (the length of the lever arm) is its <fr:strong>torque</fr:strong>.
            <fr:tex display="block">                  \vec { \tau } =  \vec {r}  \times   \vec {F}             </fr:tex>
            The magnitude of torque is <fr:tex>\tau  = rF \sin \theta  </fr:tex> (<fr:tex>r</fr:tex> is the magnitude of the
            <fr:strong>position vector</fr:strong> <fr:tex>\vec {r}</fr:tex> and <fr:tex>\theta</fr:tex> is the angle between the force
            vector and the lever arm vector).
        </fr:p><fr:p>
            In three-dimensional Euclidean Space, the torque can be written as the components:
            <fr:tex display="block">                  \vec { \tau } =  \begin {pmatrix}                      \tau _x  \\                       \tau _y  \\                       \tau _z                  \end {pmatrix} =  \begin {pmatrix}                     yF_z - zF_y  \\                      zF_x - xF_z  \\                      xF_y - yF_x                  \end {pmatrix}             </fr:tex>
            The component of torque in the direction of an axis is called the torque to that axis.
        </fr:p><fr:p>
            The net torque determines the rate of change of the body&apos;s angular momentum.
            <fr:tex display="block">                  \vec { \tau } =  \frac {d \vec {L}}{dt}             </fr:tex>
            The angular momentum of a particle is defined as:
            <fr:tex display="block">                  \vec {L} =  \vec {r}  \times   \vec {p}             </fr:tex></fr:p>
 
   
   <fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="false" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>495</fr:anchor><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
            Now we prove the equivalence of definitions.
            <fr:tex display="block">                  \frac {d \vec {L}}{dt} =  \vec {r} \times \frac {d \vec {p}}{dt} +  \frac {d \vec {r}}{dt} \times \vec {p}             </fr:tex>
            The rate of change of linear momentum is the force and the rate of change of position is velocity.
            <fr:tex display="block">                  \frac {d \vec {L}}{dt} =  \vec {r} \times \vec {F} +  \vec {v} \times \vec {p}             </fr:tex>
            The cross product of <fr:tex>\vec {p}</fr:tex> with <fr:tex>\vec {v}</fr:tex> is <fr:tex>0</fr:tex> because velocity and momentum are parallel.
            Hence we have:
            <fr:tex display="block">                  \frac {d \vec {L}}{dt} =  \vec {r} \times \vec {F} =  \tau              </fr:tex>
        </fr:mainmatter></fr:tree>
 
<fr:p>
            The above statement leads to the Conservation of Angular Momentum.
        </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>499</fr:anchor><fr:title>Rigid Body Dynamics</fr:title><fr:parent>phy-0004</fr:parent></fr:frontmatter><fr:mainmatter><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false"><fr:frontmatter><fr:anchor>498</fr:anchor><fr:title>Moment of Inertia</fr:title></fr:frontmatter><fr:mainmatter><fr:p>
            When a body is free to rotate around an axis, torque must be applied to change its angular momentum.
            The amount of torque needed to cause any given angular acceleration
            is proportional to the moment of inertia of the body.
            The moment of inertia plays the role in rotational kinetics that mass (inertia) plays in linear kinetics,
            both characterize the resistance of a body to changes in its motion.
        </fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:context><fr:related></fr:related><fr:backlinks></fr:backlinks><fr:references><fr:tree xmlns:fr="http://www.jonmsterling.com/jms-005P.xml" toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="true" root="false"><fr:frontmatter><fr:anchor>659</fr:anchor><fr:taxon>Reference</fr:taxon><fr:addr>cat-sci-2013</fr:addr><fr:route>cat-sci-2013.xml</fr:route><fr:title>Category theory for scientists</fr:title><fr:authors><fr:author>David I. Spivak</fr:author></fr:authors><fr:meta name="doi">/10.48550/arXiv.1302.6946</fr:meta><fr:meta name="venue">Category Theory</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>
    Show that category theory can be applied throughout the sciences as a framework for modeling phenomena and communicating results.
</fr:p></fr:mainmatter></fr:tree></fr:references></fr:backmatter></fr:tree>