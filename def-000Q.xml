<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?><fr:tree toc="true" numbered="true" show-heading="true" show-metadata="true" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
  <fr:frontmatter>
    <fr:anchor>1552</fr:anchor>
    <fr:addr type="user">def-000Q</fr:addr>
    <fr:route>def-000Q.xml</fr:route>
    <fr:title text="Linearly dependent">Linearly dependent</fr:title>
    <fr:taxon>Definition</fr:taxon>
    <fr:authors></fr:authors>
  </fr:frontmatter>
  <fr:mainmatter>
    <fr:p>A set of vectors <fr:tex display="inline">\{v_1, \dots , v_n\}</fr:tex> is called <fr:strong>linearly dependent</fr:strong> if
    <fr:tex display="block">a_1 v_1 + \dots  + a_n v_n = 0</fr:tex>
    for some <fr:tex display="inline">a_1, \dots , a_n \in  \mathbb {F}</fr:tex> with at least one <fr:tex display="inline">a_i \neq  0</fr:tex> (not all <fr:tex display="inline">0</fr:tex>).</fr:p>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree toc="false" numbered="false" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
      <fr:frontmatter>
        <fr:title text="Context">Context</fr:title>
        <fr:authors></fr:authors>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="false" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
          <fr:frontmatter>
            <fr:anchor>1553</fr:anchor>
            <fr:addr type="user">math-0002</fr:addr>
            <fr:route>math-0002.xml</fr:route>
            <fr:title text="Finite Dimensional Vector Space">Finite Dimensional Vector Space</fr:title>
            <fr:taxon>Linear Algebra</fr:taxon>
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>1</fr:month>
              <fr:day>26</fr:day>
            </fr:date>
            <fr:authors></fr:authors>
          </fr:frontmatter>
          <fr:mainmatter>
            <fr:p>This note introduces the concept of finite-dimensional vector space.
    Refer to <fr:link type="local" href="linear-algebra-2015.xml" addr="linear-algebra-2015" title="Linear Algebra Done Right">Linear Algebra Done Right</fr:link>.</fr:p>
            <fr:p>Adding up scalar mulitples of vectors in a list gives a linear combination.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>506</fr:anchor>
                <fr:addr type="user">def-000L</fr:addr>
                <fr:route>def-000L.xml</fr:route>
                <fr:title text="Linear Combination">Linear Combination</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a <fr:link type="local" href="def-000H.xml" addr="def-000H" title="Vector Space">vector space</fr:link> over a field <fr:tex display="inline">F</fr:tex>.
    Let <fr:tex display="inline">v_1, \dots , v_n</fr:tex> be vectors in <fr:tex display="inline">V</fr:tex>.
    A <fr:strong>linear combination</fr:strong> of <fr:tex display="inline">v_1, \dots , v_n</fr:tex> is an expression of the form
    <fr:tex display="block">         a_1 v_1 + \dots  + a_n v_n     </fr:tex>
    where <fr:tex display="inline">a_1, \dots , a_n \in  F</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>To talk about a structure, we usually define a collection of this structure.
    Hence we have span for linear combinations.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>507</fr:anchor>
                <fr:addr type="user">def-000M</fr:addr>
                <fr:route>def-000M.xml</fr:route>
                <fr:title text="Linear Span">Linear Span</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a vector space over a field <fr:tex display="inline">F</fr:tex>.
    Let <fr:tex display="inline">v_1, \dots , v_n</fr:tex> be vectors in <fr:tex display="inline">V</fr:tex>.
    The <fr:strong>span</fr:strong> of <fr:tex display="inline">v_1, \dots , v_n</fr:tex> is defined as
    <fr:tex display="block">         \text {span}(v_1, \dots , v_n) = \{a_1 v_1 + \dots  + a_n v_n \mid  a_i \in  F\}     </fr:tex>
    The span of empty set is defined to be <fr:tex display="inline">\{0\}</fr:tex>.</fr:p>
                <fr:p>If <fr:tex display="inline">\text {span}(v_1, \dots , v_n) = V</fr:tex>, we say that <fr:tex display="inline">v_1, \dots , v_n</fr:tex> <fr:strong>spans</fr:strong> <fr:tex display="inline">V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>Suppose we have span <fr:tex display="inline">S=\text {span}(v_1, \dots , v_n)</fr:tex>. (Span is trivially a subspace.)
    Obviously for all <fr:tex display="inline">v_j (1 \leq  j \leq  n)</fr:tex>, <fr:tex display="inline">v_j \in  S</fr:tex>.
    Because subspaces are closed under scalar multiplication and addition, every
    subspace of <fr:tex display="inline">V</fr:tex> containing <fr:tex display="inline">v_1, \dots , v_n</fr:tex> must contain <fr:tex display="inline">S</fr:tex>.
    Thus we conclude that <fr:tex display="inline">S</fr:tex> is the smallest subspace containing <fr:tex display="inline">v_1, \dots , v_n</fr:tex>.</fr:p>
            <fr:p>The discussion about <fr:strong>spans</fr:strong> leads to a key definition in linear algebra.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>508</fr:anchor>
                <fr:addr type="user">def-000N</fr:addr>
                <fr:route>def-000N.xml</fr:route>
                <fr:title text="Finite-Dimensional Vector Space">Finite-Dimensional Vector Space</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>A <fr:link type="local" href="def-000H.xml" addr="def-000H" title="Vector Space">vector space</fr:link> <fr:tex display="inline">V</fr:tex> is called <fr:strong>finite-dimensional</fr:strong> if some <fr:link type="local" href="def-000G.xml" addr="def-000G" title="List">list</fr:link> of vectors <fr:tex display="inline">v_1, \dots , v_n</fr:tex> <fr:link type="local" href="def-000M.xml" addr="def-000M" title="Linear Span">spans</fr:link> <fr:tex display="inline">V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>The opposite of finite-dimensional is infinite-dimensional.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>509</fr:anchor>
                <fr:addr type="user">def-000O</fr:addr>
                <fr:route>def-000O.xml</fr:route>
                <fr:title text="Infinite-dimensional vector space">Infinite-dimensional vector space</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>A vector space <fr:tex display="inline">V</fr:tex> is called <fr:strong>infinite-dimensional</fr:strong> if it is not <fr:link type="local" href="def-000N.xml" addr="def-000N" title="Finite-Dimensional Vector Space">finite-dimensional</fr:link>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>Consider the situation that there is only one way to
    express a vector <fr:tex display="inline">v</fr:tex> as a linear combination of vectors in a list <fr:tex display="inline">v_1, \dots , v_n</fr:tex>.
    What property of the list <fr:tex display="inline">v_1, \dots , v_n</fr:tex> does this situation imply? The answer is
    linear independence.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>510</fr:anchor>
                <fr:addr type="user">def-000P</fr:addr>
                <fr:route>def-000P.xml</fr:route>
                <fr:title text="Linearly independent">Linearly independent</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>A set of vectors <fr:tex display="inline">\{v_1, \dots , v_n\}</fr:tex> is called <fr:strong>linearly independent</fr:strong> if
    <fr:tex display="block">a_1 v_1 + \dots  + a_n v_n = 0</fr:tex>
    implies that <fr:tex display="inline">a_1 = \dots  = a_n = 0</fr:tex>.
    The trivial case of <fr:tex display="inline">\{0\}</fr:tex> is also considered linearly independent.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>If some vectors are not linearly independent, then there are more than one way to
    express a vector as a linear combination of vectors in the list. This leads to 
    the following definition.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>511</fr:anchor>
                <fr:addr type="user">def-000Q</fr:addr>
                <fr:route>def-000Q.xml</fr:route>
                <fr:title text="Linearly dependent">Linearly dependent</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>A set of vectors <fr:tex display="inline">\{v_1, \dots , v_n\}</fr:tex> is called <fr:strong>linearly dependent</fr:strong> if
    <fr:tex display="block">a_1 v_1 + \dots  + a_n v_n = 0</fr:tex>
    for some <fr:tex display="inline">a_1, \dots , a_n \in  \mathbb {F}</fr:tex> with at least one <fr:tex display="inline">a_i \neq  0</fr:tex> (not all <fr:tex display="inline">0</fr:tex>).</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>The following lemma is a direct consequence of the definition of linear independence.
    It states that for a given linearly dependent list, we can always remove a vector
    without changing the span.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>512</fr:anchor>
                <fr:addr type="user">thm-0001</fr:addr>
                <fr:route>thm-0001.xml</fr:route>
                <fr:title text="Linear Dependence Lemma">Linear Dependence Lemma</fr:title>
                <fr:taxon>Lemma</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">v_1, \dots , v_n</fr:tex> be vectors in a vector space <fr:tex display="inline">V</fr:tex> over a field <fr:tex display="inline">\mathbb {F}</fr:tex>.
    If <fr:tex display="inline">v_1, \dots , v_n</fr:tex> are linearly dependent, then there exists <fr:tex display="inline">1 \leq  i \leq  n</fr:tex> such that
    <fr:ul><fr:li><fr:tex display="inline">v_i \in  \text {span}(v_1, \dots , v_{i-1})</fr:tex></fr:li>
        <fr:li>Remove <fr:tex display="inline">v_i</fr:tex> from the list <fr:tex display="inline">v_1, \dots , v_n</fr:tex> and the span does not change</fr:li></fr:ul></fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>513</fr:anchor>
                <fr:addr type="user">thm-0002</fr:addr>
                <fr:route>thm-0002.xml</fr:route>
                <fr:title text="Length of linearly independent list  length of spanning list">Length of linearly independent list <fr:tex display="inline">\leq </fr:tex> length of spanning list</fr:title>
                <fr:taxon>Lemma</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>In a finite dimensional vector space, the length of a linearly independent list is less than or equal to the length of a spanning list.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>We have discussed linear independent lists and spanning lists.
    Now we are ready to define a basis.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>514</fr:anchor>
                <fr:addr type="user">def-000R</fr:addr>
                <fr:route>def-000R.xml</fr:route>
                <fr:title text="Basis">Basis</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>A basis of <fr:tex display="inline">V</fr:tex> is a list of vectors in <fr:tex display="inline">V</fr:tex>
    that is linearly independent and spans <fr:tex display="inline">V</fr:tex>.</fr:p>
                <fr:p><fr:strong>Criterion for basis</fr:strong>
    A list of vectors <fr:tex display="inline">\{v_1, \dots , v_n\}</fr:tex> is a basis of <fr:tex display="inline">V</fr:tex> if and only if
    every <fr:tex display="inline">v \in  V</fr:tex> can be written <fr:strong>uniquely</fr:strong> as a linear combination of <fr:tex display="inline">v_1, \dots , v_n</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>For instance, we have standard basis <fr:tex display="inline">\{e_1, \dots , e_n\}</fr:tex> for <fr:tex display="inline">\mathbb {F}^n</fr:tex>,
    where <fr:tex display="inline">e_i</fr:tex> is the vector with <fr:tex display="inline">1</fr:tex> at <fr:tex display="inline">i</fr:tex>-th position and <fr:tex display="inline">0</fr:tex> elsewhere.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>515</fr:anchor>
                <fr:addr type="user">thm-0005</fr:addr>
                <fr:route>thm-0005.xml</fr:route>
                <fr:title text="Spanning List contains a basis">Spanning List contains a basis</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Every spanning list in a vector space can be reduced to a basis.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>From the <fr:link type="local" href="thm-0005.xml" addr="thm-0005" title="Spanning List contains a basis">theorem</fr:link> we can infer a corollary.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>516</fr:anchor>
                <fr:addr type="user">thm-0006</fr:addr>
                <fr:route>thm-0006.xml</fr:route>
                <fr:title text="Basis of finite-dimensional vector space">Basis of finite-dimensional vector space</fr:title>
                <fr:taxon>Corollary</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Every finite-dimensional vector space has a basis.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>The next result states for a spanning list can be reduced to a basis.
    We can adjoin one or more vectors to a linearly independent list to form a basis.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>517</fr:anchor>
                <fr:addr type="user">thm-0007</fr:addr>
                <fr:route>thm-0007.xml</fr:route>
                <fr:title text="Linearly dependent list extends to a basis">Linearly dependent list extends to a basis</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Every linearly independent list of vectors in  a finite-dimensional vector space can be extended to a basis.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>Remind the definition of <fr:link type="external" href="der-000K">direct sum</fr:link>, we can now show that
    every subspace of a finite-dimensional vecrtor space can be paired
    with another subspace to form a direct sum of the whole space.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>518</fr:anchor>
                <fr:addr type="user">thm-0008</fr:addr>
                <fr:route>thm-0008.xml</fr:route>
                <fr:title text="Direct Sum of Subspaces of V">Direct Sum of Subspaces of <fr:tex display="inline">V</fr:tex></fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Suppose <fr:tex display="inline">V</fr:tex> is a finite dimensional vector space,
    and <fr:tex display="inline">U</fr:tex> is a subspace of <fr:tex display="inline">V</fr:tex>.
    Then there exists a subspace <fr:tex display="inline">W</fr:tex> of <fr:tex display="inline">V</fr:tex> such that
    <fr:tex display="inline">V = U \oplus  W</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>This post discusses about <fr:em>finite-dimensional vector space</fr:em>.
    But we have not yet defined what is dimension.
    We tempted to define the dimension as the length of basis intuitively.
    With this definition we should prove its well-definedness.
    That is, every basis has the same length.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>519</fr:anchor>
                <fr:addr type="user">thm-0009</fr:addr>
                <fr:route>thm-0009.xml</fr:route>
                <fr:title text="Basis length is invariant">Basis length is invariant</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a finite-dimensional vector space.
    Then every basis of <fr:tex display="inline">V</fr:tex> has the same length.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>This can be proved by <fr:link type="local" href="thm-0002.xml" addr="thm-0002" title="Length of linearly independent list  length of spanning list">Lemma 8</fr:link>.
    Now we can formally define the dimension of such spaces.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>520</fr:anchor>
                <fr:addr type="user">def-001V</fr:addr>
                <fr:route>def-001V.xml</fr:route>
                <fr:title text="Dimension">Dimension</fr:title>
                <fr:taxon>Definition</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>The <fr:strong>dimension</fr:strong> of a finite-dimensional vector space <fr:tex display="inline">V</fr:tex> is the length of any basis of the vector space.
    Denoted by <fr:tex display="inline">\dim  V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>Every subspace of a finite-dimensional vector space is also finite-dimensional.
    Hence we can talk about the dimension of a subspace.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>521</fr:anchor>
                <fr:addr type="user">thm-000A</fr:addr>
                <fr:route>thm-000A.xml</fr:route>
                <fr:title text="Dimension of a subspace">Dimension of a subspace</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex display="inline">U</fr:tex> be a subspace of <fr:tex display="inline">V</fr:tex>.
    Then <fr:tex display="inline">\dim  U \leq  \dim  V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>According to the definition of <fr:link type="local" href="def-000P.xml" addr="def-000P" title="Linearly independent">linearly independent</fr:link>,
    to show a list of vectors is a basis, we only need to show it is linearly independent,
    and it spans the whole space.
    The next theorems simplifies the task:</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>522</fr:anchor>
                <fr:addr type="user">thm-000B</fr:addr>
                <fr:route>thm-000B.xml</fr:route>
                <fr:title text="Linearly independent list of the right length is a basis">Linearly independent list of the right length is a basis</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link type="local" href="def-000P.xml" addr="def-000P" title="Linearly independent">linearly independent</fr:link> list of vectors in <fr:tex display="inline">V</fr:tex> with length equal to <fr:tex display="inline">\dim  V</fr:tex> is a basis of <fr:tex display="inline">V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>523</fr:anchor>
                <fr:addr type="user">thm-000C</fr:addr>
                <fr:route>thm-000C.xml</fr:route>
                <fr:title text="Spanning list of the right length is a basis">Spanning list of the right length is a basis</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a finite-dimensional vector space.
    Then every <fr:link type="local" href="def-000M.xml" addr="def-000M" title="Linear Span">spanning</fr:link> list of vectors in <fr:tex display="inline">V</fr:tex> with length equal to <fr:tex display="inline">\dim  V</fr:tex> is a basis of <fr:tex display="inline">V</fr:tex>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:p>Now we move to the discussion of the dimension of the sum of two subspaces.
    This is analogous to the <fr:link type="local" href="thm-000E.xml" addr="thm-000E" title="Inclusion-Exclusion Principle">inclusion-exclusion principle</fr:link>.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>524</fr:anchor>
                <fr:addr type="user">thm-000D</fr:addr>
                <fr:route>thm-000D.xml</fr:route>
                <fr:title text="Dimension of a sum">Dimension of a sum</fr:title>
                <fr:taxon>Theorem</fr:taxon>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>Let <fr:tex display="inline">V</fr:tex> be a finite-dimensional vector space,
    and <fr:tex display="inline">U</fr:tex> and <fr:tex display="inline">W</fr:tex> be subspaces of <fr:tex display="inline">V</fr:tex>.
    Then
    <fr:tex display="block">         \dim (U + W) = \dim  U + \dim  W - \dim (U \cap  W).     </fr:tex></fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
          </fr:mainmatter>
          <fr:backmatter></fr:backmatter>
        </fr:tree>
      </fr:mainmatter>
      <fr:backmatter></fr:backmatter>
    </fr:tree>
    <fr:tree toc="false" numbered="false" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
      <fr:frontmatter>
        <fr:title text="Backlinks">Backlinks</fr:title>
        <fr:authors></fr:authors>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree toc="true" numbered="false" show-heading="true" show-metadata="true" expanded="false" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
          <fr:frontmatter>
            <fr:anchor>1554</fr:anchor>
            <fr:addr type="user">math-0007</fr:addr>
            <fr:route>math-0007.xml</fr:route>
            <fr:title text="Vector Calculus and Geometry of Space">Vector Calculus and Geometry of Space</fr:title>
            <fr:taxon>Differential Geometry</fr:taxon>
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>4</fr:month>
              <fr:day>5</fr:day>
            </fr:date>
            <fr:authors></fr:authors>
          </fr:frontmatter>
          <fr:mainmatter>
            <fr:p>Notes about multi-variable calculus, geometry of space and linear algebra.
    Refer to <fr:link type="external" href="A%20Visual%20Introduction%20to%20Differential%20Forms%20and%20Calculus%20on%20Manifolds">df-cm-2018</fr:link>.</fr:p>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>651</fr:anchor>
                <fr:addr type="machine">#312</fr:addr>
                <fr:route>unstable-312.xml</fr:route>
                <fr:title text="Review of Vector Spaces">Review of Vector Spaces</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>We now start with introducing the vector space over the field of real numbers <fr:tex display="inline">\mathbb {R}</fr:tex>.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>652</fr:anchor>
                    <fr:addr type="user">def-000H</fr:addr>
                    <fr:route>def-000H.xml</fr:route>
                    <fr:title text="Vector Space">Vector Space</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A vector space over a <fr:link type="local" href="def-0006.xml" addr="def-0006" title="Field">field</fr:link> <fr:tex display="inline">F</fr:tex> is a non-empty set <fr:tex display="inline">V</fr:tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <fr:tex display="inline">V</fr:tex> are commonly called <fr:strong>vectors</fr:strong>, and the elements of <fr:tex display="inline">F</fr:tex> are called <fr:strong>scalars</fr:strong>.
    <fr:ul><fr:li>Commutativity: <fr:tex display="inline">             \forall  x, y \in  V, x + y = y + x         </fr:tex></fr:li>
        <fr:li>Associativity: <fr:tex display="inline">             \forall  x, y, z \in  V, (x + y) + z = x + (y + z)         </fr:tex></fr:li>
        <fr:li>Additive Identity: <fr:tex display="inline">             \exists  0 \in  V \text { such that } \forall  x \in  V, x + 0 = x         </fr:tex></fr:li>
        <fr:li>Multiplicative Identity: <fr:tex display="inline">             \forall  x \in  V, 1x = x         </fr:tex></fr:li>
        <fr:li>Additive Inverse: <fr:tex display="inline">             \forall  x \in  V, \exists  y \in  V \text { such that } x + y = 0         </fr:tex></fr:li>
        <fr:li>Distributivity: <fr:tex display="inline">             \forall  x, y \in  V, \forall  c, d \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx         </fr:tex></fr:li></fr:ul></fr:p>
                    <fr:p>Elements of a vector space are called <fr:strong>vectors</fr:strong> or <fr:strong>points</fr:strong>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Use <fr:tex display="inline">\mathbb {R}^2</fr:tex> as an example we can see (Note that we always treat elements of vector spaces as 
        column vectors and never as row vectors):
        <fr:tex display="block">             c \cdot  \begin {bmatrix}                 a \\ b             \end {bmatrix} = \begin {bmatrix}                 c \cdot  a \\ c \cdot  b             \end {bmatrix}         </fr:tex></fr:p>
                <fr:p>Now we will consider a certain type of transformation between vector spaces called a <fr:link type="local" href="def-0025.xml" addr="def-0025" title="Linear Map"><fr:strong>linear transformation</fr:strong></fr:link>.
        Suppose <fr:tex display="inline">T</fr:tex> is a mapping between <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>, that is <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex>, then <fr:tex display="inline">T</fr:tex> is a linear transformation if:
        <fr:tex display="block">             T(c \cdot  \vec {v}) = c \cdot  T(\vec {v})             \\              T(\vec {v} + \vec {w}) = T(\vec {v}) + T(\vec {w})         </fr:tex>
        If <fr:tex display="inline">T</fr:tex> is a linear transformation from <fr:tex display="inline">\mathbb {R}^m</fr:tex> to <fr:tex display="inline">\mathbb {R}</fr:tex> we simply call it a <fr:strong>linear function</fr:strong> or a <fr:strong>linear functional</fr:strong>.</fr:p>
                <fr:p>We now turn our attention to the relationship between linear transformation and matrices. 
        We just stick to vector spaces <fr:tex display="inline">\mathbb {R}^n</fr:tex> and the standard basis made up of the <fr:strong>Euclidian unit vectors</fr:strong>.
        In order to write linear transformation <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> as a matrix we need ordered bases for both <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
        We can use the intuitively obvious order <fr:tex display="inline">e_1 &lt; e_2 &lt; \cdots  &lt; e_n</fr:tex>.
        Now we can give formal definition of the matrix representation of a linear transformation.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>653</fr:anchor>
                    <fr:addr type="user">def-003W</fr:addr>
                    <fr:route>def-003W.xml</fr:route>
                    <fr:title text="Matrix Representation of Linear Transformation over {R}^n">Matrix Representation of Linear Transformation over <fr:tex display="inline">\mathbb {R}^n</fr:tex></fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>Suppose that <fr:tex display="inline">T:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> is a linear transformation between vector spaces <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
    Let <fr:tex display="inline">e_1, e_2, \ldots , e_n</fr:tex> be the standard basis of <fr:tex display="inline">\mathbb {R}^n</fr:tex> and <fr:tex display="inline">f_1, f_2, \ldots , f_m</fr:tex> be the standard basis of <fr:tex display="inline">\mathbb {R}^m</fr:tex>.
    Then the matrix representation of <fr:tex display="inline">T</fr:tex> is the <fr:tex display="inline">m \times  n</fr:tex> matrix <fr:tex display="inline">A</fr:tex> such that for <fr:tex display="inline">1\leq  j\leq  n</fr:tex>:
    <fr:tex display="block">         T(e_j) = \sum _{i=1}^m A_{ij} f_i     </fr:tex>
    where the matrix representation of <fr:tex display="inline">T</fr:tex> is given by the <fr:tex display="inline">m\times  n</fr:tex> matrix with entries <fr:tex display="inline">A_{ij}</fr:tex>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>The last major topic in this section is the definition of the <fr:link type="local" href="def-003X.xml" addr="def-003X" title="Dual Space">dual space</fr:link>.
        In our discussion, we only concern the dual space of <fr:tex display="inline">\mathbb {R}^n</fr:tex> which is denoted as <fr:tex display="inline">(\mathbb {R}^n)^*</fr:tex>.
        Now let&apos;s consider the <fr:strong>dual basis</fr:strong> of <fr:tex display="inline">(\mathbb {R}^n)^*</fr:tex> which is denoted as <fr:tex display="inline">\{T_1, \cdots , T_n\}</fr:tex>, 
        which is defined by:
        <fr:tex display="block">             T_i(e_j) = e^i(e_j) = \langle  e^i, e_j \rangle  = \delta _{j}^i         </fr:tex>
        where <fr:tex display="inline">\delta _{ij}</fr:tex> is the <fr:link type="local" href="def-001P.xml" addr="def-001P" title="Kronecker Delta">Kronecker delta</fr:link>. We say that <fr:tex display="inline">T_i</fr:tex> is dual to the vector <fr:tex display="inline">e_i</fr:tex>.
        Note that we also denote <fr:tex display="inline">T_i</fr:tex> as <fr:tex display="inline">e^i</fr:tex> using superscript notation. And the notation <fr:tex display="inline">\langle  e^i, e_j \rangle </fr:tex> d
        indicates the products of row vector <fr:tex display="inline">e^i</fr:tex> and column vector <fr:tex display="inline">e_j</fr:tex> (Usually used in quantum computing).
        <fr:tex display="block">             \alpha (v) = \langle  \alpha , v \rangle  = [a,b] \times  \begin {bmatrix}                 x \\ y             \end {bmatrix} = ax + by         </fr:tex>
        This explains wht we always denote elements of the vector space as column vectors, because elements of the dual space 
        are written as row vectors and its very important to distinguish between them.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>654</fr:anchor>
                <fr:addr type="machine">#313</fr:addr>
                <fr:route>unstable-313.xml</fr:route>
                <fr:title text="Dot Products">Dot Products</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>In linear algebra, <fr:strong>dot product</fr:strong> or <fr:strong>scalar product</fr:strong> is an operation that takes two vectors and returns a scalar.
        Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them.
        Dot product is also used to define lengths and angles.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>655</fr:anchor>
                    <fr:addr type="user">def-0041</fr:addr>
                    <fr:route>def-0041.xml</fr:route>
                    <fr:title text="Dot Product (Coordinate Form)">Dot Product (Coordinate Form)</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>The <fr:strong>dot product</fr:strong> of two vectors <fr:tex display="inline">\vec {a} = (a_1, a_2, \cdots , a_n)</fr:tex> and <fr:tex display="inline">\vec {b} = (b_1, b_2, \cdots , b_n)</fr:tex> is defined as
    <fr:tex display="block">         \vec {a}\cdot \vec {b} = a_1b_1 + a_2b_2 + \cdots  + a_nb_n = \sum _{i=1}^n a_ib_i.     </fr:tex>
    The dot product is also called the <fr:strong>inner product</fr:strong> or <fr:strong>scalar product</fr:strong>.
    The dot product satisfies the following properties:
    <fr:ul><fr:li><fr:strong>Commutative</fr:strong>: <fr:tex display="inline">\vec {a}\cdot \vec {b} = \vec {b}\cdot \vec {a}</fr:tex></fr:li>
        <fr:li><fr:strong>Distributive</fr:strong>: <fr:tex display="inline">\vec {a}\cdot (\vec {b} + \vec {c}) = \vec {a}\cdot \vec {b} + \vec {a}\cdot \vec {c}</fr:tex></fr:li>
        <fr:li><fr:strong>Bilinear</fr:strong>: <fr:tex display="inline">\vec {a}\cdot (k\vec {b}) = k(\vec {a}\cdot \vec {b}) = (\vec {a}\cdot  k\vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Scalar Multiplication</fr:strong>: <fr:tex display="inline">(c_1\vec {a}) \cdot  (c_2\vec {b}) = c_1c_2(\vec {a}\cdot \vec {b})</fr:tex></fr:li>
        <fr:li><fr:strong>Orthogonality</fr:strong>: If <fr:tex display="inline">\vec {a}\cdot \vec {b} = 0</fr:tex>, then <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> are <fr:strong>orthogonal</fr:strong></fr:li>
        <fr:li><fr:strong>Product Rule</fr:strong>: If <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> are vector valued differentiable functions then the derivative 
            of <fr:tex display="inline">\vec {a}\cdot \vec {b}</fr:tex> is given by the rule <fr:tex display="inline">(\vec {a}\cdot \vec {b})&apos; = \vec {a}&apos;\cdot \vec {b} + \vec {a}\cdot \vec {b}&apos;</fr:tex></fr:li></fr:ul></fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>656</fr:anchor>
                    <fr:addr type="user">def-0042</fr:addr>
                    <fr:route>def-0042.xml</fr:route>
                    <fr:title text="Dot Product (Geometric Form)">Dot Product (Geometric Form)</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>In <fr:strong>Euclidean space</fr:strong>, a <fr:strong>Euclidean vector</fr:strong> is a geometric object that possesses both 
    a norm and a direction. The <fr:strong>dot product</fr:strong> of two vectors <fr:tex display="inline">\vec {a}</fr:tex> and <fr:tex display="inline">\vec {b}</fr:tex> is defined as
    <fr:tex display="block">         \vec {a}\cdot \vec {b} = \lVert \vec {a}\rVert \lVert \vec {b}\rVert \cos \theta      </fr:tex>
    where <fr:tex display="inline">\theta </fr:tex> is the angle between the two vectors.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>The geometric definition of dot product helps us express the projection of one vector onto another as well as the component of 
        one vector in the direction of another. By simple geometry we can derive the formula for the <fr:strong>projection</fr:strong>
        <fr:tex display="block">             \text {proj}_{\vec {a}}\vec {b} = \frac {\vec {a}\cdot \vec {b}}{\lVert \vec {a}\rVert }\frac {\vec {a}}{\lVert \vec {a}\rVert }         </fr:tex>
        and the <fr:strong>component</fr:strong> of <fr:tex display="inline">\vec {b}</fr:tex> in the direction <fr:tex display="inline">\vec {a}</fr:tex> is given by
        <fr:tex display="block">             \text {comp}_{\vec {a}}\vec {b} = \lVert \text {proj}_{\vec {a}}\vec {b}\rVert  = \frac {\vec {a}\cdot \vec {b}}{\lVert \vec {a}\rVert }         </fr:tex></fr:p>
                <fr:p>Two points determine a line, and so does a point and a vector. Define the base point vector <fr:tex display="inline">\vec {b}=(x,y,z)</fr:tex> and
        the direction vector <fr:tex display="inline">\vec {v}=(a,b,c)</fr:tex> then the line is given by <fr:tex display="inline">\vec {r}(t)</fr:tex>
        <fr:tex display="block">             \vec {r}(t) = t\vec {v} + \vec {b} = (at+x, bt+y, ct+z)         </fr:tex>
        Solving for <fr:tex display="inline">t</fr:tex> in the equation we get
        <fr:tex display="block">             t = \frac {x-at}{a} = \frac {y-bt}{b} = \frac {z-ct}{c}         </fr:tex>
        which is the <fr:strong>equation of line</fr:strong>.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>657</fr:anchor>
                <fr:addr type="machine">#314</fr:addr>
                <fr:route>unstable-314.xml</fr:route>
                <fr:title text="Volume and Determinants">Volume and Determinants</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>The <fr:strong>determinant</fr:strong> has various properties and applications in linear algebra and geometry.
        For us the most useful thing about it will be how it relates to volume:
        the determinant of a matrix gives the <fr:strong>signed volume</fr:strong> of the parallelepiped that 
        is generated by the vectors given by the matrix columns.</fr:p>
                <fr:p>Determinants can be introduced in a variety of different ways but many of them are not at all clear.
        It usually relates to volume hence we will actually use our intuitive understanding of volumes and 
        three properties that we expected volume to have to derive the determinant (It is <fr:strong>uniquely</fr:strong> determined!).</fr:p>
                <fr:p>So how do we expect volume to behave?
        First we expect a unit cube to have a volume of one.
        Second we expect the <fr:strong>degenerate</fr:strong> parallelepiped to have a volume of zero. Basically in <fr:tex display="inline">n</fr:tex> dimensions any 
        <fr:tex display="inline">n-1</fr:tex> dimensions object has zero <fr:tex display="inline">n</fr:tex>-D volume.
        Third we expect that volumes to be <fr:strong>linear</fr:strong>.
        Now with these three properties we move to the actual mathematics.</fr:p>
                <fr:p>Suppose we have a parallelepiped <fr:tex display="inline">\mathscr {P}\in \mathbb {R}^n</fr:tex> whose edges are given by <fr:tex display="inline">v_1, v_2, \cdots , v_n\in \mathbb {R}^n</fr:tex>.
        We sat that the parallelepiped <fr:tex display="inline">\mathscr {P}</fr:tex> is the <fr:strong>span</fr:strong> of the vectors <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> and 
        write <fr:tex display="inline">\mathscr {P}=\text {span}\{v_1, v_2, \cdots , v_n\}</fr:tex> (Note that this span is different from linear span).
        We want to find function <fr:tex display="inline">D:\mathbb {R}^{n\times  n}\to \mathbb {R}</fr:tex> which takes <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> or a matrix with <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> as columns
        to a real number which is the volume of <fr:tex display="inline">\mathscr {P}</fr:tex>. Now we present the three properties in mathematical form.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>658</fr:anchor>
                    <fr:addr type="machine">#315</fr:addr>
                    <fr:route>unstable-315.xml</fr:route>
                    <fr:title text="Properties of Volume">Properties of Volume</fr:title>
                    <fr:date>
                      <fr:year>2024</fr:year>
                      <fr:month>4</fr:month>
                      <fr:day>5</fr:day>
                    </fr:date>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:ul><fr:li><fr:tex display="inline"> D(I) = I </fr:tex> where <fr:tex display="inline">I = [e_1, e_2, \cdots , e_n]</fr:tex> is the identity matrix.</fr:li>
            <fr:li><fr:tex display="inline"> D(v_1, v_2, \cdots , v_n) = 0 </fr:tex> if <fr:tex display="inline">v_i = v_j</fr:tex> for any <fr:tex display="inline">i\neq  j</fr:tex>.</fr:li>
            <fr:li><fr:tex display="inline"> D(v_1, \cdots , v_{j-1}, v+cw, v_{j+1}, \cdots , v_n) \\                  = D(v_1, \cdots , v_{j-1}, v, v_{j+1}, \cdots , v_n) + cD(v_1, \cdots , v_{j-1}, w, v_{j+1}, \cdots , v_n) </fr:tex>
                for any <fr:tex display="inline">1 \leq  j \leq  n</fr:tex>, that is, <fr:tex display="inline">D</fr:tex> is linear.</fr:li></fr:ul>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Now we use these properties of volume to derive several other useful properties.
        The first property is that the volumes are signed.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>659</fr:anchor>
                    <fr:addr type="machine">#316</fr:addr>
                    <fr:route>unstable-316.xml</fr:route>
                    <fr:title text="Derived Properties of Volume Function">Derived Properties of Volume Function</fr:title>
                    <fr:date>
                      <fr:year>2024</fr:year>
                      <fr:month>4</fr:month>
                      <fr:day>5</fr:day>
                    </fr:date>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:ul><fr:li><fr:tex display="inline">D</fr:tex> is alternating, if we switch any two vectors the sign changes.
                <fr:tex display="block">                     D(v_1, \cdots , v_i, \cdots , v_j, \cdots , v_n) = -D(v_1, \cdots , v_j, \cdots , v_i, \cdots , v_n)                 </fr:tex></fr:li> 
            <fr:li>If <fr:tex display="inline">v_1, v_2, \cdots , v_n</fr:tex> are <fr:link type="local" href="def-000Q.xml" addr="def-000Q" title="Linearly dependent">linear dependent</fr:link> then
                <fr:tex display="block">                     D(v_1, v_2, \cdots , v_n) = 0                 </fr:tex></fr:li>
            <fr:li>Adding a multiple of one vector to another does not change the determinant.</fr:li></fr:ul>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>We almost ready to derive the formula for determinant. The final ingredient we need to do is <fr:strong>permutations</fr:strong>.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>660</fr:anchor>
                    <fr:addr type="user">def-003Y</fr:addr>
                    <fr:route>def-003Y.xml</fr:route>
                    <fr:title text="Permutation">Permutation</fr:title>
                    <fr:taxon>Defintion</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A <fr:strong>permutation</fr:strong> of a set <fr:tex display="inline">S</fr:tex> is a bijection from <fr:tex display="inline">S</fr:tex> to itself.
    The set of permutation of <fr:tex display="inline">\{1,\cdots , n\}</fr:tex> is usually denoted by <fr:tex display="inline">S_n</fr:tex>.
    We often denote a particular permutation <fr:tex display="inline">\sigma </fr:tex> by <fr:strong>Cauchy&apos;s two-line notation</fr:strong>:
    <fr:tex display="block">         \begin {bmatrix}             1 &amp; 2 &amp; \cdots  &amp; n \\             \sigma (1) &amp; \sigma (2) &amp; \cdots  &amp; \sigma (n)         \end {bmatrix}     </fr:tex>
    or <fr:strong>Cauchy&apos;s one-line notation</fr:strong>: <fr:tex display="inline">(\sigma (1),\sigma (2),\cdots ,\sigma (n))</fr:tex>.
    Another common notation is the <fr:strong>cycle notation</fr:strong>:
    <fr:tex display="block">         (i_1\ i_2\ \cdots \ i_k)     </fr:tex> which means <fr:tex display="inline">i_1 \to  i_2 \to  \cdots  \to  i_k \to  i_1</fr:tex>.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>661</fr:anchor>
                    <fr:addr type="user">def-003Z</fr:addr>
                    <fr:route>def-003Z.xml</fr:route>
                    <fr:title text="Transposition">Transposition</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>A <fr:link type="local" href="def-003Y.xml" addr="def-003Y" title="Permutation">permutation</fr:link> in which only two elements are exchanged is called a <fr:strong>transposition</fr:strong>.
    The notation is <fr:tex display="inline">\tau _{i,j}</fr:tex> where <fr:tex display="inline">i</fr:tex> and <fr:tex display="inline">j</fr:tex> are the two elements exchanged while the others remain fixed.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Notice that the composition of two permutations is also a permutation. 
        And for any permutation <fr:tex display="inline">\sigma </fr:tex> we can perform a series of transpositions to get the identity permutation.
        It turns out that the count of the number of transpositions needed to get the identity permutation is always the same,
        which is called the <fr:strong>parity</fr:strong> of the permutation.</fr:p>
                <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
                  <fr:frontmatter>
                    <fr:anchor>662</fr:anchor>
                    <fr:addr type="user">def-0040</fr:addr>
                    <fr:route>def-0040.xml</fr:route>
                    <fr:title text="Sign of Permutation">Sign of Permutation</fr:title>
                    <fr:taxon>Definition</fr:taxon>
                    <fr:authors></fr:authors>
                  </fr:frontmatter>
                  <fr:mainmatter>
                    <fr:p>The <fr:strong>sign</fr:strong> of a <fr:link type="local" href="def-003Y.xml" addr="def-003Y" title="Permutation">permutation</fr:link> <fr:tex display="inline">\sigma \in  S_n</fr:tex> is a function <fr:tex display="inline">\text {sgn}:S_n\to \{-1,1\}</fr:tex> defined as
    <fr:tex display="inline">\text {sgn}(\sigma ) = 1</fr:tex> if <fr:tex display="inline">\sigma </fr:tex> requires an even number of permutations and 
    <fr:tex display="inline">\text {sgn}(\sigma ) = -1</fr:tex> if <fr:tex display="inline">\sigma </fr:tex> requires an odd number of permutations to get the identity permutation.</fr:p>
                  </fr:mainmatter>
                  <fr:backmatter></fr:backmatter>
                </fr:tree>
                <fr:p>Now we define the permutation of unit vectors <fr:tex display="inline">E_\sigma  = [e_{\sigma (1)}, e_{\sigma (2)}, \cdots , e_{\sigma (n)}]</fr:tex>.
        We got the property that
        <fr:tex display="block">             D(E_\sigma ) = \text {sgn}(\sigma )D(I) = \text {sgn}(\sigma )         </fr:tex>
        Now we have all the pieces necessary to find a formula that will give the volume of the parallelepiped spanned
        by <fr:tex display="inline">n</fr:tex> vectors.
        <fr:tex display="block">             \begin {align*}                 D\left (\begin {bmatrix}                     a_{11} &amp; a_{12} &amp; \cdots  &amp; a_{1n} \\                     a_{21} &amp; a_{22} &amp; \cdots  &amp; a_{2n} \\                     \vdots  &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                     a_{n1} &amp; a_{n2} &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) &amp;= \sum _{i_1=1}^n a_{i_11}D\left (\begin {bmatrix}                     | &amp; a_{12} &amp; \cdots  &amp; a_{1n} \\                     e_{i_1} &amp; a_{22} &amp; \cdots  &amp; a_{2n} \\                     | &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                     | &amp; a_{n2} &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) \\                  &amp;= \sum _{i_1=1}^n a_{i_11} \sum _{i_2=1}^n a_{i_22}D\left (\begin {bmatrix}                     | &amp; | &amp; \cdots  &amp; a_{1n} \\                     e_{i_1} &amp; e_{i_2} &amp; \cdots  &amp; a_{2n} \\                     | &amp; | &amp; \vdots  &amp; \vdots  \\                     | &amp; | &amp; \cdots  &amp; a_{nn}                 \end {bmatrix}\right ) \\                 &amp;= \vdots  \\                  &amp;= \sum _{i_1, i_2, \cdots , i_n = 1}^{n} a_{i_11}a_{i_22}\cdots  a_{i_nn}D\left (                     \begin {bmatrix}                         | &amp; | &amp;  &amp; | \\                         e_{i_1} &amp; e_{i_2} &amp; \cdots  &amp; e_{i_n} \\                         | &amp; | &amp;  &amp; | \\                     \end {bmatrix}                 \right ) \\                  &amp;= \sum _{\sigma \in  S_n} a_{\sigma (1)1}\cdots  a_{\sigma (n)n}                 D\left (                     \begin {bmatrix}                         | &amp; | &amp;  &amp; | \\                         e_{\sigma (1)} &amp; e_{\sigma (2)} &amp; \cdots  &amp; e_{\sigma (n)} \\                         | &amp; | &amp;  &amp; | \\                     \end {bmatrix}                 \right ) \\                  &amp;= \sum _{\sigma \in  S_n} a_{\sigma (1)1}a_{\sigma (2)2}\cdots  a_{\sigma (n)n} \text {sgn}(\sigma ) \\                  &amp;= \sum _{\sigma \in  S_n} \text {sgn}(\sigma ) \prod _{i=1}^n a_{\sigma (i)i}             \end {align*}         </fr:tex>
        In the forth step we transform the terms because the value of <fr:tex display="inline">D</fr:tex> is zero for any <fr:tex display="inline">{i_j} = {i_k}</fr:tex>,
        non-zero terms should be permutation of <fr:tex display="inline">S_n</fr:tex>.</fr:p>
                <fr:p>It&apos;s easy to validate that the following properties of the determinant holds:
        <fr:ul><fr:li><fr:tex display="inline">D(AB) = D(A)D(B)</fr:tex></fr:li>
            <fr:li><fr:tex display="inline">D(A) = D(A^T)</fr:tex></fr:li></fr:ul>
        The second statement for transpose of <fr:tex display="inline">A</fr:tex> indicates that all the properties above also holds for row as well.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
            <fr:tree toc="true" numbered="true" show-heading="true" show-metadata="false" expanded="true" root="false" xmlns:fr="http://www.jonmsterling.com/jms-005P.xml">
              <fr:frontmatter>
                <fr:anchor>663</fr:anchor>
                <fr:addr type="machine">#317</fr:addr>
                <fr:route>unstable-317.xml</fr:route>
                <fr:title text="Derivatives of Multivariable Functions">Derivatives of Multivariable Functions</fr:title>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>5</fr:day>
                </fr:date>
                <fr:authors></fr:authors>
              </fr:frontmatter>
              <fr:mainmatter>
                <fr:p>In this section we will introduce the idea of the derivative of a multivariable function. 
        Recall that a function <fr:tex display="inline">f:\mathbb {R}\to \mathbb {R}</fr:tex> the derivative of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">x_0\in \mathbb {R}</fr:tex> is given by
        <fr:tex display="block">             f&apos;(x_0) = \lim _{h\to  0} \frac {f(x_0+h) - f(x_0)}{h}         </fr:tex>
        if the limit exists. Now let&apos;s do some transformations:
        <fr:tex display="block">             \begin {align*}                 &amp; f&apos;(x_0) = \lim _{h\to  0} \frac {f(x_0+h) - f(x_0)}{h} \\                 \implies  &amp; \lim _{h\to  0} \frac {f(x_0+h) - f(x_0) -f&apos;(x_0)h }{h} = 0 \\                 \implies  &amp; \lim _{x\to  x_0} \frac {f(x) - f(x_0) - f&apos;(x_0)(x-x_0)}{x-x_0} = 0 \\                  \implies  &amp; \lim _{x\to  x_0} \frac {|f(x) - f(x_0) - f&apos;(x_0)(x-x_0)|}{|x-x_0|} = 0             \end {align*}         </fr:tex></fr:p>
                <fr:p>Since <fr:tex display="inline">f&apos;(x_0)</fr:tex> represents the slope of the line tangent to the graph of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">(x_0, f(x_0))</fr:tex>,
        differentiability of <fr:tex display="inline">f</fr:tex> at <fr:tex display="inline">x_0</fr:tex> means that there exists a number <fr:tex display="inline">m</fr:tex> st
        <fr:tex display="block">             \lim _{x\to  x_0} \frac {|f(x) - f(x_0) - m(x-x_0)|}{|x-x_0|} = 0         </fr:tex>
        Now consider the function <fr:tex display="inline">T:\mathbb {R}\to \mathbb {R}</fr:tex> where <fr:tex display="inline">T(s) = ms</fr:tex>
        <fr:tex display="block">             T(s+t) = m(s+t) = ms + mt = T(s) + T(t)             \\              T(cs) = mcs = c(ms) = cT(s)         </fr:tex>
        then <fr:tex display="inline">T</fr:tex> is a linear transformation. In fact <fr:tex display="inline">T</fr:tex> is the linear function that most closely approximates the 
        function <fr:tex display="inline">f</fr:tex> at the point <fr:tex display="inline">(x_0, f(x_0))</fr:tex>. So for <fr:tex display="inline">x</fr:tex> values that are very close to <fr:tex display="inline">x_0</fr:tex> we have
        <fr:tex display="block">             f(x) \approx  m(x-x_0) + f(x_0)         </fr:tex></fr:p>
                <fr:p>Now let&apos;s generalize the concept of derivatives to functions of the form <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}^m</fr:tex>.
        We assume the function <fr:tex display="inline">f</fr:tex> has the form
        <fr:tex display="block">             \begin {align*}                 &amp;f(x_1, x_2, \cdots , x_n) =                  \\                  &amp;(f_1(x_1, x_2, \cdots , x_n), f_2(x_1, x_2, \cdots , x_n), \cdots , f_m(x_1, x_2, \cdots , x_n))             \end {align*}         </fr:tex>
        We want to search for this linear transformation which we will denoted by <fr:tex display="inline">Df</fr:tex>,
        that most closely approximates this function <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}^m</fr:tex> at some specific point <fr:tex display="inline">x_0=(x_{1_0}, x_{2_0}, \cdots , x_{n_0}) \in  \mathbb {R}^n</fr:tex>.
        If <fr:tex display="inline">f</fr:tex> is differentiable at <fr:tex display="inline">x_0</fr:tex> then there exists a linear transformation <fr:tex display="inline">Df(x_0):\mathbb {R}^n\to \mathbb {R}^m</fr:tex> such that
        <fr:tex display="block">             \lim _{x\to  x_0} \frac {                 \lVert                      f(x) - f(x_0) - Df(x_0)(x-x_0)                 \rVert              }{\lVert x-x_0\rVert } = 0         </fr:tex>
        The <fr:tex display="inline">\lVert \cdot \rVert </fr:tex> represents the <fr:strong>Euclidean norm</fr:strong> of the vector (Multi-dimensional version of the absolute value)
        <fr:tex display="block">             \lVert \vec {x}\rVert  = \sqrt {x_1^2 + x_2^2 + \cdots  + x_n^2} = \sqrt {\sum _{i=1}^n x_i^2}         </fr:tex>
        which is just the length of the vector. This allows us to perform dividing.</fr:p>
                <fr:p>As before we have
        <fr:tex display="block">             f(x) \approx  Df(x_0)(x-x_0) + f(x_0)         </fr:tex>
        Now we want to write <fr:tex display="inline">Df(x)</fr:tex> as a matrix. Denote the basis of <fr:tex display="inline">\mathbb {R}^n</fr:tex> as <fr:tex display="inline">e_j</fr:tex> and the basis of <fr:tex display="inline">\mathbb {R}^m</fr:tex> as <fr:tex display="inline">f_i</fr:tex>.
        Then we want to find <fr:tex display="inline">a_{ij}</fr:tex> st
        <fr:tex display="block">             Df(x)(e_j) = \sum _{i=1}^{m} a_{ij} f_j = \begin {bmatrix}                 a_{1j} \\ a_{2j} \\ \vdots  \\ a_{mj}             \end {bmatrix}         </fr:tex>
        In other words, the <fr:tex display="inline">i</fr:tex>-th component of the <fr:tex display="inline">j</fr:tex>-th column of <fr:tex display="inline">Df(x)</fr:tex> is just the <fr:tex display="inline">i</fr:tex>-th component of the <fr:tex display="inline">Df(x)(e_j)</fr:tex></fr:p>
                <fr:p>Recall from vector calculus that given a function <fr:tex display="inline">f:\mathbb {R}^n\to \mathbb {R}</fr:tex> we defined the <fr:strong>partial derivative</fr:strong> of <fr:tex display="inline">f</fr:tex> with respect to the <fr:tex display="inline">x_j</fr:tex> as 
        <fr:tex display="block">             \frac {\partial  f}{\partial  x_j} = \lim _{h\to 0}             \frac {f(x_1,\cdots ,x_j+h,\cdots ,x_n) - f(x_1,\cdots ,x_n)}{h}         </fr:tex>
        Hence we can define the partial derivatives for each <fr:tex display="inline">f_i (1\leq  i\leq  m)</fr:tex> with respect to each <fr:tex display="inline">x_j (1\leq  j\leq  n)</fr:tex>.
        <fr:tex display="block">             \frac {\partial  f_i}{\partial  x_j} = \lim _{h\to 0}             \frac {f_i(x_1,\cdots ,x_j+h,\cdots ,x_n) - f_i(x_1,\cdots ,x_n)}{h}         </fr:tex>
        Thus we have
        <fr:tex display="block">             \frac {\partial  f_i}{\partial  x_j} = a_{ij}         </fr:tex>
        To find <fr:tex display="inline">a_{ij}</fr:tex> of <fr:tex display="inline">Df(x_0)</fr:tex> we need to find the <fr:tex display="inline">i</fr:tex>-th element of <fr:tex display="inline">Df(x_0)(e_j)</fr:tex>. Let
        <fr:tex display="block">             x = \begin {bmatrix}                 x_{1_0} \\ x_{2_0} \\ \vdots  \\ x_{n_0}             \end {bmatrix} + \begin {bmatrix}                 0 \\ \vdots  \\ 1 \\ \vdots  \\ 0             \end {bmatrix} = x_0 + he_j         </fr:tex>
        We have 
        <fr:tex display="block">             \lim _{x\to  x_0}\frac {\lVert f(x)-f(x_0)-Df(x_0)(he_j)\rVert }{\lVert he_j\rVert }             \\ \implies               \lim _{h\to 0}\frac {\lVert                  f(x_0+he_j) - f(x_0) -hDf(x_0)(e_j)             \rVert }{\lVert h\rVert } = 0         </fr:tex>
        The component is given by 
        <fr:tex display="block">             \lim _{h\to 0}\frac {\lVert f_i(x_0+he_j)-f_i(x_0)-ha_{ij}\rVert }{\lVert h\rVert } = 0             \\ \implies               a_{ij} = \lim _{h\to 0}\frac {f_i(x_0+he_j) - f_i(x_0)}{h}         </fr:tex>
        which is exactly <fr:tex display="inline">\frac {\partial  f_i}{\partial  x_j}</fr:tex>. Thus the matrix representation of <fr:tex display="inline">Df(x)</fr:tex> is given by 
        a matrix called the <fr:strong>Jacobin matrix</fr:strong> of <fr:tex display="inline">f</fr:tex>.
        <fr:tex display="block">             Df(x) = \begin {bmatrix}                 \frac {\partial  f_1}{\partial  x_1} &amp; \frac {\partial  f_1}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_1}{\partial  x_n} \\                 \frac {\partial  f_2}{\partial  x_1} &amp; \frac {\partial  f_2}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_2}{\partial  x_n} \\                 \vdots  &amp; \vdots  &amp; \ddots  &amp; \vdots  \\                 \frac {\partial  f_m}{\partial  x_1} &amp; \frac {\partial  f_m}{\partial  x_2} &amp; \cdots  &amp; \frac {\partial  f_m}{\partial  x_n}             \end {bmatrix} = \left [                 \frac {\partial  f_i}{\partial  x_j}             \right ]         </fr:tex>
        where <fr:tex display="inline">i</fr:tex> ranges row and <fr:tex display="inline">j</fr:tex> ranges column.</fr:p>
              </fr:mainmatter>
              <fr:backmatter></fr:backmatter>
            </fr:tree>
          </fr:mainmatter>
          <fr:backmatter></fr:backmatter>
        </fr:tree>
      </fr:mainmatter>
      <fr:backmatter></fr:backmatter>
    </fr:tree>
  </fr:backmatter>
</fr:tree>