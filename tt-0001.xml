<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="forest.xsl"?>
<tree expanded="true" show-heading="true" show-metadata="true" toc="false" numbered="false" root="false"><frontmatter><anchor>990</anchor>  <taxon>Type Theory</taxon> <addr>tt-0001</addr>  <route>tt-0001.xml</route> <date><year>2024</year> <month>1</month> <day>26</day></date>  <title>Untyped Lambda Calculus</title> </frontmatter> <mainmatter><p>
    Refer to <link href="ttafp-2014.xml" type="local" addr="ttafp-2014" title="Type Theory and Formal Proofs">Type Theory and Formal Proof</link>.
</p><p>
In dealing with functions there are two <strong>construction principles</strong> and one <strong>evalutaion rule</strong>
<ul><li>Construction Principles</li>
<ul><li>Function Abstraction: <tex>\lambda  x.M</tex></li>
<li>Function Application: <tex>M N</tex></li></ul>
<li>Evaluation Rule</li>
<ul><li>Beta Reduction: <tex>( \lambda  x.M)N \to  M[N/x]</tex></li></ul></ul>
The beta reduction makes use of the <strong>substitution</strong> <tex>M[N/x]</tex> which represents the result of replacing all free occurences of <tex>x</tex> in <tex>M</tex> with <tex>N</tex>.
</p>
<p>Expressions in the lambda calculus is called <strong>terms</strong>. The set of terms is denoted <tex>\Lambda</tex>.</p>
<tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>991</anchor>  <taxon>Definition</taxon> <addr>def-000F</addr>  <route>def-000F.xml</route>   <title>Set of Lambda Terms</title> </frontmatter> <mainmatter><p>
Let <tex>\Lambda</tex> be the set of lambda terms. Then <tex>\Lambda</tex> is defined inductively as follows:
(<tex>V</tex> is the set of variables)
<ul><li>Variable: <tex>\forall  x \in  V, x \in   \Lambda</tex></li>
<li>Abstraction: <tex>\forall  x \in  V, M \in   \Lambda ,  \lambda  x.M \in   \Lambda</tex></li>
<li>Application: <tex>\forall  M,N \in   \Lambda , (MN) \in   \Lambda</tex></li></ul></p><p>
Another way to define <tex>\Lambda</tex> is to use the following grammar (The 3 possibilities are separated by <code>|</code>):
<tex display="block">\Lambda  = V |  \lambda  V. \Lambda  |  \Lambda \Lambda</tex></p></mainmatter> </tree> 
</mainmatter> <backmatter><contributions/> <context><tree expanded="false" show-heading="true" show-metadata="true" toc="false" numbered="false" root="false"><frontmatter><anchor>992</anchor>   <addr>notes</addr>  <route>notes.xml</route>   <title>Notes</title> </frontmatter> <mainmatter><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>993</anchor>  <taxon>Set Theory</taxon> <addr>math-0003</addr>  <route>math-0003.xml</route> <date><year>2024</year> <month>1</month> <day>26</day></date>  <title>Set Theory</title> </frontmatter> <mainmatter><p>
    Refer to <link href="cat-sci-2013.xml" type="local" addr="cat-sci-2013" title="Category theory for scientists">Category Theory for Scientists</link>.
</p><p><strong>Set</strong> is a common concept in mathematics.
    This post is a brief introduction to set theory aimed at 
    complete all basic knowledge of set theory.
    The following topics will be covered
    <ul><li><strong>Zermelo-Fraenkel Axioms</strong> and <strong>Axiom of Choice</strong></li>
        <li>Cardinality</li>
        <li>Set theory constructions</li></ul></p><p>
    In this post, we use the Zermelo-Fraenkel set theory with the Axiom of Choice (<strong>ZFC</strong>).
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>994</anchor>  <taxon>Definition</taxon> <addr>def-000S</addr>  <route>def-000S.xml</route>   <title>ZFC Set</title> </frontmatter> <mainmatter><p><strong>ZFC</strong> is the abbreviation of Zermelo-Fraenkel set theory with the Axiom of Choice.
    The axioms of ZFC are listed below.
    <ul><li><strong>Axiom of Extensionality</strong>:
            Two sets are equal if and only if they have the same elements.
        </li>
        <li><strong>Axiom of Pairing</strong>:
            For any two sets <tex>a</tex> and <tex>b</tex>,
            there exists a set <tex>\{   a,b   \}</tex> whose elements are exactly <tex>a</tex> and <tex>b</tex>.
        </li>
        <li><strong>Axiom schema of Separation</strong>:
            Let <tex>P</tex> is a property of sets.
            <tex>P(u)</tex> means <tex>u</tex> satisfies the property <tex>P</tex>.
            then for any set <tex>X</tex> exists <tex>Y =  \{   u  \in  X | P(u)   \}</tex>.
        </li>
        <li><strong>Axiom of Union</strong>:
            For any set <tex>X</tex> (a family of sets), exists union set <tex>\bigcup  X : \equiv   \{   
                u: \exists  v \in  X  \text { such that } u \in  v
               \}</tex>.
        </li>
        <li><strong>Axiom of Power Set</strong>:
            For any set <tex>X</tex>, exists the power <tex>P(X) : \equiv   \{   Y:Y \subseteq  X   \}</tex>.
        </li>
        <li><strong>Axiom of Infinity</strong>:
            There exists a set <tex>\omega</tex> such that <tex>\emptyset \in \omega</tex> and for any <tex>x \in \omega</tex>, <tex>x \cup \{   x   \} \in \omega</tex>.
        </li>
        <li><strong>Axiom of Regularity</strong>:
            For any non-empty set there is a minimal element with respect to the membership relation.
        </li>
        <li><strong>Axiom schema of Replacement</strong>:
            Let <tex>F</tex> be a function where <tex>\text {dom }  f = X</tex>, then for any set <tex>X</tex> exists a set <tex>Y =  \{   F(x):x \in  X   \}</tex>.
            <p>
                This function is not the normal function but some logical stuff.
            </p></li>
        <li><strong>Axiom of Choice</strong>:
            For any family of non-empty sets <tex>X</tex>, there exists a function <tex>f:X \to \bigcup  X</tex> such that for any <tex>x \in  X</tex>, <tex>f(x) \in  x</tex>.
        </li></ul></p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>995</anchor>  <taxon>Definition</taxon> <addr>def-002V</addr>  <route>def-002V.xml</route>   <title>Set Operations</title> </frontmatter> <mainmatter><p>
    Let <tex>(X_i)_{i \in  I}</tex> be a family of sets.
</p><block open="open"><headline><strong>Union</strong></headline> 
    <tex display="block">
         \bigcup _{i \in  I}X_i =  \set {x: \exists  i \in  I  \text { such that } x \in  X_i}
    </tex>
</block><block open="open"><headline><strong>Intersection</strong></headline> 
    <tex display="block">
         \bigcap _{i \in  I}X_i =  \set {x: \forall  i \in  I, x \in  X_i}
    </tex>
    Note that <tex>I  \neq   \emptyset</tex> here.
</block><block open="open"><headline><strong>Disjoint Union</strong></headline> 
    <tex display="block">
         \bigsqcup _{i \in  I}X_i =  \set {(x,i):x \in  X_i, i \in  I}
    </tex>
</block><block open="open"><headline><strong>Product</strong></headline> 
    <tex display="block">
         \prod _{i \in  I}X_i =  \set {(x_i)_{i \in  I}: \forall  i \in  I, x_i \in  X_i}
    </tex>
</block></mainmatter> </tree><p>
    And principles of set theory
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>996</anchor>  <taxon>Definition</taxon> <addr>def-000T</addr>  <route>def-000T.xml</route>   <title>Principle of Extensionality</title> </frontmatter> <mainmatter><p>
    Two sets are equal if and only if they have the same elements.
</p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>997</anchor>  <taxon>Definition</taxon> <addr>def-000U</addr>  <route>def-000U.xml</route>   <title>Principle of Comprehension</title> </frontmatter> <mainmatter><p>
    Given a set <tex>A</tex> and a property <tex>P(x)</tex>, there exists a set <tex>B</tex> such that
    <tex>x \in  B  \iff  x \in  A  \land  P(x)</tex>.
</p></mainmatter> </tree><p>
    We then define the Cartesian product of two sets
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>998</anchor>  <taxon>Definition</taxon> <addr>def-000V</addr>  <route>def-000V.xml</route>   <title>Cartesian product</title> </frontmatter> <mainmatter><p>
    Given two sets <tex>A</tex> and <tex>B</tex>, the Cartesian product <tex>A \times  B</tex> is the set
    of all ordered pairs <tex>(a,b)</tex> where <tex>a \in  A</tex> and <tex>b \in  B</tex>.
</p></mainmatter> </tree><p>
    With the Cartesian product, we can define the relation
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>999</anchor>  <taxon>Definition</taxon> <addr>def-000W</addr>  <route>def-000W.xml</route>   <title>Relation</title> </frontmatter> <mainmatter><p>
    A <strong>relation</strong> <tex>R</tex> is a subset of the Cartesian product of two sets <tex>A</tex> and
    <tex>B</tex>, i.e. <tex>R \subseteq  A \times  B</tex>.
    If <tex>(a,b) \in  R</tex>, we write <tex>aRb</tex>.

    A relation that between <tex>X</tex> and itself is called <strong>homogeneous relation</strong>.
</p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1000</anchor>  <taxon>Definition</taxon> <addr>def-000X</addr>  <route>def-000X.xml</route>   <title>Equivalence Relation</title> </frontmatter> <mainmatter><p>
    An equivalence relation <tex>R</tex> on a set <tex>A</tex> is a <link href="def-000W.xml" type="local" addr="def-000W" title="Relation">relation</link> that is reflexive,
    symmetric, and transitive.
    <ul><li>Reflexive:
            <tex>\forall  x \in  A, xRx</tex></li>
        <li>Symmetric:
            <tex>\forall  x,y \in  A, xRy \implies  yRx</tex></li>
        <li>Transitive:
            <tex>\forall  x,y,z \in  A, xRy \land  yRz \implies  xRz</tex></li></ul>
    We often denote the equivalence relation by <tex>\sim</tex>.
</p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1001</anchor>  <taxon>Definition</taxon> <addr>def-002U</addr>  <route>def-002U.xml</route>   <title>Equivalence Class</title> </frontmatter> <mainmatter><p>
    Let <tex>\sim</tex> be an <link href="def-000X.xml" type="local" addr="def-000X" title="Equivalence Relation">equivalence relation</link> on a set <tex>A</tex>.
    For any element <tex>a \in  A</tex>, the <strong>equivalence class</strong> of <tex>a</tex> is the set
    <tex>[a] =  \set {b \in  A:b \sim  a}</tex>.
    The set of all equivalence classes is denoted by <tex>A/ \sim</tex>,
    which is called the <strong>quotient set</strong> of <tex>A</tex> by <tex>\sim</tex>.
    <p>
        The equivalence class of <tex>a</tex> is also denoted by <tex>\overline {a}</tex>.
    </p></p></mainmatter> </tree><p>
    One of the most important relations is the order relation.
    The basic order relation is the preorder.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1002</anchor>  <taxon>Definition</taxon> <addr>def-000Z</addr>  <route>def-000Z.xml</route>   <title>Preorder</title> </frontmatter> <mainmatter><p>
    A <strong>preorder</strong> is a relation <tex>\leq</tex> that is reflexive and transitive.
    <ul><li>Reflexive: <tex>a \leq  a</tex></li>
        <li>Transitive: <tex>a \leq  b</tex> and <tex>b \leq  c</tex> implies <tex>a \leq  c</tex></li></ul></p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1003</anchor>  <taxon>Definition</taxon> <addr>def-000Y</addr>  <route>def-000Y.xml</route>   <title>Partial Order</title> </frontmatter> <mainmatter><p>
    A <strong>(non-strict) partial order</strong> is a relation <tex>\leq</tex> that is reflexive, antisymmetric and transitive.
    <ul><li>Reflexive: <tex>a \leq  a</tex></li>
        <li>Antisymmetric: <tex>a \leq  b</tex> and <tex>b \leq  a</tex> implies <tex>a=b</tex></li>
        <li>Transitive: <tex>a \leq  b</tex> and <tex>b \leq  c</tex> implies <tex>a \leq  c</tex></li></ul>
    A non-strict partial order is also known as an antisymmetric <link href="def-000Z.xml" type="local" addr="def-000Z" title="Preorder">preorder</link>.
</p></mainmatter> </tree><p>
    And the strict partial order (notice the difference between asymmetric and antisymmetric)
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1004</anchor>  <taxon>Definition</taxon> <addr>def-0010</addr>  <route>def-0010.xml</route>   <title>Strict partial orders</title> </frontmatter> <mainmatter><p>
    A strict partial order is a relation <tex>&lt;</tex> that is irreflexive, asymmetric and transitive.
    <ul><li>Irreflexive: <tex>\neg (a&lt;a)</tex></li>
        <li>Asymmetric: <tex>a&lt;b</tex> implies <tex>\neg (b&lt;a)</tex></li>
        <li>Transitive: <tex>a&lt;b</tex> and <tex>b&lt;c</tex> implies <tex>a&lt;c</tex></li></ul></p></mainmatter> </tree><p>
    With the definition of order, we can define the upper bound and lower bound
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1005</anchor>  <taxon>Definition</taxon> <addr>def-0011</addr>  <route>def-0011.xml</route>   <title>Upper Bound and Lower Bound</title> </frontmatter> <mainmatter><p>
    Let a subset <tex>S</tex> of a <link href="def-000Y.xml" type="local" addr="def-000Y" title="Partial Order">partially ordered</link> set <tex>(P,  \leq )</tex>,
    <tex>S</tex> is bounded above if there exists <tex>x  \in  P</tex> such that <tex>\forall  y  \in  S, y  \leq  x</tex>. And <tex>x</tex> is called an <strong>upper bound</strong> of <tex>S</tex>.
    Dually, <tex>S</tex> is bounded below if there exists <tex>x  \in  P</tex> such that <tex>\forall  y  \in  S, x  \leq  y</tex>. And <tex>x</tex> is called a <strong>lower bound</strong> of <tex>S</tex>.
</p>
    <p><strong>Supremum (least upper bound)</strong></p>
    <p>
    An element <tex>x \in  P</tex> is a supremum of <tex>S</tex>,
    if for all upper bounds <tex>z  \in  P</tex> of <tex>S</tex>, <tex>x  \leq  z</tex>.
    Denoted as <tex>x =  \sup  S</tex>.
    </p>
    <p><strong>Infimum (greatest lower bound)</strong></p>
    <p>
    An element <tex>x \in  P</tex> is a infimum of <tex>S</tex>,
    if for all lower bounds <tex>z  \in  P</tex> of <tex>S</tex>, <tex>z  \leq  x</tex>.
    Denoted as <tex>x =  \inf  S</tex>.
    </p>
</mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1006</anchor>  <taxon>Definition</taxon> <addr>def-002G</addr>  <route>def-002G.xml</route>   <title>Function</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets then a <strong>function</strong> <tex>f:X  \to  Y</tex>
    is a mapping that sends each element of <tex>X</tex> to a unique element of <tex>Y</tex>,
    denoted by <tex>f(x) = y</tex>.
    Function is a special case of <link href="def-000W.xml" type="local" addr="def-000W" title="Relation">relation</link>, and it is a relation that is left-total and right-unique.
    <tex display="block">
        f  \in  X  \times  Y  \text { and }  \forall  x  \in  X,  \exists ! y  \in  Y, (x,y)  \in  f
    </tex>
    <tex>X</tex> is said to be the <strong>domain</strong> of <tex>f</tex> and <tex>Y</tex> is said to be the <strong>codomain</strong> of <tex>f</tex>,
    where we denote <tex>X =  \text {dom }  f</tex> and <tex>Y =  \text {cod }  f</tex>.
</p><p>
    Two functions <tex>f:X \to  Y</tex> and <tex>g:Y \to  Z</tex> can be <strong>composed</strong> to form a new function <tex>g  \circ  f : X  \to  Z</tex>,
    where the composition is defined by
    <tex display="block">
        (g  \circ  f)(x) = g(f(x)) 
    </tex></p><p>
    The set of all functions from <tex>X</tex> to <tex>Y</tex> is denoted by <tex>\hom _ \text {set} (X, Y)</tex>.
</p></mainmatter> </tree><p>
    The isomorphism function is defined as follows
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1007</anchor>  <taxon>Definition</taxon> <addr>def-002H</addr>  <route>def-002H.xml</route>   <title>Set Isomorphism</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets and <tex>f: X  \to  Y</tex> be a function.
    The function <tex>f</tex> is called an <strong>isomorphism</strong> if it is both <link href="def-002D.xml" type="local" addr="def-002D" title="Injective">injective</link> and <link href="def-002F.xml" type="local" addr="def-002F" title="Surjective">surjective</link>.
    In other words, there exists a function <tex>g: Y  \to  X</tex> such that
    <tex display="block">
        g  \circ  f =  \text {id} _X  \text { and } f  \circ  g =  \text {id} _Y
    </tex>
    where <tex>\text {id} _X</tex> and <tex>\text {id} _Y</tex> are the <strong>identity functions</strong> on <tex>X</tex> and <tex>Y</tex> respectively.
    And we say <tex>f</tex> is <strong>invertible</strong> and <tex>g</tex> is the <strong>inverse</strong> of <tex>f</tex>.
    If there is a isomorphism between <tex>X</tex> and <tex>Y</tex>, we say <tex>X</tex> and <tex>Y</tex> are <strong>isomorphic</strong>,
    denoted by <tex>X  \cong  Y</tex>.
    Isomorphism is an <link href="def-000X.xml" type="local" addr="def-000X" title="Equivalence Relation">equivalence relation</link>.
</p></mainmatter> </tree><p>
    With isomorphism, we can define the cardinality of a set.
    Two isomorphic sets have the same cardinality.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1008</anchor>  <taxon>Definition</taxon> <addr>def-002I</addr>  <route>def-002I.xml</route>   <title>Cardinality</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> be a set and <tex>n  \in   \mathbb {N}</tex>. 
    <tex>A</tex> si said to have <strong>cardinality</strong> <tex>n</tex>, denoted by <tex> |A|= n</tex>,
    if there exists an isomorphism between <tex>A</tex> and <tex>S_n =  \{   1,2, \cdots ,n   \}</tex>.
    If <tex>A</tex> has finite cardinality, we say <tex>A</tex> is <strong>finite</strong>, otherwise
    we say <tex>A</tex> is <strong>infinite</strong>, denoted by <tex>|A|  \geq   \infty</tex>.
</p></mainmatter> </tree><p>
    The next topic is the product of sets
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1009</anchor>  <taxon>Definition</taxon> <addr>def-002J</addr>  <route>def-002J.xml</route>   <title>Product of Sets</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets, then the <strong>Cartesian product</strong> of <tex>X</tex> and <tex>Y</tex> is the set
    <tex display="block">
        X  \times  Y =  \set {(x,y)  \mid  x  \in  X  \text { and } y  \in  Y}
    </tex>
    There are two natural projections from the Cartesian product to the original sets, namely
    <tex display="block">
         \pi _1 : X  \times  Y  \to  X  \text { and }  \pi _2 : X  \times  Y  \to  Y
    </tex></p></mainmatter> </tree><p>
    This leads to an improtant concept named <strong>universal property</strong>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1010</anchor>  <taxon>Lemma</taxon> <addr>thm-000J</addr>  <route>thm-000J.xml</route>   <title>Universal Property for Product of Sets</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets.
    For any set <tex>A</tex> and function
    <tex>f: A  \to  X</tex> and <tex>g: A  \to  Y</tex>,
    there exists a <em>unique</em> function <tex>h: A  \to  X  \times  Y</tex> such that
    the following diagram commutes:
    
    <center><embedded-tex hash="4157eb89f51117c585cb94d00d036a56"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \begin {tikzcd}
            &amp; {X \times  Y}  \\ 
            X &amp;&amp; Y  \\ 
            &amp; A
             \arrow [&quot;{ \pi _1}&quot;', from=1-2, to=2-1]
             \arrow [&quot;{ \pi _2}&quot;, from=1-2, to=2-3]
             \arrow [&quot;f&quot;, from=3-2, to=2-1]
             \arrow [&quot;g&quot;', from=3-2, to=2-3]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}
     
    </embedded-tex-body></embedded-tex></center>

    We might denote the unique function by <tex>\langle  f,g  \rangle : A  \to  X  \times  Y</tex>.
    It is sufficient to define <tex>\langle  f,g  \rangle (a) = (f(a),g(a))</tex> for all <tex>a \in  A</tex> as the unique function.
</p></mainmatter> </tree><p>
    Dual to the product of sets, we have the coproduct of sets
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1011</anchor>  <taxon>Definition</taxon> <addr>def-002K</addr>  <route>def-002K.xml</route>   <title>Coproduct of Sets</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets, then the <strong>coproduct</strong> of <tex>X</tex> and <tex>Y</tex> is 
    defined as the <strong>disjoint union</strong> of <tex>X</tex> and <tex>Y</tex>, denoted by <tex>X  \sqcup  Y</tex>.
    There are two natural injections from the original sets to the coproduct, namely
    <tex display="block">
        i_1 : X  \to  X  \sqcup  Y  \text { and } i_2 : Y  \to  X  \sqcup  Y
    </tex></p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1012</anchor>  <taxon>Lemma</taxon> <addr>thm-000K</addr>  <route>thm-000K.xml</route>   <title>Universal Property for Coproduct of Sets</title> </frontmatter> <mainmatter><p>
    Let <tex>X</tex> and <tex>Y</tex> be sets. For any set <tex>A</tex> and function
    <tex>f : X  \to  A</tex> and <tex>g : Y  \to  A</tex>, there exists a <em>unique</em> function
    <tex>h : X  \sqcup  Y  \to  A</tex> such that the following diagram commutes:
    
    <center><embedded-tex hash="31473672edfba5d6215d76dd08a01a24"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \begin {tikzcd}
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; {X \sqcup  Y}
             \arrow [&quot;{i_1}&quot;', from=2-1, to=3-2]
             \arrow [&quot;{i_2}&quot;, from=2-3, to=3-2]
             \arrow [&quot;f&quot;, from=2-1, to=1-2]
             \arrow [&quot;g&quot;', from=2-3, to=1-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
         \end {tikzcd}   
     
    </embedded-tex-body></embedded-tex></center>

    We might denote the unique as <tex>f \sqcup  g: X  \sqcup  Y  \to  A</tex>.
</p></mainmatter> </tree><p>
    In this section we discuss the <em>limits</em> of variously-shaped diagrams of sets.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1013</anchor>  <taxon>Definition</taxon> <addr>def-002L</addr>  <route>def-002L.xml</route>   <title>Pullback of Sets</title> </frontmatter> <mainmatter><p>
    Suppose we have sets <tex>X</tex>, <tex>Y</tex>, and <tex>Z</tex> and functions
    <tex>f : X  \to  Z</tex> and <tex>g : Y  \to  Z</tex>.
    
    <center><embedded-tex hash="aea0109fc5888410344cbfd1c2bfad2d"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;', from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </embedded-tex-body></embedded-tex></center>

    Its <strong>fiber product</strong> is the set
    <tex display="block">
        X  \times _Z Y =  \{   (x,w,y)  \mid  f(x) = w = g(y)   \} 
    </tex>
    There are obvious projections 
    <tex>
         \pi _1 : X  \times _Z Y  \to  X  \text { and }  \pi _2 : X  \times _Z Y  \to  Y
    </tex>
    such that the following diagram commutes (<tex>W = X  \times _Z Y</tex>):
    
    <center><embedded-tex hash="9194755931a1b27a68b010256252d579"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \begin {tikzcd}
            W &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;f&quot;', from=2-1, to=2-2]
             \arrow [&quot;g&quot;, from=1-2, to=2-2]
             \arrow [&quot;{ \pi _2}&quot;, from=1-1, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;', from=1-1, to=2-1]
             \arrow [&quot; \lrcorner &quot;{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
         \end {tikzcd}
     
    </embedded-tex-body></embedded-tex></center>

    The <strong>pullback</strong> is defined to be any set <tex>W  \cong  X \times _Z Y</tex>
    The corner symbol indicates <tex>W</tex> is a <em>pullback</em></p></mainmatter> </tree><p>
    The pullback also satisfies the universal property.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1014</anchor>  <taxon>Lemma</taxon> <addr>thm-000L</addr>  <route>thm-000L.xml</route>   <title>Universal Property for Pullback</title> </frontmatter> <mainmatter><p>
    Suppose the given diagram:
    
    <center><embedded-tex hash="5e6f2da5af96f3d2b5aa340ada59f646"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \begin {tikzcd}
            &amp; Y  \\ 
            X &amp; Z
             \arrow [&quot;t&quot;', from=2-1, to=2-2]
             \arrow [&quot;u&quot;, from=1-2, to=2-2]
         \end {tikzcd}
     
    </embedded-tex-body></embedded-tex></center>

    For any set <tex>A</tex> and commutative solid arrow diagram as below
    (functions <tex>f:A \to  X</tex> and <tex>g:A \to  Y</tex> such that <tex>t \circ  f = u \circ  g</tex>):
    
    <center><embedded-tex hash="2d3ff6bcdbabe8193a5f90642c805f62"><embedded-tex-preamble>
       \usepackage {tikz-cd}
       \usepackage {amssymb}
    </embedded-tex-preamble> <embedded-tex-body>
         
         \usetikzlibrary {arrows}
         \begin {tikzcd}
            &amp; {X \times _ZY}  \\ 
             \\ 
            &amp; A  \\ 
            X &amp;&amp; Y  \\ 
            &amp; Z
             \arrow [&quot;f&quot;', from=3-2, to=4-1]
             \arrow [&quot;g&quot;, from=3-2, to=4-3]
             \arrow [&quot;t&quot;', from=4-1, to=5-2]
             \arrow [&quot;u&quot;, from=4-3, to=5-2]
             \arrow [&quot;{ \exists !}&quot;, dashed, from=3-2, to=1-2]
             \arrow [&quot;{ \pi _1}&quot;', bend right, from=1-2, to=4-1]
	         \arrow [&quot;{ \pi _2}&quot;, bend left, from=1-2, to=4-3]
         \end {tikzcd}
     
    </embedded-tex-body></embedded-tex></center>

    there exists a <em>unique</em> arrow <tex>\langle  f,g  \rangle _Z: A \to  X \times _Z Y</tex> such that
    <tex display="block">
         \pi _1 \circ \langle  f,g  \rangle _Z = f  \text { and }  \pi _2 \circ \langle  f,g  \rangle _Z = g
    </tex></p></mainmatter> </tree></mainmatter> </tree><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1015</anchor>  <taxon>Math Analysis</taxon> <addr>math-0004</addr>  <route>math-0004.xml</route> <date><year>2024</year> <month>1</month> <day>27</day></date>  <title>The Construction of <tex>\mathbb {R}</tex></title> </frontmatter> <mainmatter><p>
    We start constructing <tex>\mathbb {R}</tex> from <tex>\mathbb {Q}</tex> by a way that it satisfies the existence theorem,
    the core of construction.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1016</anchor>  <taxon>Theorem</taxon> <addr>thm-0003</addr>  <route>thm-0003.xml</route>   <title>Existence theorem</title> </frontmatter> <mainmatter><p>
    There exists an ordered field <tex>\mathbb {R}</tex> that satisfies the <link href="def-0012.xml" type="local" addr="def-0012" title="Least upper bound property">least upper bound property</link>.
    Moreover <tex>\mathbb {R}</tex> contains <tex>\mathbb {Q}</tex> as a subfield.
</p></mainmatter> </tree><p>
    The least-upper-bound property mentioned above is defined:
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1017</anchor>  <taxon>Definition</taxon> <addr>def-0012</addr>  <route>def-0012.xml</route>   <title>Least upper bound property</title> </frontmatter> <mainmatter><p>
    A set <tex>S</tex> has the least upper bound property if every non-empty subset <tex>T</tex> of <tex>S</tex> that is bounded above has a least upper bound <tex>\sup  T</tex>.
</p></mainmatter> </tree><p>
    Why do we need the least-upper-bound property?
    Consider the set <tex>S =  \{ x  \in   \mathbb {Q} | x^2 &lt; 2 \}</tex>.
    <tex>S</tex> is bounded above by <tex>2</tex>, but it does not have a least upper bound in <tex>\mathbb {Q}</tex>.
    Therefore we can't express <tex>\sqrt {2}</tex> in field <tex>\mathbb {Q}</tex> since some &quot;gaps&quot; exist.
    This fact motivates us to construct a more complete field <tex>\mathbb {R}</tex>.
    We have constructed <tex>\mathbb {Q}</tex> from <tex>\mathbb {Z}</tex>, and now we construct <tex>\mathbb {R}</tex> from <tex>\mathbb {Q}</tex>.
</p><p>
    Then we should find a way to express &quot;<tex>\sqrt {2}</tex>&quot; using <tex>\mathbb {Q}</tex>.
    A crucial idea is <strong>approximating</strong> <tex>\sqrt {2}</tex> by a sequence of rational numbers.
    <tex display="block">
         \sqrt {2} :=  \{  p^2&lt;2  \lor  p&lt;0, p \in \mathbb {Q}  \} 
    </tex>
    We can cut the number axis into two pieces by <tex>\sqrt {2}</tex>, such cut is called a <strong>Dedekind cut</strong>. 
    A cut should be well-defined rather than just an intuitive concept.
</p><p>
    As we use set theory to construct <tex>\mathbb {R}</tex>, it motivates us to define Dedekind cut as a set.
    It should satisfies some properties:
    <ul><li>Can't be empty or the whole <tex>\mathbb {Q}</tex></li>
        <li>Closed downward</li>
        <li>Contains not the largest number</li></ul>
    A formal definition is given below:
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1018</anchor>  <taxon>Definition</taxon> <addr>def-0013</addr>  <route>def-0013.xml</route>   <title>Dedekind cuts</title> </frontmatter> <mainmatter><p>
    A Dedekind cut is a partition of the rationals <tex>\mathbb {Q}</tex> into two non-empty sets <tex>L</tex> and <tex>R</tex> such that:
    <ul><li><tex>L \neq \emptyset</tex></li>
        <li><tex>R \neq \emptyset</tex></li>
        <li>if <tex>x,y \in \mathbb {Q}, x&lt;y</tex> and <tex>y \in  L</tex> then <tex>x \in  L</tex></li>
        <li>if <tex>p \in  L</tex> then exists <tex>q \in  L</tex> such that <tex>p&lt;q</tex></li></ul></p></mainmatter> </tree><p>
    Now we can defined the real number as a set of Dedekind cuts.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1019</anchor>  <taxon>Definition</taxon> <addr>def-0014</addr>  <route>def-0014.xml</route>   <title>Real Number System</title> </frontmatter> <mainmatter><p>
    The element of <tex>\mathbb {R}</tex> is a <link href="def-0013.xml" type="local" addr="def-0013" title="Dedekind cuts">Dedekind Cut</link> in <tex>\mathbb {Q}</tex>.
    <tex display="block">
         \mathbb {R} :=  \{  L | (L,R)  \text { is a Dedekind Cut}  \} 
    </tex></p></mainmatter> </tree><p>
    Now define the order relation on <tex>\mathbb {R}</tex>.
    We have defined <tex>\mathbb {R}</tex> as the set of Dedekind cuts, so we can define the strict partial order relation <tex>&lt;</tex> on <tex>\mathbb {R}</tex> by the set operation <tex>\subset</tex>.
    The irreflexive, asymmetric and transitive properties are trivial. 
</p></mainmatter> </tree><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1020</anchor>  <taxon>Linear Algebra</taxon> <addr>math-0001</addr>  <route>math-0001.xml</route> <date><year>2024</year> <month>1</month> <day>26</day></date>  <title>Introduction to Vector Space</title> </frontmatter> <mainmatter><p>
    This note introduces the concept of vector space.
    Refer to <link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015" title="Linear Algebra Done Right">Linear Algebra Done Right</link>.
</p><p>
    The motivation for the definition of a vector space comes from the properties
    of vectors in Euclidean space <tex>\mathbb {R}^n</tex> and <tex>\mathbb {C}^n</tex>.
    The definition abstracts and generalizes these properties.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1021</anchor>  <taxon>Definition</taxon> <addr>def-000H</addr>  <route>def-000H.xml</route>   <title>Vector Space</title> </frontmatter> <mainmatter><p>
    A vector space over a <link href="def-0006.xml" type="local" addr="def-0006" title="Field">field</link> <tex>F</tex> is a non-empty set <tex>V</tex> together with a binary operation and a binary function that satisfy the axioms listed below. 
    In this context, the elements of <tex>F</tex> are commonly called <strong>vectors</strong>, and the elements of <tex>F</tex> are called <strong>scalars</strong>.
    <ul><li>Commutativity: <tex>
             \forall  x, y  \in  V, x + y = y + x
        </tex></li>
        <li>Associativity: <tex>
             \forall  x, y, z  \in  V, (x + y) + z = x + (y + z)
        </tex></li>
        <li>Additive Identity: <tex>
             \exists  0  \in  V  \text { such that }  \forall  x  \in  V, x + 0 = x
        </tex></li>
        <li>Multiplicative Identity: <tex>
             \forall  x  \in  V, 1x = x
        </tex></li>
        <li>Additive Inverse: <tex>
             \forall  x  \in  V,  \exists  y  \in  V  \text { such that } x + y = 0
        </tex></li>
        <li>Distributivity: <tex>
             \forall  x, y  \in  V,  \forall  c, d  \in  F, c(x + y) = cx + cy, (c + d)x = cx + dx
        </tex></li></ul></p><p>
    Elements of a vector space are called <strong>vectors</strong> or <strong>points</strong>.
</p></mainmatter> </tree><p>
    When dealing with vector spaces, we usually interested only in subspaces.
    And the union of subspaces is rarely a subspace, thus
    we are more interested with sums of subspaces.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1022</anchor>  <taxon>Definition</taxon> <addr>def-000I</addr>  <route>def-000I.xml</route>   <title>Linear Subspace</title> </frontmatter> <mainmatter><p>
    A subset <tex>U</tex> of a vector space <tex>V</tex> over a field <tex>F</tex> is called a <strong>subspace</strong> of <tex>V</tex> if <tex>U</tex> is itself a <strong>vector space</strong> over <tex>F</tex> with the operations of addition and scalar multiplication on <tex>V</tex>.
    The subset also satisfies the following axioms (vice versa):
    <ul><li>Additive identity: <tex>0 \in  U</tex></li>
        <li>Closure: <tex>\forall  u,v \in  U, u+v \in  U</tex></li>
        <li>Closed Scalar multiplication: <tex>\forall  u \in  U,  \forall  c \in  F, cu \in  U</tex></li></ul></p></mainmatter> </tree><p>
    After that we can define the sum of subsets.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1023</anchor>  <taxon>Definition</taxon> <addr>def-000J</addr>  <route>def-000J.xml</route>   <title>Sum of subsets</title> </frontmatter> <mainmatter><p>
    Let <tex>U_1,  \dots , U_n</tex> be subsets of a vector space <tex>V</tex>.
    The <strong>sum</strong> of <tex>U_1,  \dots , U_n</tex> is defined as
    <tex display="block">U_1 +  \dots  + U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \}</tex>.
</p></mainmatter> </tree><p>
    The sum of subspaces is the smallest subspace that contains all the subspaces.
</p><p>
    Every element in <tex>U_1 +  \dots  + U_n</tex> can be written as a sum of elements <tex>u_i</tex> in <tex>U_i</tex>:
    <tex display="block">
        u_1+ \cdots +u_n
    </tex>
    We will interested in cases where each vector in <tex>U_1 +  \dots  + U_n</tex> can be represented in the form above
    in only one way. This leads to the definition of direct sum.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1024</anchor>  <taxon>Definition</taxon> <addr>def-000K</addr>  <route>def-000K.xml</route>   <title>Direct Sum</title> </frontmatter> <mainmatter><p>
    Let <tex>U_1,  \dots , U_n</tex> be subspaces of a vector space <tex>V</tex>.
    The <strong>direct sum</strong> of <tex>U_1,  \dots , U_n</tex> is defined as
    <tex display="block">
        U_1  \oplus   \dots   \oplus  U_n =  \{ u_1 +  \dots  + u_n  \mid  u_i  \in  U_i \} 
    </tex>
    if every element in <tex>U_1  \oplus   \dots   \oplus  U_n</tex> can be written as <tex>u_1 +  \dots  + u_n </tex> in only one way.
    This definition requires every vector in the sum have a unique representation.
</p></mainmatter> </tree></mainmatter> </tree><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1025</anchor>  <taxon>Linear Algebra</taxon> <addr>math-0002</addr>  <route>math-0002.xml</route> <date><year>2024</year> <month>1</month> <day>26</day></date>  <title>Finite Dimensional Vector Space</title> </frontmatter> <mainmatter><p>
    This note introduces the concept of finite-dimensional vector space.
    Refer to <link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015" title="Linear Algebra Done Right">Linear Algebra Done Right</link>.
</p><p>
    Adding up scalar mulitples of vectors in a list gives a linear combination.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1026</anchor>  <taxon>Definition</taxon> <addr>def-000L</addr>  <route>def-000L.xml</route>   <title>Linear Combination</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a <link href="def-000H.xml" type="local" addr="def-000H" title="Vector Space">vector space</link> over a field <tex>F</tex>.
    Let <tex>v_1,  \dots , v_n</tex> be vectors in <tex>V</tex>.
    A <strong>linear combination</strong> of <tex>v_1,  \dots , v_n</tex> is an expression of the form
    <tex display="block">
        a_1 v_1 +  \dots  + a_n v_n
    </tex>
    where <tex>a_1,  \dots , a_n  \in  F</tex>.
</p></mainmatter> </tree><p>
    To talk about a structure, we usually define a collection of this structure.
    Hence we have span for linear combinations.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1027</anchor>  <taxon>Definition</taxon> <addr>def-000M</addr>  <route>def-000M.xml</route>   <title>Linear Span</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a vector space over a field <tex>F</tex>.
    Let <tex>v_1,  \dots , v_n</tex> be vectors in <tex>V</tex>.
    The <strong>span</strong> of <tex>v_1,  \dots , v_n</tex> is defined as
    <tex display="block">
         \text {span} (v_1,  \dots , v_n) =  \{ a_1 v_1 +  \dots  + a_n v_n  \mid  a_i  \in  F \} 
    </tex>
    The span of empty set is defined to be <tex>\{ 0 \}</tex>.    
</p><p>
    If <tex>\text {span} (v_1,  \dots , v_n) = V</tex>, we say that <tex>v_1,  \dots , v_n</tex> <strong>spans</strong> <tex>V</tex>.
</p></mainmatter> </tree><p>
    Suppose we have span <tex>S= \text {span} (v_1,  \dots , v_n)</tex>. (Span is trivially a subspace.)
    Obviously for all <tex>v_j (1  \leq  j  \leq  n)</tex>, <tex>v_j  \in  S</tex>.
    Because subspaces are closed under scalar multiplication and addition, every
    subspace of <tex>V</tex> containing <tex>v_1,  \dots , v_n</tex> must contain <tex>S</tex>.
    Thus we conclude that <tex>S</tex> is the smallest subspace containing <tex>v_1,  \dots , v_n</tex>.
</p><p>
    The discussion about <strong>spans</strong> leads to a key definition in linear algebra.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1028</anchor>  <taxon>Definition</taxon> <addr>def-000N</addr>  <route>def-000N.xml</route>   <title>Finite-Dimensional Vector Space</title> </frontmatter> <mainmatter><p>
    A <link href="def-000H.xml" type="local" addr="def-000H" title="Vector Space">vector space</link> <tex>V</tex> is called <strong>finite-dimensional</strong> if some <link href="def-000G.xml" type="local" addr="def-000G" title="List">list</link> of vectors <tex>v_1,  \dots , v_n</tex> <link href="def-000M.xml" type="local" addr="def-000M" title="Linear Span">spans</link> <tex>V</tex>.
</p></mainmatter> </tree><p>
    The opposite of finite-dimensional is infinite-dimensional.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1029</anchor>  <taxon>Definition</taxon> <addr>def-000O</addr>  <route>def-000O.xml</route>   <title>Infinite-dimensional vector space</title> </frontmatter> <mainmatter><p>
    A vector space <tex>V</tex> is called <strong>infinite-dimensional</strong> if it is not <link href="def-000N.xml" type="local" addr="def-000N" title="Finite-Dimensional Vector Space">finite-dimensional</link>.
</p></mainmatter> </tree><p>
    Consider the situation that there is only one way to
    express a vector <tex>v</tex> as a linear combination of vectors in a list <tex>v_1,  \dots , v_n</tex>.
    What property of the list <tex>v_1,  \dots , v_n</tex> does this situation imply? The answer is
    linear independence.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1030</anchor>  <taxon>Definition</taxon> <addr>def-000P</addr>  <route>def-000P.xml</route>   <title>Linearly independent</title> </frontmatter> <mainmatter><p>
    A set of vectors <tex>\{ v_1,  \dots , v_n \}</tex> is called <strong>linearly independent</strong> if
    <tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</tex>
    implies that <tex>a_1 =  \dots  = a_n = 0</tex>.
    The trivial case of <tex>\{ 0 \}</tex> is also considered linearly independent.
</p></mainmatter> </tree><p>
    If some vectors are not linearly independent, then there are more than one way to
    express a vector as a linear combination of vectors in the list. This leads to 
    the following definition.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1031</anchor>  <taxon>Definition</taxon> <addr>def-000Q</addr>  <route>def-000Q.xml</route>   <title>Linearly dependent</title> </frontmatter> <mainmatter><p>
    A set of vectors <tex>\{ v_1,  \dots , v_n \}</tex> is called <strong>linearly dependent</strong> if
    <tex display="block">a_1 v_1 +  \dots  + a_n v_n = 0</tex>
    for some <tex>a_1,  \dots , a_n  \in   \mathbb {F}</tex> with at least one <tex>a_i  \neq  0</tex> (not all <tex>0</tex>).
</p></mainmatter> </tree><p>
    The following lemma is a direct consequence of the definition of linear independence.
    It states that for a given linearly dependent list, we can always remove a vector
    without changing the span.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1032</anchor>  <taxon>Lemma</taxon> <addr>thm-0001</addr>  <route>thm-0001.xml</route>   <title>Linear Dependence Lemma</title> </frontmatter> <mainmatter><p>
    Let <tex>v_1,  \dots , v_n</tex> be vectors in a vector space <tex>V</tex> over a field <tex>\mathbb {F}</tex>.
    If <tex>v_1,  \dots , v_n</tex> are linearly dependent, then there exists <tex>1  \leq  i  \leq  n</tex> such that
    <ul><li><tex>v_i  \in   \text {span} (v_1,  \dots , v_{i-1})</tex></li>
        <li>Remove <tex>v_i</tex> from the list <tex>v_1,  \dots , v_n</tex> and the span does not change</li></ul></p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1033</anchor>  <taxon>Lemma</taxon> <addr>thm-0002</addr>  <route>thm-0002.xml</route>   <title>Length of linearly independent list <tex>\leq</tex> length of spanning list</title> </frontmatter> <mainmatter><p>
    In a finite dimensional vector space, the length of a linearly independent list is less than or equal to the length of a spanning list.
</p></mainmatter> </tree><p>
    We have discussed linear independent lists and spanning lists.
    Now we are ready to define a basis.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1034</anchor>  <taxon>Definition</taxon> <addr>def-000R</addr>  <route>def-000R.xml</route>   <title>Basis</title> </frontmatter> <mainmatter><p>
    A basis of <tex>V</tex> is a list of vectors in <tex>V</tex>
    that is linearly independent and spans <tex>V</tex>. 
</p><p><strong>Criterion for basis</strong>
    A list of vectors <tex>\{ v_1,  \dots , v_n \}</tex> is a basis of <tex>V</tex> if and only if
    every <tex>v  \in  V</tex> can be written <strong>uniquely</strong> as a linear combination of <tex>v_1,  \dots , v_n</tex>.
</p></mainmatter> </tree><p>
    For instance, we have standard basis <tex>\{ e_1,  \dots , e_n \}</tex> for <tex>\mathbb {F}^n</tex>,
    where <tex>e_i</tex> is the vector with <tex>1</tex> at <tex>i</tex>-th position and <tex>0</tex> elsewhere.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1035</anchor>  <taxon>Theorem</taxon> <addr>thm-0005</addr>  <route>thm-0005.xml</route>   <title>Spanning List contains a basis</title> </frontmatter> <mainmatter><p>
    Every spanning list in a vector space can be reduced to a basis.
</p></mainmatter> </tree><p>
    From the <link href="thm-0005.xml" type="local" addr="thm-0005" title="Spanning List contains a basis">theorem</link> we can infer a corollary.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1036</anchor>  <taxon>Corollary</taxon> <addr>thm-0006</addr>  <route>thm-0006.xml</route>   <title>Basis of finite-dimensional vector space</title> </frontmatter> <mainmatter><p>
    Every finite-dimensional vector space has a basis.
</p></mainmatter> </tree><p>
    The next result states for a spanning list can be reduced to a basis.
    We can adjoin one or more vectors to a linearly independent list to form a basis.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1037</anchor>  <taxon>Theorem</taxon> <addr>thm-0007</addr>  <route>thm-0007.xml</route>   <title>Linearly dependent list extends to a basis</title> </frontmatter> <mainmatter><p>
    Every linearly independent list of vectors in  a finite-dimensional vector space can be extended to a basis.
</p></mainmatter> </tree><p>
    Remind the definition of <link href="der-000K" type="external">direct sum</link>, we can now show that
    every subspace of a finite-dimensional vecrtor space can be paired
    with another subspace to form a direct sum of the whole space.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1038</anchor>  <taxon>Theorem</taxon> <addr>thm-0008</addr>  <route>thm-0008.xml</route>   <title>Direct Sum of Subspaces of <tex>V</tex></title> </frontmatter> <mainmatter><p>
    Suppose <tex>V</tex> is a finite dimensional vector space,
    and <tex>U</tex> is a subspace of <tex>V</tex>.
    Then there exists a subspace <tex>W</tex> of <tex>V</tex> such that
    <tex>V = U  \oplus  W</tex>.
</p></mainmatter> </tree><p>
    This post discusses about <em>finite-dimensional vector space</em>.
    But we have not yet defined what is dimension.
    We tempted to define the dimension as the length of basis intuitively.
    With this definition we should prove its well-definedness.
    That is, every basis has the same length.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1039</anchor>  <taxon>Theorem</taxon> <addr>thm-0009</addr>  <route>thm-0009.xml</route>   <title>Basis length is invariant</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a finite-dimensional vector space.
    Then every basis of <tex>V</tex> has the same length.
</p></mainmatter> </tree><p>
    This can be proved by <link href="thm-0002.xml" type="local" addr="thm-0002" title="Length of linearly independent list  length of spanning list">Lemma 8</link>.
    Now we can formally define the dimension of such spaces.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1040</anchor>  <taxon>Definition</taxon> <addr>def-001V</addr>  <route>def-001V.xml</route>   <title>Dimension</title> </frontmatter> <mainmatter><p>
    The <strong>dimension</strong> of a finite-dimensional vector space <tex>V</tex> is the length of any basis of the vector space.
    Denoted by <tex>\dim  V</tex>.
</p></mainmatter> </tree><p>
    Every subspace of a finite-dimensional vector space is also finite-dimensional.
    Hence we can talk about the dimension of a subspace.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1041</anchor>  <taxon>Theorem</taxon> <addr>thm-000A</addr>  <route>thm-000A.xml</route>   <title>Dimension of a subspace</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a finite-dimensional vector space,
    and <tex>U</tex> be a subspace of <tex>V</tex>.
    Then <tex>\dim  U  \leq   \dim  V</tex>.
</p></mainmatter> </tree><p>
    According to the definition of <link href="def-000P.xml" type="local" addr="def-000P" title="Linearly independent">linearly independent</link>,
    to show a list of vectors is a basis, we only need to show it is linearly independent,
    and it spans the whole space.
    The next theorems simplifies the task:
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1042</anchor>  <taxon>Theorem</taxon> <addr>thm-000B</addr>  <route>thm-000B.xml</route>   <title>Linearly independent list of the right length is a basis</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a finite-dimensional vector space.
    Then every <link href="def-000P.xml" type="local" addr="def-000P" title="Linearly independent">linearly independent</link> list of vectors in <tex>V</tex> with length equal to <tex>\dim  V</tex> is a basis of <tex>V</tex>.
</p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1043</anchor>  <taxon>Theorem</taxon> <addr>thm-000C</addr>  <route>thm-000C.xml</route>   <title>Spanning list of the right length is a basis</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a finite-dimensional vector space.
    Then every <link href="def-000M.xml" type="local" addr="def-000M" title="Linear Span">spanning</link> list of vectors in <tex>V</tex> with length equal to <tex>\dim  V</tex> is a basis of <tex>V</tex>.
</p></mainmatter> </tree><p>
    Now we move to the discussion of the dimension of the sum of two subspaces.
    This is analogous to the <link href="thm-000E.xml" type="local" addr="thm-000E" title="Inclusion-Exclusion Principle">inclusion-exclusion principle</link>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1044</anchor>  <taxon>Theorem</taxon> <addr>thm-000D</addr>  <route>thm-000D.xml</route>   <title>Dimension of a sum</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be a finite-dimensional vector space,
    and <tex>U</tex> and <tex>W</tex> be subspaces of <tex>V</tex>.
    Then
    <tex display="block">
         \dim (U + W) =  \dim  U +  \dim  W -  \dim (U  \cap  W).
    </tex></p></mainmatter> </tree></mainmatter> </tree><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1045</anchor>  <taxon>Linear Algebra</taxon> <addr>math-0005</addr>  <route>math-0005.xml</route> <date><year>2024</year> <month>1</month> <day>31</day></date>  <title>Linear Maps</title> </frontmatter> <mainmatter><p>
    This note introduces the concept of linear maps.
    Refer to <link href="linear-algebra-2015.xml" type="local" addr="linear-algebra-2015" title="Linear Algebra Done Right">Linear Algebra Done Right</link>.
</p><p>
    Now we arrive at the main topic of this chapter: linear maps. 
    In classic mathematics, to understand the properties of the structure or space,
    we often study the maps between them.
    For vector spaces we study the <strong>linear maps</strong>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1046</anchor>  <taxon>Definition</taxon> <addr>def-0025</addr>  <route>def-0025.xml</route>   <title>Linear Map</title> </frontmatter> <mainmatter><p>
    A <strong>linear map</strong> is a function between two vector spaces that preserves the operations of addition and scalar multiplication.
    In other words, a function <tex>T: V  \to  W</tex> where <tex>V,W</tex> are vector spaces if the following conditions are satisfied:
    <ul><li>Additivity: <tex>T(u+v) = T(u) + T(v)</tex> for all <tex>u,v  \in  V</tex></li>
        <li>Homogeneity: <tex>T( \alpha  v) =  \alpha  T(v)</tex> for all <tex>\alpha   \in   \mathbb {F}</tex> and <tex>v  \in  V</tex></li></ul>
    Sometimes we ignore the brackets and write <tex>T v</tex> instead of <tex>T(v)</tex>.
</p></mainmatter> </tree><p>
    Now we can talk about the set of all linear maps between two vector spaces.
    <tex display="block">
         \mathcal {L} (V,W) =  \{    T: V  \to  W | T  \text { is a linear map}   \} 
    </tex></p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1047</anchor>  <taxon>Example</taxon> <addr>eg-0002</addr>  <route>eg-0002.xml</route>   <title>Differentiation is linear map</title> </frontmatter> <mainmatter><p>
    Define <tex>D \in \mathcal {L} ( \mathcal {P}( \mathbb {R} ), \mathcal {P}( \mathbb {R} ))</tex> (recall that <tex>\mathcal {P}</tex> means <link href="def-0027.xml" type="local" addr="def-0027" title="Polynomial">set of polynomials</link>) by
    <tex display="block">
        D(f) = f'
    </tex>
    We can see that <tex>D</tex> a linear map.
    <ul><li>Additivity: <tex>D(f+g) = (f+g)' = f' + g' = D(f) + D(g)</tex></li>
        <li>Homogeneity: <tex>D( \alpha  f) = ( \alpha  f)' =  \alpha  f' =  \alpha  D(f)</tex></li></ul></p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1048</anchor>  <taxon>Definition</taxon> <addr>eg-0003</addr>  <route>eg-0003.xml</route>   <title>Integration is linear map</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be the vector space of all continuous functions on the interval <tex>[a,b]</tex>.
    The map <tex>I: V  \to  V</tex> defined by
    <tex display="block">
        I(f) =  \int _a^x f(t) dt
    </tex>
    is a <strong>linear map</strong>.
    In other words, <tex>I</tex> preserves the operations of addition and scalar multiplication:
    For all <tex>f,g  \in  V</tex> and all <tex>\alpha   \in   \mathbb {R}</tex>,
    <tex display="block">
        I(f+g) = I(f) + I(g)  \quad   \text {and}  \quad  I( \alpha  f) =  \alpha  I(f)
    </tex></p></mainmatter> </tree><p>
    We can find a linear map that takes on <em>whatever values we wish</em> on the 
    vectors in a basis by the following theorem.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1049</anchor>  <taxon>Theorem</taxon> <addr>thm-000F</addr>  <route>thm-000F.xml</route>   <title>Linear maps and basis of domain</title> </frontmatter> <mainmatter><p>
    Let <tex>v_1, v_2,  \ldots , v_n</tex> be a basis of vector space <tex>V</tex>.
    Then for any vector space <tex>W</tex> and any vectors <tex>w_1, w_2,  \ldots , w_n</tex> in <tex>W</tex>,
    there exists a unique linear map <tex>T: V  \to  W</tex> such that
    <tex display="block">
        T(v_i) = w_i  \quad   \text {for all}  \quad  i = 1,2, \ldots ,n
    </tex></p></mainmatter> </tree><p>
    Now let's turn to the algebraic operations over the set of linear maps <tex>\mathcal {L} (V,W)</tex>.
    We begin by defining the addition and scalar multiplication of linear maps.
    This leads to a surprising result: the set of linear maps is actually a vector space.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1050</anchor>  <taxon>Definition</taxon> <addr>def-0029</addr>  <route>def-0029.xml</route>   <title>Addition and scalar multiplication over <tex>\mathcal {L} (V,W)</tex></title> </frontmatter> <mainmatter><p>
    Let <tex>T_1, T_2  \in   \mathcal {L} (V,W)</tex>.
    We define the <strong>addition</strong> of <tex>T_1</tex> and <tex>T_2</tex> as the linear map <tex>T_1 + T_2: V  \to  W</tex> such that
    <tex display="block">
        (T_1 + T_2)(v) = T_1(v) + T_2(v)  \quad   \text {for all}  \quad  v  \in  V
    </tex>
    The scalar multiplication of a linear map <tex>T  \in   \mathcal {L} (V,W)</tex> by a scalar <tex>c  \in   \mathbb {F}</tex> is the linear map <tex>cT: V  \to  W</tex> such that
    <tex display="block">
        (cT)(v) = cT(v)  \quad   \text {for all}  \quad  v  \in  V
    </tex>
    With these operations, <tex>\mathcal {L} (V,W)</tex> is a <link href="def-000H.xml" type="local" addr="def-000H" title="Vector Space"><strong>vector space</strong></link> over the field <tex>\mathbb {F}</tex>.
    Note that the additive identity of <tex>\mathcal {L} (V,W)</tex> is the <strong>zero map</strong> <tex>0: V  \to  W</tex> such that
    <tex display="block">
        0(v) = 0  \quad   \text {for all}  \quad  v  \in  V
    </tex></p></mainmatter> </tree><p>
    Usually it makes no sense to multiply two linear maps. But we can define
    an operation called the <strong>product</strong> of linear maps, which is just the composition of the two functions.
    This can form a <strong>monoid</strong> or even a <strong>group</strong> under certain conditions.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1051</anchor>  <taxon>Definition</taxon> <addr>def-002A</addr>  <route>def-002A.xml</route>   <title>Product of Linear Maps</title> </frontmatter> <mainmatter><p>
    Let <tex>T_1: V  \to  W</tex> and <tex>T_2: W  \to  U</tex> be linear maps.
    We define the <strong>product</strong> of <tex>T_1</tex> and <tex>T_2</tex> as the linear map <tex>T_2  \circ  T_1: V  \to  U</tex> such that
    <tex display="block">
        (T_2  \circ  T_1)(v) = T_2(T_1(v))  \quad   \text {for all}  \quad  v  \in  V
    </tex>
    Note that this is just the composition of the two functions <tex>T_1</tex> and <tex>T_2</tex>. 
    And we usually denote <tex>T_2  \circ  T_1</tex> by <tex>T_2T_1</tex>.
    The product of linear maps is associative, that is,
    <tex display="block">
        (T_3  \circ  T_2)  \circ  T_1 = T_3  \circ  (T_2  \circ  T_1)
    </tex>
    for any linear maps <tex>T_1: V  \to  W</tex>, <tex>T_2: W  \to  U</tex>, and <tex>T_3: U  \to  X</tex>.
    The identity map <tex>I_V: V  \to  V</tex> is the identity element of the set of linear maps <tex>\mathcal {L} (V,V)</tex> under the product operation.
    That is, for any linear map <tex>T: V  \to  V</tex>,
    <tex display="block">
        I_V  \circ  T = T  \circ  I_V = T
    </tex>
    where <tex>I_V</tex> is the identity map on <tex>V</tex>.
    The set of all linear maps from a vector space to itself, <tex>\mathcal {L} (V,V)</tex>, forms a <link href="def-0007.xml" type="local" addr="def-0007" title="Monoid"><strong>monoid</strong></link> under the product operation.
    The set of all invertible linear maps from a vector space to itself, <tex>\mathcal {L} (V,V)^*</tex>, forms a group under the product operation.
    The identity map is the identity element of the <link href="def-0001.xml" type="local" addr="def-0001" title="Group"><strong>group</strong></link> <tex>\mathcal {L} (V,V)^*</tex>.
</p><p>
    With addition we also have the distributive law for the product of linear maps.
    That is, for any linear maps <tex>S,S_1,S_2: V  \to  W</tex> and <tex>T,T_1,T_2: U \to  V</tex>:
    <tex display="block">
        (S_1 + S_2)T = S_1T + S_2T  \quad   \text {and}  \quad  T(S_1 + S_2) = TS_1 + TS_2
    </tex></p></mainmatter> </tree><p>
    In algebra, we have a structure named <strong>kernel</strong>, which is the set of all elements that are mapped to the zero element.
    For linear maps, the kernel is the <strong>null space</strong></p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1052</anchor>  <taxon>Definition</taxon> <addr>def-002C</addr>  <route>def-002C.xml</route>   <title>Null Space</title> </frontmatter> <mainmatter><p>
    For <tex>T: V  \to  W</tex>, the <strong>null space</strong> of <tex>T</tex> is the set of all vectors in <tex>V</tex> that are mapped to <tex>0</tex> in <tex>W</tex>.
    <tex display="block">
         \text {null }  T =  \{   v  \in  V | T(v) = 0   \} 
    </tex>
    The null space of <tex>T</tex> is a subspace of <tex>V</tex>.
</p></mainmatter> </tree><p>
    The injective linear map is defined like normal <link href="def-002D.xml" type="local" addr="def-002D" title="Injective">injective</link> functions.
    To check whether a linear map is injective, we can just check whether the null space is trivial.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1053</anchor>  <taxon>Theorem</taxon> <addr>thm-000G</addr>  <route>thm-000G.xml</route>   <title>Injectivity equivalent to Kernel Triviality</title> </frontmatter> <mainmatter><p>
    Let <tex>T: V  \to  W</tex> be a linear map. Then <tex>T</tex> is injective if and only if <tex>\text {null }  T =  \{   0   \}</tex>.
</p></mainmatter> </tree><p>
    The image of a linear map is the set of all elements that are mapped to by some element in the domain.
    This is called the <strong>range</strong> of the linear map, just like <link href="def-002E.xml" type="local" addr="def-002E" title="Range">range</link> of normal function.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1054</anchor>  <taxon>Theorem</taxon> <addr>thm-000H</addr>  <route>thm-000H.xml</route>   <title>Range is a subspace</title> </frontmatter> <mainmatter><p>
    If <tex>T: V  \to  W</tex> is a linear map, then the range of <tex>T</tex> is a subspace of <tex>W</tex>.
</p></mainmatter> </tree><p>
    The next theorem plays a crucial role in the study of linear maps.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1055</anchor>  <taxon>Theorem</taxon> <addr>thm-000I</addr>  <route>thm-000I.xml</route>   <title>Fundamental Theorems of Linear Maps</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> be finite-dimensional vector space and <tex>T : V  \to  W</tex> be a linear map. 
    Then <tex>\text {range }  T</tex> is finite-dimensional and 
    <tex display="block">
         \dim  V =  \dim   \text {range }  T +  \dim   \text {null }  T
    </tex></p></mainmatter> </tree><p>
    Now we can show that no linear map from a finite-dimensional vector space
    to a <em>smaller</em> (In dimension) vector space can be <link href="def-002D.xml" type="local" addr="def-002D" title="Injective">injective</link>.
    This can be easily proved by the fundamental theorem of linear maps.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1056</anchor>  <taxon>Lemma</taxon> <addr>thm-000M</addr>  <route>thm-000M.xml</route>   <title>Map to smaller dimension is not injective</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> and <tex>W</tex> be finite-dimensional vector spaces, 
    and <tex>\dim  V &gt;  \dim  W</tex>.
    Then no linear map <tex>T:V \to  W</tex> is injective.
</p></mainmatter> </tree><p>
    Similarly, we can show that no linear map from a finite-dimensional vector space
    to a <em>larger</em> (In dimension) vector space can be <link href="def-002F.xml" type="local" addr="def-002F" title="Surjective">surjective</link>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1057</anchor>  <taxon>Lemma</taxon> <addr>thm-000N</addr>  <route>thm-000N.xml</route>   <title>Map to bigger dimension is not surjective</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> and <tex>W</tex> be finite-dimensional vector spaces, 
    and <tex>\dim  V &lt;  \dim  W</tex>.
    Then no linear map <tex>T:V \to  W</tex> is surjective.
</p></mainmatter> </tree><p>
    These two lemmas are very important in the study of linear equations.
    The idea here is to express linear equations system in terms of linear maps.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1058</anchor>  <taxon>Example</taxon> <addr>eg-0004</addr>  <route>eg-0004.xml</route>   <title>Homogeneous Linear Equations System</title> </frontmatter> <mainmatter><block open="open"><headline>
    <strong>Reprase in terms of a linear map the question of whether a <link href="def-002Q.xml" type="local" addr="def-002Q" title="Homogeneous Linear Equations">homogeneous system linear equations</link> has a nonzero solution.</strong>
</headline> 
    Let <tex>A</tex> be the coefficient matrix of a homogeneous linear system.
    <tex display="block">
        A =  \begin {bmatrix}
            a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\ 
            a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\ 
             \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\ 
            a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}
         \end {bmatrix}
    </tex>
    The equation <tex>A \vec {x} =  \vec {0}</tex> has a trivial solution <tex>\vec {x} =  \vec {0}</tex>.
    The question here is whether there is a nontrivial solution.
    <p>
        Define <tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</tex> by
        <tex display="block">
            T( \vec {x}) = A \vec {x}
        </tex>
        Then the question of whether the homogeneous linear system has a nontrivial solution is equivalent to 
        asking <tex>\text {null }  T</tex> is nontrivial.
        That is, <tex>T</tex> is <link href="thm-000G.xml" type="local" addr="thm-000G" title="Injectivity equivalent to Kernel Triviality">not injective</link>.
    </p>
</block></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1059</anchor>  <taxon>Theorem</taxon> <addr>thm-000O</addr>  <route>thm-000O.xml</route>   <title>Homogeneous system of linear equations</title> </frontmatter> <mainmatter><p> 
    A homogeneous system of linear equations
    with more variables than equations has 
    a nontrivial solution.
</p></mainmatter> </tree><p>
    We have seen that <link href="thm-000M.xml" type="local" addr="thm-000M" title="Map to smaller dimension is not injective">map to smaller dimension is not injective</link>.
    <tex>T</tex> is not injective if <tex>n &gt; m</tex>. This results the theorem above.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1060</anchor>  <taxon>Example</taxon> <addr>eg-0005</addr>  <route>eg-0005.xml</route>   <title>Inhomogeneous Linear Equations System</title> </frontmatter> <mainmatter><block open="open"><headline>
    <strong>Rephrase in terms of a linear map the question of whether a inhomogeneous system linear equations has no solutions
    for some choice of constant terms.</strong>
</headline> 
    Let <tex>A</tex> be the coefficient matrix of a inhomogeneous linear system.
    <tex display="block">
        A =  \begin {bmatrix}
            a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\ 
            a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\ 
             \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\ 
            a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}
         \end {bmatrix}
    </tex>
    The equation <tex>A \vec {x} =  \vec {b}</tex> has a solution <tex>\vec {x} = A^{-1} \vec {b}</tex>.
    <p>
        Define <tex>T:  \mathbb {F} ^n  \to   \mathbb {F} ^m</tex> by
        <tex display="block">
            T( \vec {x}) = A \vec {x}
        </tex>
        Then the statement that inhomogeneous linear system has no solutions is equivalent to 
        <tex>\vec {b}  \not \in   \text {range }  T</tex>.
        Thus the question is rephrased as not having a solution for some choice of <tex>\vec {b}</tex>.
        What condition ensures <tex>T</tex> is not surjective.
    </p>
</block></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1061</anchor>  <taxon>Theorem</taxon> <addr>thm-000P</addr>  <route>thm-000P.xml</route>   <title>Inhomogeneous system of linear equations</title> </frontmatter> <mainmatter><p>
    An inhomogeneous system of linear equations
    with more equations than variables has 
    no solution for some choice of the constant term.
</p></mainmatter> </tree><p>
    Let <tex>v_1, v_2,  \cdots , v_n</tex> be a basis of <tex>V</tex>.
    We know that for any value of a linear map <tex>T:V \to  W</tex>,
    can be determined by values <tex>\{   T(v_1), T(v_2),  \cdots , T(v_n)   \}</tex>.
    This leads to the definition of the matrix representation of a linear map.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1062</anchor>  <taxon>Definition</taxon> <addr>def-002R</addr>  <route>def-002R.xml</route>   <title>Matrix</title> </frontmatter> <mainmatter><p>
    Let <tex>m,n \in   \mathbb {Z} ^+</tex>.
    A <tex>m \times  n</tex> matrix is a rectangular array of elements of a field <tex>\mathbb {F}</tex>
    with <tex>m</tex> <strong>rows</strong> and <tex>n</tex> <strong>columns</strong>.
    <tex display="block">
        A =  \begin {bmatrix}
            a_{11} &amp; a_{12} &amp;  \cdots  &amp; a_{1n}  \\ 
            a_{21} &amp; a_{22} &amp;  \cdots  &amp; a_{2n}  \\ 
             \vdots  &amp;  \vdots  &amp;  \ddots  &amp;  \vdots   \\ 
            a_{m1} &amp; a_{m2} &amp;  \cdots  &amp; a_{mn}
         \end {bmatrix}
    </tex>
    The notation <tex>A_{jk}</tex> refers to the element in the <tex>j</tex>-th row and <tex>k</tex>-th column.
</p></mainmatter> </tree><p>
    Now we can define the matrix representation of a linear map.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1063</anchor>  <taxon>Definition</taxon> <addr>def-002S</addr>  <route>def-002S.xml</route>   <title>Matrix of Linear Maps</title> </frontmatter> <mainmatter><p>
    Let <tex>T \in   \mathcal {L} (V,W)</tex>,
    <tex>\{   v_1, \ldots ,v_n   \} \subset  V</tex> be a basis of <tex>V</tex>,
    and <tex>\{   w_1, \ldots ,w_m   \} \subset  W</tex> be a basis of <tex>W</tex>.
    The <strong>matrix of <tex>T</tex></strong> with respect to these bases is
    the <tex>m \times  n</tex> matrix <tex>\mathcal {M} (T)</tex> such that
    <tex display="block">
        T(v_j) =  \sum _{i=1}^m  \mathcal {M} (T)_{ij}w_i
    </tex>
    Or we denote <tex>\mathcal {M} (T)</tex> as <tex>\mathcal {M} (T, (v_1, \ldots ,v_n), (w_1, \ldots ,w_m))</tex>.
</p><p>
    If <tex>T</tex> maps <tex>n</tex>-dimensional vector space to <tex>m</tex>-dimensional vector space,
    then <tex>\mathcal {M} (T)</tex> is a <tex>m \times  n</tex> matrix.
</p><block open="open"><headline>
    <strong>Addition</strong>
</headline> 
    For two same-size matrix <tex>A,B</tex>,
    the sum of <tex>A</tex> and <tex>B</tex> is the matrix <tex>C</tex> such that
    <tex display="block">
        C_{ij} = A_{ij} + B_{ij}
    </tex>
    In the language of linear maps <tex>S,T \in   \mathcal {L} (V,W)</tex>,
    <tex display="block">
         \mathcal {M} (T+S) =  \mathcal {M} (T) +  \mathcal {M} (S)
    </tex>
</block><block open="open"><headline>
    <strong>Scalar Multiplication</strong>
</headline> 
    For a scalar <tex>c</tex> and a matrix <tex>A</tex>,
    the product of <tex>c</tex> and <tex>A</tex> is the matrix <tex>B</tex> such that
    <tex display="block">
        B_{ij} = cA_{ij}
    </tex>
    In the language of linear maps <tex>T \in   \mathcal {L} (V,W)</tex>,
    <tex display="block">
         \mathcal {M} (cT) = c \mathcal {M} (T)
    </tex>
</block><block open="open"><headline>
    <strong>Set of Matrices</strong>
</headline> 
    The set of all <tex>m \times  n</tex> matrices with elements in <tex>\mathbb {F}</tex> is denoted as <tex>\mathcal {M} _{m \times  n}( \mathbb {F} )</tex>
    or <tex>\mathbb {F} ^{m \times  n}</tex>.
</block></mainmatter> </tree><p>
    We can see that <tex>\mathbb {F} ^{m \times  n}</tex> is itself a vector space.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1064</anchor>  <taxon>Theorem</taxon> <addr>thm-000Q</addr>  <route>thm-000Q.xml</route>   <title><tex>\dim \mathbb {F} ^{m \times  n} = mn</tex></title> </frontmatter> <mainmatter><p><tex>\mathbb {F} ^{m \times  n}</tex> is a vector space with dimension <tex>mn</tex>.
</p></mainmatter> </tree><p>
    Consider linear maps <tex>T:U \to  V</tex> and <tex>S:V \to  W</tex>.
    The composition of linear maps is <tex>ST</tex>.
    Does the composition of linear maps have a matrix representation?
    <tex display="block">
         \mathcal {M} (ST) =  \mathcal {M} (S) \mathcal {M} (T)
    </tex>
    This makes no sense now but indicates the definition of <strong>matrix multiplication</strong>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1065</anchor>  <taxon>Definition</taxon> <addr>def-002T</addr>  <route>def-002T.xml</route>   <title>Matrix Multiplication</title> </frontmatter> <mainmatter><p>
    Let <tex>A</tex> be a <tex>m \times  n</tex> matrix and <tex>B</tex> be a <tex>n \times  p</tex> matrix.
    Then <tex>AC</tex> is defined as the <tex>m \times  p</tex> matrix <tex>C</tex> such that
    <tex display="block">
        C_{ij} =  \sum _{k=1}^n A_{ik}B_{kj}
    </tex></p><block open="open"><headline>
    <strong>Derivation</strong>
</headline> 
    Let <tex>T:U \to  V</tex> and <tex>S:V \to  W</tex> be linear maps.
    Denote <tex>A =  \mathcal {M} (S)</tex> and <tex>C =  \mathcal {M} (T)</tex>.
    Then the composition of linear maps <tex>ST</tex> is computed
    <tex display="block">
         \begin {align*}
            (ST)(u)_k &amp;= S( \sum _{r=1}^n C_{rk}v_r)  \\ 
            &amp;=  \sum _{r=1}^n C_{rk}S(v_r)  \\ 
            &amp;=  \sum _{r=1}^n C_{rk} \sum _{s=1}^m A _{sr}w_s  \\ 
            &amp;=  \sum _{s=1}^m \left ( \sum _{r=1}^n C_{rk}A_{sr} \right )w_s  \\ 
         \end {align*}
    </tex>
    Thus <tex>\mathcal {M} (ST)</tex> is the <tex>m \times  p</tex> whose entries are
    <tex display="block">
         \mathcal {M} (ST)_{sk} =  \sum _{r=1}^n A_{sr}C_{rk}
    </tex>
</block></mainmatter> </tree><p>
    Now we see that the desired matrix multiplication holds.
    Matrix multiplication is not commutative in general.
    However, it satisfies the associative law and the distributive law.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1066</anchor>  <taxon>Definition</taxon> <addr>def-002Y</addr>  <route>def-002Y.xml</route>   <title><tex>A_{j \cdot }</tex> and <tex>A_{ \cdot  j}</tex></title> </frontmatter> <mainmatter><p>
    Let <tex>A</tex> be a <tex>m \times  n</tex> matrix.
    <ul><li>
            If <tex>1 \leq  j \leq  m</tex> then <tex>A_{j \cdot }</tex> is the <tex>j</tex>-th row of <tex>A</tex>,
            defined as a <tex>1 \times  n</tex> matrix. (A row vector)
        </li>
        <li>
            If <tex>1 \leq  j \leq  n</tex> then <tex>A_{ \cdot  j}</tex> is the <tex>j</tex>-th column of <tex>A</tex>,
            defined as a <tex>m \times  1</tex> matrix. (A column vector)
        </li></ul></p></mainmatter> </tree><p>
    With the notation we can think of matrix multiplication in another perspective.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1067</anchor>  <taxon>Lemma</taxon> <addr>thm-000R</addr>  <route>thm-000R.xml</route>   <title>Entry pf matrix product</title> </frontmatter> <mainmatter><p>
    Suppose <tex>A</tex> is an <tex>m \times  n</tex> matrix and <tex>B</tex> is an <tex>n \times  p</tex> matrix.
    Then the entry of the product <tex>AB</tex> is:
    <tex display="block">
        (AB)_{ij} = A_{i \cdot }B_{ \cdot  j}
    </tex>
    for <tex>1 \leq  i \leq  m</tex> and <tex>1 \leq  j \leq  p</tex>.
</p></mainmatter> </tree><p>
    We have an interesting observation.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1068</anchor>  <taxon>Lemma</taxon> <addr>thm-000S</addr>  <route>thm-000S.xml</route>   <title>Linear Combination of columns</title> </frontmatter> <mainmatter><p>
    Let <tex>A</tex> be an <tex>m \times  n</tex> matrix,
    and <tex>c</tex> is a <tex>1 \times  1</tex> matrix.
    <tex display="block">
        c =  \begin {pmatrix} c_1  \\  c_2  \\   \vdots   \\  c_n  \end {pmatrix}
    </tex>
    Then <tex>Ac = c_1A_{ \cdot  1} + c_2A_{ \cdot  2} +  \cdots  + c_nA_{ \cdot  n}</tex>.
    In other words, <tex>Ac</tex> is a linear Combination of the columns of <tex>A</tex>,
    with the scalars that multiply the columns coming from <tex>c</tex>.
</p></mainmatter> </tree><p>
    Now we begin the study the invertibility of linear maps.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1069</anchor>  <taxon>Definition</taxon> <addr>def-002Z</addr>  <route>def-002Z.xml</route>   <title>Inverse</title> </frontmatter> <mainmatter><p>
    A linear map <tex>T \in \mathcal {L} (V,W)</tex> is said to be <tex>invertible</tex> if 
    there exists a linear map <tex>S \in \mathcal {L} (W,V)</tex> such that:
    <tex display="block">
         \begin {align*}
            T \cdot  S &amp;=  \text {id} _V  \\ 
            S \cdot  T &amp;=  \text {id} _W
         \end {align*}
    </tex>
    where <tex>\text {id}</tex> is the identity map.
    If a linear map <tex>T</tex> is invertible, 
    then the map <tex>S</tex> is <strong>unique</strong> and is called the <strong>inverse</strong> of <tex>T</tex>, denoted <tex>T^{-1}</tex>.
</p><p>
    An <strong>isomorphism</strong> is a linear map that is invertible.
    Two vector spaces are said to be <strong>isomorphic</strong> if there exists an isomorphism between them.
</p></mainmatter> </tree><p>
    A linear map is invertible if and only if
    it is <strong>bijective</strong>.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1070</anchor>  <taxon>Theorem</taxon> <addr>thm-000T</addr>  <route>thm-000T.xml</route>   <title>Isomorphism of equal dimensions</title> </frontmatter> <mainmatter><p>
    Two finite-dimensional vector spaces over <tex>\mathbb {F}</tex>
    are isomorphic iff they have the same <link href="def-001V.xml" type="local" addr="def-001V" title="Dimension">dimension</link>.
</p></mainmatter> </tree><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1071</anchor>  <taxon>Theorem</taxon> <addr>thm-000U</addr>  <route>thm-000U.xml</route>   <title><tex>\mathcal {L} (V,W)</tex> is isomorphic to <tex>\mathbb {F} ^{m \times  n}</tex></title> </frontmatter> <mainmatter><p>
    Let <tex>v_1, v_2,  \ldots , v_n</tex> be a basis for <tex>V</tex>,
    and <tex>w_1, w_2,  \ldots , w_m</tex> be a basis for <tex>W</tex>.
    Then <tex>\mathcal {M}</tex> is an isomorphism between <tex>\mathcal {L} (V,W)</tex> and <tex>\mathbb {F} ^{m \times  n}</tex>.
</p></mainmatter> </tree><p>
    This has a trivial corollary.
</p><tree expanded="true" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1072</anchor>  <taxon>Corollary</taxon> <addr>thm-000V</addr>  <route>thm-000V.xml</route>   <title>Dimension product</title> </frontmatter> <mainmatter><p>
    Let <tex>V</tex> and <tex>W</tex> be finite-dimensional vector spaces.
    Then <tex>\mathcal {L} (V,W)</tex> is finite-dimensional and
    <tex display="block">
         \dim ( \mathcal {L} (V,W)) =  \dim (V) \dim (W).
    </tex></p></mainmatter> </tree></mainmatter> </tree><tree expanded="false" show-heading="true" show-metadata="false" toc="true" numbered="true" root="false"><frontmatter><anchor>1073</anchor>  <taxon>Compute Science</taxon> <addr>cs-0001</addr>  <route>cs-0001.xml</route> <date><year>2024</year> <month>1</month> <day>29</day></date>  <title>Is JavaScript an untyped language?</title> </frontmatter> <mainmatter><p>
    This is a note about the the argument that JavaScript is an untyped language.
    Most opinions came from the References.
</p><p>
    The first thing I want to classify is the word <strong>strong typing</strong> and <strong>weak typing</strong> are meaningless.
    In a limit case we can compare two languages that have similar type system, and talk about which one is <em>stronger</em>.
    But for the common case, it's totally nonsense.
</p><p>
    Static and dynamic typing is a meaningful classsification. But the discussion about dynamic and static languages is mostly wrong on the Internet.
    Dynamic language is a popular concept, however, it is rather a <strong>marketing</strong> than a well-defined terminology.
    It's designed to confuse rather than inform.
</p><p>
    In fact, dynamic typing is just a special case of static typing.
    It limits more than contributes.The root of the problem is the confusion 
    between type and class. It's very useful to have multiple classes of values
    of a same type.
    They are interchangeable because they represent values of the same type.
    Only the form of presentation differs.
</p><p>
    The distinction between two classes of the same type is dynamic.
    But this does not conflict with the fact that only one static type.
    In type theory this is what we called <strong>Sum Type</strong>.
    Being a sum type we can dispatch on the class of the value of the type,
    and decide what to do at runtime.
</p><p>
    This characteristics is same to dynamic language where values can be classified into
    various forms that can be distinguished at runtime.
    The answer is now clear: dynamic language classifies all values in this way.
    What they do just merge all values of the language into a single type.
    The so-called <strong>untyped</strong> language is just <strong>unityped</strong>.
</p><p>
    Therefore, JavaScript is definitely untyped.
</p>
    <p><strong>References</strong></p>
    <ul><li><link href="https://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/" type="external">Dynamic and static language</link></li>
        <li><link href="https://stackoverflow.com/questions/964910/is-javascript-an-untyped-language" type="external">stackoverflow</link></li>
        <li><link href="https://blogs.perl.org/users/ovid/2010/08/what-to-know-before-debating-type-systems.html" type="external">What to know before debating type systems</link></li>
        <li><em>Practical Foundations for Programming Languages</em>, Robert Harper</li></ul>
</mainmatter> </tree></mainmatter> </tree></context> <related/> <backlinks/> <references><tree expanded="false" show-heading="true" show-metadata="true" toc="false" numbered="false" root="false"><frontmatter><anchor>1074</anchor>  <taxon>Reference</taxon> <addr>ttafp-2014</addr>  <route>ttafp-2014.xml</route>  <authors><author>Rob Nederpelt</author><author>Darrell F. Schroeter</author> </authors> <title>Type Theory and Formal Proofs</title> <meta name="doi">10.1017/CBO9781139567725</meta><meta name="venue">Mathematics, Logic, Categories and Sets, Computer Science, Programming Languages and Applied Logic</meta></frontmatter> <mainmatter/> </tree></references></backmatter></tree>